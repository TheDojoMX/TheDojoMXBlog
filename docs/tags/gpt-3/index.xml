<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Gpt-3 on The Dojo MX Blog</title><link>https://blog.thedojo.mx/tags/gpt-3/</link><description>Recent content in Gpt-3 on The Dojo MX Blog</description><generator>Hugo -- gohugo.io</generator><language>es</language><lastBuildDate>Mon, 27 Feb 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://blog.thedojo.mx/tags/gpt-3/index.xml" rel="self" type="application/rss+xml"/><item><title>¿Qué es un modelo transformador de inteligencia artificial?</title><link>https://blog.thedojo.mx/2023/02/27/qu%C3%A9-es-un-modelo-transformador-de-inteligencia-artificial/</link><pubDate>Mon, 27 Feb 2023 00:00:00 +0000</pubDate><guid>https://blog.thedojo.mx/2023/02/27/qu%C3%A9-es-un-modelo-transformador-de-inteligencia-artificial/</guid><description>En los últimos años los modelos de inteligencia artificial generativos han avanzado mucho. Esto es en parte gracias a una nueva arquitectura para las redes neuronales llamada transformer o de transformador, como les llamaremos en este artículo. Hablemos de en qué consiste esta arquitectura y por qué es tan revolucionaria o porque ha ayudado tanto a avanzar en el campo de la inteligencia artificial.
Redes neuronales recurrentes (RNN) Estas eran el estándar para hacer varias tareas, entre ellas la traducción.</description></item></channel></rss>