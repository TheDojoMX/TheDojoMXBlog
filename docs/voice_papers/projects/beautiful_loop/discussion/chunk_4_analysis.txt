Section: Section 4
Characters: 9993
==================================================
Below is the complete content of Section 4 from “A Beautiful Loop,” enriched with an integrated explanation that preserves its key findings, nuanced reasoning, and technical details.

──────────────────────────────
Buddhism (Williams, 2013) and Indian philosophy (Skorupski, 2012; Berger, 2015). For our purposes we define luminosity as the clarity or intensity of knowing or awareness within conscious experience. Connecting epistemic depth with luminosity has the particular benefit of avoiding an infinite regress: as a source of light is never illuminated by another one… (Bhartṛhari, 1963). Just as a light shining out of a lamp illuminates the objects but also the lamp itself, ideas of luminosity and self-reflective awareness often go hand in hand (Williams, 2013). Luminosity and recursion indicate that it is just one knowing with varying degrees, just as a light varies in brightness, but is one light. For our purposes, luminosity provides a useful metaphor—with phenomenological resonance—for the graded nature or clarity of awareness that seems to be possible for conscious systems.

Now, returning to our construct of the reality model. In this context, luminosity is the degree to which the reality model (non-locally) knows itself. Within a hierarchical active inference system, the requisite sharing means that the reality model entails the inference, belief, or expectation, that it exists. By metaphor, it is as if the system’s output becomes another sensory modality that is recursively distributed back through all layers of the system. To provide a metaphor: When we speak out loud, we produce sounds and at the same time hear those sounds and their meaning (i. e., we hear our own voice and what we are saying). Therefore, our output (voice) is also our input (sound). We sequentially produce form (output) and then monitor the global context of that form (input) to ensure that our speech communicates a coherent stream of meaning. There is a continuous looping between what we create through action and what we perceive through the senses. Similarly, the key output of the inferential process in the brain is the construction of a reality model that allows us to survive (analogous to the voice). But this global reality model is also an input to the system and becomes part of the inferential process itself (analogous to the sound, cf. Figure). Consider that while particular contents of the reality model can be confirmed or disconfirmed by new evidence (e. g., transitions in binocular rivalry), the existence of the reality model is nevertheless receiving continuous validation, regardless of the contents (e. g., all changes confirm that a reality model exists). Hence, the epistemic field is constantly evidencing its own existence (i. e., field-evidencing). Any action the organism takes—as little as a saccade, a thought, or a breath—confirms to itself that it (the model) exists. Indeed, all model (i. e., Bayesian belief) updates confirm it. Hence, the fact that the reality model exists becomes a precise inference that rarely loses the inferential competition.

Figure
Generating an epistemic field and its reflective sharing
Note. This figure illustrates the integration of information (operationalized by the hierarchical generative model (HGM)) into a reality model via nested Bayesian binding. The cone at the center illustrates a multi-tiered HGM structure with increasing levels of abstraction, from basic unimodal processes to abstract reasoning exemplified by large scale networks in the brain. The cone includes feedforward and feedback loops throughout all layers. Increasing abstraction reflects increasing compression, information integration, temporal depth, and conceptualization (cf. Figure). A weighted combination of features across the hierarchy are combined or bound together via inferential competition (faded green arrows) to form a global posterior which is homologous to the reality model (the conscious cloud on the top left). This conscious cloud contains diverse perceptual, sensory, and conceptual elements, connected to corresponding hierarchical levels. Crucially, the reality model is recursively broadcast back throughout the hierarchy in the form of top-down predictions of both content and context (thick green arrow), where context is instantiated by predictions of precision. Crucially, predictions of precision weight the prediction errors that underwrite those predictions in a recursive fashion. This sharing of the reality model fine-tunes inference for binding by upweighting representations that cohere with it. We hypothesize that this recursion is the causal mechanism permitting epistemic depth (the sensation of knowing) because the information contained in the reality model loops back into the conscious cloud via the implicit abstraction hierarchy. Hence, the reality model contains information about the existence of itself. While the loop is shown to and from the conscious cloud to illustrate the schema, computationally, all the recursion is within the feedback loops of the central cone structure: there is no dualism implied in this account.

WINNING INFERENCES BIND INTO THE GLOBAL POSTERIOR:
THE WORLD MODEL
EPISTEMIC DEPTH
Ø The world model reflexively feeds back into the abstraction hierarchy
Ø The broadcast information enhances the binding process by upweighting representations that cohere with the unified world model
INFERENTIAL COMPETITION
HYPER-MODELS AND TINY CREATURES

Modeling epistemic depth in a rigorous way calls for a system that not only forms predictions about external states but also—crucially—models its own modelling recursively at a global scale. One way to pursue this is through what we term hyper-generative models, or hyper-models for short. In hierarchical active inference, each layer infers hidden causes in ascending degrees of abstraction. However, to capture epistemic depth, the architecture requires a truly higher-order (i. e., hyper) model that tracks how each layer’s inferences and precision-weightings are being deployed system-wide. Formally, we can posit a hyper-parameter set Φ that encodes beliefs about which layers to trust more (or less) under different contexts, how strongly to up- or down-weight prediction errors, and how to orchestrate feedback loops across the entire network. Such a deeply global parameter permits a system to recursively rework and rediscover their own modelling processes, and thus become a truly agentic self-constructing and deconstructing system, reminiscent of the way humans can intentionally and radically change themselves given the right motivation and context.

Crucially, hyper-parameters that contextualize belief updating—through descending predictions of precision to lower layers—update the (ascending) precision-weighted prediction errors that update the hyper-parameters that update (descending) predictions of precision. And so on, ad infinitum. It is this recursive aspect that equips belief updating with epistemic depth. In terms of phenomenal transparency and opacity, we can imagine each hierarchical layer as a type of glass that can change its optical properties (cf. Figure). In the setting of epistemic depth, descending predictions of precision render transparent panes of glass opaque, equipping the hierarchy with the ability to contextualize and select what is broadcast from one level to the next. In terms of a lamp illuminating itself, epistemic depth offers a very different picture: a picture more akin to a series of holographic screens illuminating each other in their reflected light. This picture foregrounds the recursive, non-local and (self) reflective nature of epistemic depth.

Clarifying how a hyper-parameter set, Φ orchestrates the entire system is a challenge. One possibility is to define Φ within a factor-graph architecture that includes hyper-nodes encoding conditional beliefs about each sub-model’s precision or reliability (Parr & Friston, 2018). These hyper-nodes would propagate top-down signals—precision updates, gating directives, or structural reconfigurations—to lower-level nodes, ensuring that each layer’s inference is shaped by global meta-beliefs. Such a mechanism would allow simulation of when and how reflective broadcasts occur, enabling comparisons to neurophysiological data and refining our broader understanding of epistemic depth in biological and artificial systems.

Practically, this kind of architecture has proved useful in modelling brain responses, using a variant of predictive coding called the hierarchical Gaussian filter. In computational neuroscience, minimal forms of epistemic depth have been used to illustrate attentional selection and the segregation of figure from ground. Technically, the nonlocal aspect of epistemic depth inherits from the fact that the hyper-parameter—prescribing precisions at every level of the hierarchy—renders each level part of the hyper-parameter’s Markov blanket (because they are all children of the hyper-parameter). This mandates recursive message passing between the Bayesian beliefs over hyper-parameters and all levels, in which descending predictions of precision are reflected back in the form of a prediction error over precision. See Kanai et al., for the functional form of these second-order prediction errors in the context of predictive coding architectures.

Figure
Epistemic depth as hyper-modeling
Note. This diagram illustrates the abstraction hierarchy of features as being composed of layers of smart glass which have the property of being able to change from being transparent (e. g., the layers on the left) to more or less opaque (e.

──────────────────────────────
Explanation and Significance:
This section deeply explores the notion of “luminosity” as a metaphor for the clarity and intensity of conscious awareness, drawing parallels with ancient philosophical traditions. It argues that luminosity—and its recursive, self-referential properties—allows us to conceptualize how the brain’s reality model continually “illuminates” itself. Core to this discussion is the idea that within a hierarchical active inference system, the process of generating and then recursively integrating sensory outputs and predictions creates a loop where the world model constantly confirms its own existence.

The narrative further introduces hyper-generative models (or hyper-models) as a technical framework required to model this recursive self-awareness. By defining a hyper-parameter set Φ that governs the weighting and updating of prediction errors across the entire system, the authors delineate a mechanism by which epistemic depth (the sensation of knowing) emerges from nested, multi-level inference processes. This recursive binding—illustrated with metaphors such as a lamp illuminating itself or holographic screens mutually reflecting light—captures how top-down predictions interact with bottom-up sensory data to create a coherent, self-validating model of reality.

The significance of these ideas is manifold. First, they offer a coherent explanation for how the brain might overcome the potential infinite regress of self-awareness. Second, they provide a mechanistic account linking phenomenological experience (or luminosity) with computational processes (Bayesian updating, precision weighting, and hyper-modeling). Third, by grounding these theoretical insights in illustrations drawn from predictive coding and neurobiological data, the section builds a bridge between abstract theory and empirical observation. 

Ultimately, this part of the paper argues that consciousness is not a static snapshot but the emergent result of a continuously updated, reflective process in which the brain’s reality model is both the product and the producer of its own knowing. This “beautiful loop”—where winning inferences bind into a global posterior that recurrently re-enters the inferential hierarchy—illuminates (both literally and metaphorically) the depth, complexity, and recursive self-referential nature of conscious experience.