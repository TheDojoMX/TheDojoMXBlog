Section: Section 4
Characters: 9999
==================================================
• Inference time computing: La inferencia genera un notable incremento en el "IQ" de un modelo. Se plantea que tomar un modelo open source grande, hacerle distillation para especializarlo y aplicarle una gran cantidad de cómputo en tiempo de inferencia proporciona una ventaja significativa. 
• Capacidad en CBRN: Se menciona una “fuga masiva de capacidad” en el campo CBRN (químico, biológico, radiológico y nuclear) como consecuencia de la disponibilidad de grandes recursos de cómputo en inferencia. 
• Estructura de modelos de datos en el futuro: Se proyecta que en 5 a 10 años existirán 10 modelos distribuidos globalmente – cinco en Estados Unidos, tres en China y dos en otros lugares. Estos modelos son centros de datos con capacidad de múltiples gigavatios, y en China se espera que sean propiedad del gobierno. 
• Seguridad en instalaciones nucleares: Se ofrece el detalle de una instalación de plutonio en Estados Unidos, ubicada dentro de una base mayor, fuertemente custodiada con numerosos sistemas de seguridad (armas, barriadas, etc.), siendo una de las dos instalaciones existentes en el país. 
• Proliferación de centros de datos: Se advierte que si la tecnología llega a implementarse en servidores de menor escala, existirá un problema de proliferación masiva de centros de datos basados en modelos open source sin un régimen de control adecuado. 
• Ejemplo del clúster de Grock: Un clúster construido por Nvidia en Memphis, Tennessee, entrenó el modelo Grock en aproximadamente 20 días utilizando 200,000 GPUs. Se estima un costo aproximado de $50,000 por GPU, lo que implica que el clúster equivale a un supercomputador de ~$10 mil millones alojado en un edificio. 
• Distribución de inteligencia y riesgos: Se destaca que, si la inteligencia se convierte en un problema distribuido (aprovechable en servidores pequeños) se plantea el riesgo de acceso por parte de actores maliciosos, como terroristas. 
• Aprendizaje y auto-mejora: Se discute el concepto de auto-mejora recursiva. Actualmente, los sistemas son capaces de aprender y ajustar sus procesos, pero todavía no se observa que puedan generar sus propios objetivos o “exfiltrarse” de su sistema de control. 
• Función de recompensa y problema de no-estacionariedad: Los modelos usan funciones de recompensa simples (por ejemplo, "vencer al humano"). Sin embargo, surge el problema de la “no estacionariedad” cuando las reglas cambian y se necesita aplicar conocimientos previos a nuevos contextos para descubrir patrones y lograr avances significativos. 
• Escalafón (scaffolding): Se predice que hacia 2025 la capacidad de la IA para generar su propio “scaffolding” (establecer marcos o andamios conceptuales) se hará inminente. Este enfoque permite preparar las “vías” y “migas de pan” para que la IA propicie avances en tareas que requieran inferencia continua durante períodos prolongados (por ejemplo, 20 horas consecutivas de cómputo).