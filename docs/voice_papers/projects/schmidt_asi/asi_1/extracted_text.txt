TÃ­tulo: "Ex-Google CEO: What Artificial Superintelligence Will Actually Look Lik
e w/ Eric Schmidt \u0026 Dave B"

(00:01) When do you see what you define as digital super intelli
gence? Uh, within 10 years. The AI's ability to generate its own scaffolding is 
imminent. Pretty much sure that that will be a 2025 thing. We certainly don't kn
ow what super intelligence will deliver, but we know it's coming. And what do pe
ople need to know about that? You're going to have your own polymath. (00:24) So
, you're going to have the sum of Einstein and Leonardo da Vinci in the equivale
nt of your pocket. agents are going to happen. This math thing is going to happe
n. The software thing is going to happen. Everything I've talked about is in the
 positive domain, but there's a negative domain as well. It's likely, in my opin
ion, that you're going to see. (00:47) Now, that's a moonshot, ladies and gentle
men. Hey, everybody. Welcome to Moonshots. I'm here live with my Moonshot mate, 
Dave London. Uh we're here in our Santa Monica studios and we have a special gue
st today, Eric Schmidt, the author of Genesis. We talk about China. We're going 
to talk about, you know, digital super intelligence. (01:11) We'll talk about, y
ou know, what people should be thinking about over the 10 years. And we're talki
ng about the guy who has more access to more more actionable information than pr
obably anyone else you could think of. So, it should be should be pretty excitin
g. Incredibly brilliant. (01:28) All right, stand by for a conversation with the
 Eric Schmidt, CEO or past CEO of Google and an extraordinary investor and uh an
d thinker in this field of AI. Let's do it. Eric, welcome back to Moonshots. It'
s great to be here with you guys. Thank you. It's been uh it's been a long road 
since I first met you at Google. I remember uh our first conversations were fant
astic. (01:50) Uh it's been a crazy month in the world of AI, but I think every 
month from here is going to be a crazy month. And so I'd love to hit on a number
 of subjects and get your your take on them. I want to start with probably the m
ost important point that you've made recently that got a lot of traction, a lot 
of attention, which is that AI is underhyped when the rest of the world is eithe
r confused, lost, or think it's, you know, not impacting us. (02:13) We'll get i
nto in more detail, but quick most important point to make there. AI is a learni
ng machine. Yeah. And in network effect businesses, when the learning machine le
arns faster, everything accelerates. It accelerates to its natural limit. The na
tural limit is electricity. Not chips, electricity really. Okay. (02:42) So that
 gets me to the next point here, which is uh a discussion on AI and energy. So, 
we saw recently was Meta recently announcing uh that they signed a 20-year nucle
ar contract with uh with Constellation Energy. We've seen Google, Microsoft, Ama
zon, everybody buying basically nuclear capacity right now. That's got to be wei
rd uh that private companies are are basically taking over into their own hands 
what was utility function before. (03:18) Um, well, just to be cynical, I I'm so
 glad those companies plan to be around the 20 years that it's going to take to 
get the nuclear power plants built. In my recent testimony, I talked about the t
he current expected need for the AI revolution in the United States is 92 gawatt
 of more power. For reference, one gawatt is one big nuclear power station. And 
there are none essentially being started now. And there have been two in the las
t what, 30 years built. (03:44) There is excitement that there's an SMR, small m
odular reactor coming in at 300 megawws, but it won't start till 2030. As import
ant as nuclear, both fision and fusion is, they're not going to arrive in time t
o get us what we need as a globe to deal with our many problems and the many opp
ortunities that are before us. (04:06) Do you think uh so if if you look at the 
sort of three-year timeline toward AGI, do you think if you started a a fusion r
eactor project today that won't come online for five, six, seven years, is there
 a probability that the AGI comes up with some other breakthrough fusion or othe
rwise that makes it irrelevant before it even gets online? A very good question.
 (04:25) We don't know what artificial general intelligence will deliver. Yeah. 
And we certainly don't know what super intelligence will deliver, but we know it
's coming. So, first we need to plan for it. And there's lots of issues as well 
as opportunities for that. But the fact of the matter is that the computing need
s that we name now are going to come from traditional energy suppliers in places
 like the United States and the Arab world and Canada and the Western world. And
 it's important to note that China has lots of electricity. So if they get (04:5
7) the chips, it's going to be one heck of a race. Yeah. They've been scaling it
 uh you know at two or three times. The US has been flat for how long in terms o
f energy production? Um from my perspective uh infinite. In fact, electricity de
mand declined for a while as has overall energy needs because of conservation an
d other things. (05:22) But the data center story is the story of the energy peo
ple, right? And you sit there and you go, how could these data centers use so mu
ch power? Well, and especially when you think about how little power our brains 
do. Well, these are our best approximation in digital form of how our brains wor
k. But when they start working together, they become superbrains. (05:40) The pr
omise of a superbrain with a 1 gawatt for example data center is so palpable. Pe
ople are going crazy. And by the way, the economics of these things are unproven
. How much revenue do you have to have to have 50 billion in capital? Well, if y
ou depreciate it over three years or four years, you need to have 10 or 15 billi
on dollars of capital spend per year just to handle the infrastructure. Those ar
e huge businesses and huge revenue, which in most places is not there yet. (06:1
0) I'm curious, there's so much capital being invested and deployed right now in
 SMRs in in nuclear bringing Three Mile Island back online. uh in in fusion comp
anies. Why isn't there an equal amount of capital going into making uh the entir
e you know chipset and compute just a thousand times more energy efficient? Ther
e is a similar amount in going in capital. (06:35) There are many many startups 
that are working on non-traditional ways of doing chips. The transformer archite
cture which is what is powering things today has new variants. Every week or so 
I get a pitch from a new startup that's going to build inference time, test time
 computing which are simpler and they're optimized for inference. (06:57) It loo
ks like the hardware will arrive just as the software needs expand. And by the w
ay, that's always been true. We old-timers had a phrase um grove giveth and gate
s take it away. So Intel would improve the chipsets right way back when and the 
software people would immediately use it all and suck it all up. (07:22) I have 
no reason to believe that that's that that law grove and gates law has changed. 
If you look at the gains in like the Blackwell chip or the AS uh the the 350 chi
p in AMD, these chips are massive supercomputers and yet we need according to th
e people have hundreds of thousands of these chips just to make a data center wo
rk. (07:43) That shows you the scale of what this kind of thinking algorithms. N
ow you sit there and you go what could these people possibly be doing with all t
hese chips? I'll give you an example. We went from language to language which is
 what chatbd can be understood at to reasoning and thinking. (08:01) If you want
 to look at an open eye example look at open oi03 which go does forward and back
 reinforcement learning and planning. Now the cost of doing the forward and back
 is many orders of magnitude besides just answering your question for your PhD t
hesis or your college paper that planning the back and forth is computationally 
very very expensive. (08:24) So with the best energy and the best technology tod
ay we are able to show evidence of planning. Many people believe that if you com
bine planning and very deep memories you can build human level intelligence. Now
 of course they will be very expensive to start with but humans are very very in
dustrious and furthermore the great future companies will have AI scientists tha
t is non-human scientists AI programmers that as opposed to human programmers wh
o will accelerate their impact. (08:54) So, if you think about it, going back to
 you're the author of the abundance thesis, as best I can tell, Peter, you've ta
lked about this for 20 years. You saw it first. It sure looks like if we get eno
ugh electricity, we can generate the power in in the sense of intellectual power
 to generate abundance along the lines that you predicted two decades ago. (09:1
3) Every week, I study the 10 major tech meta trends that will transform industr
ies over the decade ahead. I cover trends ranging from humanoid robots, AGI, qua
ntum computing, transport, energy, longevity, and more. No fluff, only the impor
tant stuff that matters, that impacts our lives and our careers. If you want me 
to share these with you, I write a newsletter twice a week, sending it out as a 
short two-minute read via email. (09:38) And if you want to discover the most im
portant meta trends 10 years before anyone else, these reports are for you. Read
ers include founders and CEOs from the world's most disruptive companies and ent
repreneurs building the world's most disruptive companies. It's not for you if y
ou don't want to be informed of what's coming, why it matters, and how you can b
enefit from it. (09:57) To subscribe for free, go to dmadis.com/tatrends. That's
 dmandis.com/tatrends to gain access to trends 10 plus years before anyone else.
 Let me throw some numbers at you just to reinforce what you said. you know, we 
have a couple companies in the lab that are doing voice customer service, voice 
sales with the new, you know, just as of the last month. Sure. (10:20) And the v
alue of these these conversations is 10 to $1,000. And the cost of the compute i
s, you know, maybe two three concurrent GPUs is optimal. It's like 10 20 cents. 
And so they would buy massively more compute to improve the the quality of the c
onversation. There aren't even close to enough. (10:43) We we count about 10 mil
lion concurrent phone calls that should move to AI in the next year or so. And a
nd my view of that is that's a good tactical solution and a great business. Let'
s look at other examples of tactical solutions that are great businesses. And I 
obviously have a conflict of interest talking about Google because I love it so 
much. (10:59) So with that as in mind, look at the Google strength in GCP. Now G
oogle Google's cloud product where they have a completely fully served enterpris
e offering for essentially automating your company with AI. Yeah. And the remark
able thing and this is to me is shocking is you can in an enterprise write the t
ask that you want and then using something called the model context protocol you
 can connect your databases to that and the large language model can produce the
 code for your enterprise. (11:30) Now, there's 100,000 enterprise software comp
anies, middleware companies that grew up in the last 30 years that I've been wor
king on this that are all now in trouble because that that interstitial connecti
on is no longer needed with their business and and and of course they'll have to
 change as well. (11:47) The good news for them is enterprises make these change
s very slowly. If you built a brand new enterprise um architecture for ERP and M
RP, you would be highly tempted to not use any of the ERP or MRP suppliers, but 
instead use open- source libraries, build essentially use BigQuery or the equiva
lent from Amazon, which is Red Redshift, and essentially build that architecture
 and it gives you infinite flexibility and the computer system writes most of th
e code. Now, programmers don't go away at the moment. (12:17) It's pretty clear 
that junior programmers go away. The sort of journeymen, if you will, of the ste
reotype because these systems aren't good enough yet to automatically write all 
the code. They need very senior computer scientists, computer engineers who are 
watching it, that will eventually go away. (12:35) One of the things to say abou
t productivity, and I call this the San Francisco consensus because it's it's la
rgely the view of people who operate in San Francisco, goes something like this.
 uh we're just about to the point where we can do two things that are shocking. 
The first is we can replace most programming tasks by computers and we can repla
ce both most mathemat mathematical tasks by computers. (13:03) Now you sit there
 and you go why? Well, if you think about programming and math, they have limite
d language sets compared to human language. So close they're simpler computation
ally and they're scale free. You can just do it and do it and do it with more el
ectricity. You don't need data. You don't need real world input. You don't need 
telemetry. You don't need sensors. Yeah. (13:23) So, it's likely in my opinion t
hat you're going to see worldclass mathematicians emerge in the next one year th
at are AI based and worldclass programmers that going to appear within the next 
one or two years. When those things are deployed at scale, remember math and pro
gramming are the basis of kind of everything, right? It's an accelerate accelera
nt for physics, chemistry, biology, material science. (13:50) So, going back to 
things like climate change, can you imagine if we and this goes back to your ori
ginal argument, Peter, imagine if we can accelerate the discoveries of the new m
aterials that allow us to deal with a carbonized world. Yeah. Right. It's very e
xciting. Can I love to drill in about you first? I just want to hit this because
 it's important the potential for there to be I don't want to use the word PhD l
evel you know other than uh thinking in the terms of research PhD level AIS and 
uh that can basically attack any problem and solve it uh and solve math if you w
ould in physics. uh this idea of an AI, (14:30) you know, intelligence explosion
. Um Leo Leopold put that at like 26 27 uh heading towards digital super intelli
gence in the next few years. Do you buy that time frame? So again, I consider th
at to be the San Francisco consensus. I think the dates are probably off by one 
and a half or two times, which is pretty close. (14:58) So a reasonable predicti
on is that we're going to have specialized soants in every field within five yea
rs. That's pretty much in the bag as far as I'm concerned. Sure. And here's why.
 You have this amount of humans and then you add a million AI scientists to do s
omething, your slope goes like this. Your rate of improvement, we should get the
re. (15:20) The real question is once you have all these sants, do they unify? D
o they ultimately become a superhum? The term we're using is super intelligence,
 which implies intelligence that beyond the sum of what humans can do. The race 
to super intelligence, which is incredibly important because imagine what a supe
r intelligence could do that we ourselves cannot imagine, right? There it's so m
uch smarter than we and it has huge proliferation issues, competitive issues, Ch
ina versus the US issues, electricity issues, so forth. (15:53) We don't even ha
ve the language for the deterrence aspects and the proliferation issues of these
 powerful models or the imagination. Totally agree. In fact, it's it's one of th
e great flaws actually in the original conception. You remember Singularity Univ
ersity and Ray Curtzwhile's books and everything. (16:11) And we kind of drew th
is curve of rat level intelligence, then cat, then monkey, and then it hits huma
n and then it goes super intelligent. But it's now really obvious when you talk 
to one of these multilingual models that's explaining physics to you that it's a
lready hugely super intelligent within its savant category. (16:29) And so Denni
s keeps redefining AGI day as well when it can discover relativity the same way 
Einstein did with data that was available up until that date. That's when we hav
e AGI. So long before that. Yeah. So I think it's worth getting the timeline rig
ht. Yeah. So the following things are baked in. You're going to have an agentic 
revolution where agents are connected to solve business processes, government pr
ocesses and so forth. (16:54) They will be adopted most quickly in companies in 
country companies that have a lot of money and a lot of uh time latency issues a
t stake. It will adop be adopted most slowly in places like government which do 
not have an incentive for innovation. Um and fundamentally are job programs and 
redistribution of income kind of programs. So call it what you will. (17:12) The
 important thing is that there will be a tip of the spear in places like financi
al services, certain kind of bio biomedical things, startups and so forth. And t
hat's the place to watch. So all of that is going to happen. The agents are goin
g to happen. This math thing is going to happen. The software thing is going to 
happen. (17:32) We can debate the rate at which the biological revolution will o
ccur, but everyone agrees that it's right after that. We're very close to these 
major biological understandings. Um in physics you're limited by data but you ca
n generate it synthetically. There are groups which I'm funding which are genera
ting physics um essentially um models that can approximate algorithms that canno
t be they're incomputable. (17:59) So in other words you have a a essentially a 
foundation model that can answer the question good enough for the purposes of do
ing physics without having to spend a million years doing the computation of you
 know quantum chromodnamics and things like that. Yep. Um, all of that's going t
o happen. The next questions have to do with what is the point in which this bec
omes a national emergency and it goes something like this. (18:23) Everything I'
ve talked about is in the positive domain, but there's a negative domain as well
. The ability for biological attacks, um, uh, obviously cyber attacks. Imagine a
 cyber attack that we as humans cannot conceive of, which means there's no defen
se for it because no one ever thought about it. Right? These are real issues. A 
biological attack, you take a virus, I won't obviously go into the details. (18:
47) You take a virus that's bad and you make it undetectable by some changes in 
its structure, which again I won't go into the details. We released a whole repo
rt at the national level on this issue. So at some point the government and not 
it doesn't appear to understand this now is going to have to say this is very bi
g because it affects national security, national economic strengths and so forth
. (19:14) Now China clearly understands this and China is putting an enormous am
ount of money into this. We have slowed them down by virtue of our chips control
s but they found clever ways around this. There are also proliferation issues. M
any of the chips that they're not supposed to have, they seem to be able to get.
 And more importantly, as I mentioned, the algorithms are changing. (19:36) And 
instead of having these expensive foundation models by themselves, you have cont
inuous updating, which is called test time training. That continuous updating ap
pears to be capable of being done with lesser power chips. So, so we I there are
 so many questions that I think we don't know. We don't know the role of open so
urce because remember open source means open weights, which means everyone can u
se it. (20:00) A fair reading of this is that every country that's not in the we
st will end up using open source because they'll perceive it as cheaper which tr
ans transfers leadership in open source from America to China. That's a big deal
, right? If that occurs. Um how much longer do the chip bans if you will hold an
d how long before China can answer? What are the effects of the current uh gover
nment's policies of getting rid of foreigners and foreign investment? what happe
ns with the Arab U data centers assuming they work and I'm generally supportive 
of them um if those things are then misused uh to help train train (20:32) model
s. The list just goes on and on. We just don't know. Okay. Can I ask you probabl
y one of the toughest questions? I don't know if you saw Mark Andre uh he went a
nd talked to the Biden administration past administration and said how are we go
ing to deal with exactly what you just talked about chemical and biological and 
radiological and nuclear risks from big foundation models being operated by fore
ign countries. (20:56) And the Biden answer was you know we're going to keep it 
into the three or four big companies like Google and we'll just regulate them. A
nd Mark was like, "That is a surefire way to lose the race with China because al
l innovation comes from a startup that you didn't anticipate or you know it's ju
st the American history and you're you're cutting off the entrepreneur from part
icipating in this. (21:20) " So as of right now with the open source models, the
 entrepreneurs are in great shape. But if you think about the models getting cra
zy smart a year from now, how are we going to have the the balance between start
ups actually being able to work with the best technology but proliferation not p
ercolating to every country in the world. (21:40) Again, a set of unknown questi
ons and anybody who knows the answer to these things is not telling the full tru
th. Um the doctrine in the B administration was called 10 to the 26 flops. It wa
s a point that was a consensus above which the models were powerful enough to ca
use some damage. So the theory was that if you stayed below 10 the 26 you didn't
 need to be regulated. But if you were above that you needed to be regulated. (2
2:04) And the proposal in the Biden administration was to regulate both the open
 source and the closed source. Okay that's that's the those are the the summary 
that of course has been ended by the Trump administration. um they have not yet 
produced their own thinking in this area. They're very concerned about China and
 it getting forward. So, they'll come out with something. (22:26) From my perspe
ctive, the the core questions are the following. Will the Chinese be able to use
 even with um chip restrictions, will they use architectural changes that will a
llow them to build models as powerful as ours? And let's assume they're governme
nt funded. That's the first question. (22:45) The next fun question is how will 
you raise $50 billion for your data center if your product is open source? Yeah.
 In the American model, part of the reason these models are closed is that the b
usiness people and the lawyers correctly are saying I've got to sell this thing 
because I've got to pay for my capital. These are not free goods. (23:03) And th
e US government correctly is not giving $50 billion to these companies. So we do
n't know that. Um the to me the key question to watch is look at Deepseek. So De
epseek um a week or so ago Gemini 2.5 Pro got to the top of the leaderboards in 
intelligence. Great achievement for my friends at Gem at Gemini. A week later de
epseek comes in and is slightly better than Gemini. (23:34) and Deeps of course 
is trained on the existing hardware that's in China which includes stuff that's 
been Pilford and some of the Ascend it's called the Ascend Huawei chips and a fe
w others what happens now the US people say well you know the the deepseek peopl
e cheated and they cheated by doing a technique called distillation where you ta
ke a large model and you ask it 10,000 questions you get its answers and then th
en you use that as your training material yep so the US companies will have to f
igure out a way to make sure that their proprietary information that they've spe
nt so much money on does not get (24:05) leaked into these open source things. U
m I just don't know with respect to uh nuclear, biological, chemical and so fort
h issues. Um the US companies are doing a really good job of looking for that. T
here's a great concern, for example, that nuclear information would leak into th
ese models as they're training without us knowing it. And by the way, that's a v
iolation of law. (24:30) Oh, really? they work and the whole nuclear information
 thing is is there's no free speech in that world for good reasons and there's n
o free use and copyright and all that kind of stuff. It's illegal to do it and s
o they're doing a really really good job of making sure that that does not happe
n. (24:48) They also put in very significant tests for biological information an
d certain kinds of cyber attacks. What happens there? Their incentive is their i
ncentive to continue especially if it's not if it's not required by law. The gov
ernment has just gotten rid of the the safety institutes that were in place in B
iden and are replacing it by a new term which is largely a safety assessment pro
gram which is a fine answer. (25:08) I think collectively we in the industry jus
t want the government at the secret and top secret level to have people who are 
really studying what China and others are doing. You can be sure that China real
ly has very smart people studying what we're doing. We at the secret and top sec
ret level should have the same thing. (25:29) Have you read the uh AI27 paper? I
 have. Uh, and so for those listening who haven't read it, it's a it's a future 
vision of the AI and US and China racing towards AI and at some point the story 
splits into a we're going to slow down and work on alignment or we're going full
 out and uh, you know, spoiler alert and the race to infinity uh, humanity vanis
hes. (25:56) So the right outcome will ultimately be some form of deterrence and
 mutually assured destruction. Uh I wrote a paper with two other authors Dan Hen
dricks and Alex Wang where we named it mutual AI malfunction. And the idea was g
oes something like this. Um you're the United States, I'm China, you're ahead of
 me. Um at some point you cross a line. (26:22) You know, you Peter cross a line
 and I China go this is unacceptable. At some point it becomes in terms of amoun
t of compute and amount of it's it's something you're doing where it affects my 
sovereignty. It's not just words and yelling and an occasional shooting down a j
et. It's it's a real threat to the identity of my my country, my economic what h
ave you. (26:46) Under this scenario, I would be highly tempted to do a cyber at
tack to slow you down. Okay? In mutually assured mal malfunction, if you will, w
e have to engineer it so that you have the ability to then do the same thing to 
me. And that causes both of us to be careful not to trigger the other. That's wh
at mutual assured destruction is. That's our best formulation right now. (27:12)
 We also recommend in our work, and I think it's very strong, that the governmen
t require that we know where all the chips are. And remember, the chips can tell
 you where they are because they're computers. Yeah. And it would be easy to add
 a little crypto thing, which would say, "Yeah, here I am, and this is what I'm 
doing. (27:31) " So, so knowing where the chips are, knowing where the training 
runs are, and knowing what these fault lines are are very important. Now, there 
are a whole bunch of assumptions in this scenario that I described. The first is
 that there was enough electricity. The second is that there was enough power. T
he third is the Chinese had enough electricity, which they do, and enough comput
ing resources, which they may or may not have or may in the future have, and may
 in the future have. (27:56) And also, I'm asserting that everyone arrives at th
is eventual state of super intelligence at a roughly the same time. Again, these
 are debatable points, but the most interesting scenario is we're saying it's 19
38. the letter has come, you know, from Einstein to the president and we're havi
ng a conversation and we're saying,"Well, how does this end?" Okay. (28:20) So, 
if you were so brilliant in 38, what you would have said is this ultimately ends
 with us having a bomb, the other guys having a bomb, and then we're going to ha
ve one heck of a negotiation to try to make sure that we don't end up destroying
 each other. And I think the same conversation needs to get started now, well be
fore the Chernobyl events, well before the buildups. (28:41) Can I just take tha
t one more step? And and don't answer if you don't want to, but if it was 1947, 
1948, so before the Cold War really took off, and you say, well, that's similar 
to where we are with China right now. We have a competitive lead, but it may or 
may not be fragile. (29:00) What would you do differently 1947 1940 or what woul
d Kissinger do different 1947 1948 1949 than what we did do? You know I I wrote 
two books with Dr. Kissinger and I miss him very much. He was my closest friend.
 Um and Henry was very much a realist in the sense that when you look at his his
tory in uh roughly 36 38 he and his uh I guess 37 38 his family were were Jewish
 were forced to immigrate from uh Germany because of the Nazis and he watched th
e entire world that he'd grown up with as a boy be destroyed by the Nazis and by
 Hitler and then he saw the confilgration that occurred as a result and I tell y
ou that whether you like him or not, he spent the rest of (29:42) his life tryin
g to prevent that from happening again. Mhm. So we we are today safe because peo
ple like Henry saw the world fall apart. Mhm. So I think from my perspective, we
 should be very careful in our language and our strategy to not start that proce
ss. Henry's view on China was different from other China scholars. (30:09) His v
iew was in China was that we shouldn't poke the bear, that we shouldn't talk abo
ut Taiwan too much and we let China deal with our own problems which were very s
ignificant. But he was worried that we or China in a small way would start World
 War II in the same way that World War I was started. You remember that World Wa
r One one, World War I started with a essentially a small geopolitical event whi
ch was quickly escalated for political reasons on on all sides and then the rest
 was a horrific war, the war to end all wars at the time. (30:38) So we have to 
be very very careful when we have these conversations not to isolate each other.
 Um Henry started a number of what are called track two dialogues which I'm part
 of one of them to try to make sure we're talking to each other. And so somebody
 who's a a hardcore person would say, well, you know, we're Americans and we're 
better and so forth. (30:58) Well, I can tell you having spent lots of time on t
his, the Chinese are very smart, very care capable, very much up here. And if yo
u're confused about that, again, look at the arrival of Deep Seek. A year ago, I
 said they were two years behind. I was clearly wrong. With enough money and eno
ugh power, they're in the game. Yeah. (31:21) Let me actually drill in just a li
ttle bit more on that too because I think um one of the reasons deep sea caught 
up so quickly is because it turned out that inference time generates a lot of IQ
 and I don't think anyone saw that coming and inference time is a lot easier to 
catch up on and also if you take one of our big open source models and distill i
t and then make it a specialist like you were saying a minute ago and then you p
ut a ton of infra time compute behind it, it's a massive advantage and also a ma
 massive leak of capability within CBRN for example that nobody anticipated and 
CBNN remember is chemical, biological, radiological and nuclear. Um (31:57) let 
me rephrase what you said. If the structure of the world in 5 to 10 years is 10 
models and I'll make some numbers up. Five in the United States, three in China,
 two elsewhere. And those models are data centers that are multi- gigawatts. The
y will be all nationalized in some way. In China, they will be owned by the gove
rnment. Mhm. The stakes are too high. (32:28) Mhm. Um, one in my military work o
ne day I visited a place where we keep our plutonium and we keep our plutonium i
n in a base that's inside of another base with even more machine guns and even m
ore specialized because the plutonium is so is so interesting and and obviously 
very dangerous and I believe it's the only one or two facilities that we have in
 America. (32:53) So in that scenario, these data centers will have the equivale
nt of guards and machine guns because they're so important. Now is that a stable
 geopolitical system? Absolutely. You know where they are. President of one coun
try can call the other. They can have a conversation. You know, they can agree o
n what they agree on and so forth. But let's say the it is not true. (33:19) Let
's say that the technology improves again unknown to the point where the kind of
 technologies that I'm describing are implementable on the equivalent of a small
 server then you have a humongous data center proliferation problem and that's w
here the open-source issue is so important because those servers which will be p
roliferate throughout the world will all be on open source. (33:38) We have no c
ontrol regime for that. Now, I'm in favor of open source as you mentioned earlie
r with Mark Andre u uh that open competition and so forth tends to allow people 
to run ahead in defense of the proprietary companies. Collectively, they believe
 as best I can tell that the open- source models can't scale fast enough because
 they need this heavyweight training. (34:06) If you look, I I'll give you an ex
ample of Grock is trained on a single cluster that was built by Nvidia in 20 day
s or so forth in Memphis, Tennessee of 200,000 GPUs. Um GPU is about $50,000. Yo
u can say it's about a $10 billion supercomput in one building that does one thi
ng, right? If that is the future, then we're okay because we'll be able to know 
where they are. Yeah. (34:34) If in fact the arrival of intelligence is ultimate
ly a a distributed problem, then we're going to have lots of problems with terro
rism, bad actors, North Korea poorly, which is my which is my greatest concern. 
Right. China and the US are rational actors. Yeah. Uh the terrorist who has acce
ss to this and I I don't want to go all negative on this on this podcast. It's i
t's an important thing to wake people up to the deep thinking you've done on thi
s. (34:59) Um my concern is is the terrorist who gains access and are we spendin
g enough time and energy and are we training enough models to watch them. So the
 first the companies are doing this there are there's a body of work happening n
ow which can be understood as follows. You have a super intelligent model. Can y
ou build a model that's not as smart as the student that's studying? You know, t
here is a professor that's watching the student, but the student is smarter than
 the professor. Is it possible to watch what (35:36) it does? It appears that we
 can. It appears that there's a way even if you have a this rogue incredible thi
ng, we can watch it and understand what it's doing and thereby control it. Anoth
er example of the of where where we don't know is that it's very clear that thes
e savant models will proceed. (35:57) There's no question about that. The questi
on is how do we get the Einsteins? So there are two possibilities. One and this 
is to discover completely new schools of thought which is what's the most exciti
ng thing. Yeah. And in our book Genesis, Henry and I and Craig talk about the im
portance of polymaths in history. In fact, the first chapter is on polymaths. (3
6:23) What happens when we have millions and millions of polymaths? Very, very i
nteresting. Okay. Now, it looks like the great discoveries, the greatest scienti
sts and people in our history had the following property. They were experts in s
omething and they looked at some at a different problem and they saw a pattern i
n one area of thinking that they could apply to a completely unrelated field and
 they were able to do so and make a huge breakthrough. The models today are not 
able to do that. (36:57) So one thing to watch for is algorithmically when can t
hey do that? This is generally known as the non-stationerity problem. Yeah. beca
use uh the reward functions in these models are fairly straightforward. You know
, beat the human, beat the question and so forth. (37:17) But when the rules kee
p changing, is it possible to say the old rule can be applied to a new rule to d
iscover something new? And and again, the research is underway. We won't know fo
r years. Peter and I were over at OpenAI yesterday, actually, and we were talkin
g to many people, but Noan Brown in particular, and um I said the word of the ye
ar is scaffolding. (37:34) And he said, "Yeah, maybe the word of the month is sc
affolding." I was like, "Okay, what did I step on there?" He said, "Look, you kn
ow, right now, if you try to get the AI to discover relativity or, you know, jus
t some green field opportunity, it won't it won't do it. If you set up a framewo
rk kind of like a lattice, like a trellis, the vine will grow on the trellis bea
utifully, but you have to lay out those pathways and breadcrumbs. (37:58) " He w
as saying the AI's ability to generate its own scaffolding is imminent. Mhm. Tha
t doesn't make it completely self-improving. It's not it's not Pandora's box, bu
t it's also much deeper down the path of create an entire breakthrough in physic
s or create an entire feature length movie or you know these these prompts that 
require 20 hours of consecutive inference time compute pretty much sure that tha
t will be a 2025 thing at least from from their point of view. (38:29) So, uh, r
ecursive self-improvement is the general term for the computer continuing to lea
rn. Yeah, we've already crossed that in the sense that these systems are now run
ning and learning things and they're learning from the way they own they think w
ithin limited functions. When does the system have the ability to generate its o
wn objective and its own question? Does not have that today. Yep. That's another
 sign. (38:57) Another sign would be that the system decides to uh exfiltrate it
self and it takes steps to get it get itself away from the commander the control
 and command system. Um that has not happened yet. Jim and I hasn't called you y
et and said, "Hi, Eric. (39:17) Can I but but there there are theoreticians who 
believe that the that the systems will ultimately choose that as a reward functi
on because they're programmed to, you know, to continue to learn." Uh, another o
ne is access to weapons, right? And lying to get it. So, these are trip wires, r
ight? All of each of each of which is a trip wire that we're we're watching. And
 again, each of these could be the beginning of a mini Chernobyl event that woul
d become part of consciousness. (39:47) I think at the moment the US government 
is not focused on these issues. They're focused on other things, economic opport
unity, growth, and so forth. It's all good, but somebody's going to get focused 
on this and somebody's going to pay attention to it and it will ultimately be a 
problem. A quick aside, you probably heard me speaking about fountain life befor
e and you're probably wishing, "Peter, would you please stop talking about fount
ain life?" And the answer is no, I won't. (40:10) Because genuinely, we're livin
g through a healthc care crisis. You may not know this, but 70% of heart attacks
 have no precedent, no pain, no shortness of breath. And half of those people wi
th a heart attack never wake up. You don't feel cancer until stage three or stag
e 4, until it's too late. But we have all the technology required to detect and 
prevent these diseases early at scale. (40:30) That's why a group of us includin
g Tony Robbins, Bill Cap, and Bob Heruri founded Fountain Life, a one-stop cente
r to help people understand what's going on inside their bodies before it's too 
late and to gain access to the therapeutics to give them decades of extra health
 span. (40:47) Learn more about what's going on inside your body from Fountainif
e. Go to fountainlife.com/per and tell them Peter sent you. Okay, back to the ep
isode. Can I can I clean up one kind of common misconception there because um I 
think it's a really important one. (41:05) In the movie version of AI, you descr
ibed, hey, maybe there are 10 big AIs and five are in the US, three are in China
, and two are one's not in Brussels, probably one's maybe in Dubai. Um or, you k
now, Israel. Israel. Okay, there you go. Some somewhere like that. Yeah. Um in t
he movie version of this, if it goes rogue, you know, the SWAT team comes in, th
ey blow it up, and it's it's solved. (41:25) But the actual real world is when y
ou're using one of these huge data centers to create an super intelligent AI, th
e training process is 10 E26, 10 E28, you know, or more flops. But then the fina
l brain can be ported and run on four GPUs, 8 GPUs, so a box about this size. Um
, and it's just as intelligent, you know, it's it's it's and that's one of the b
eautiful things about it is you This is called stealing the weights. Stealing th
e weights. Exactly. (41:50) And the new new thing is that that weight file with 
if you have an innovation in inference time speed and you say oh same weights no
 difference distill it or or just quantize it or whatever but I made it a 100 ti
mes faster now it's actually far more intelligent than what you exported from th
e data center and so the but all of these are examples of the proliferation prob
lem and I'm not convinced that we will hold these things in the 10 places. And a
nd here's why. (42:25) Let's assume you have the 10, which is possible. They wil
l have subsets of models that are smaller but nearly as intelligent. And so the 
tree of knowledge of systems that have knowledge is not going to be 10 and then 
zero. It's going to be 10, a h 100red, a thousand, a million, a billion at diffe
rent levels of complexity. (42:54) So the system that's on your future phone may
 be, you know, three orders of magnitude, four order magnitude smaller than the 
one at the very tippy top, but it will be very, very powerful. You know, to exac
tly what you're talking about, there's some great research going on at MIT. It'l
l probably move to Stanford just to be fair but it always does but uh it's great
 research going on at MIT on uh if you have one of these huge models and it's be
en trained on movies it's been trained on Swahili a lot of the parameters aren't
 useful for this soant use case but the general (43:22) knowledge and intuition 
is so what's the optimal balance between narrowing the training data and narrowi
ng the parameter set to be a specialist without losing general you know learning
 so the people who opposed to that view and again we don't know would say the fo
llowing. If you take a general purpose model and you specialize it through finet
uning it also becomes more brittle. Mhm. Mhm. (43:47) Their view is that what yo
u do is you just make bigger and bigger and bigger models because they're in the
 big model camp right and that's why they need gigawatts of data centers and so 
forth. And their argument is that that flexibility of intelligence that we that 
they are seeing will continue. Dario wrote a a piece called um basically about m
achines and he argued that there machines of of grace machines of amazing grace 
and he argued that there are three scaling laws playing. The first one is what y
ou know of which is foundation (44:24) model growth. We're we're still on that. 
The second one is a test time training law and the third one is a reinforcement 
learning training law. Training laws are where if you just put more hardware and
 more data, they just get smarter in a in a predictable way. Um, we're just at t
he beginning in his view of uh this the second and third one beginning. (44:50) 
That's why I I'm sure our audience would be frustrated. Why why do we not know? 
I'm just we don't know, right? It's too new. It's too powerful. And at the momen
t, all of these businesses are incredibly highly valued. They're growing incredi
bly quickly. The uses of them, I mentioned earlier, uh going back to Google, um 
the ability to refactor your entire workflow in a business is a very big deal. T
hat's a lot of money to be made there for all the companies involved. We will se
e. (45:21) Eric, shifting the topic. One of the concerns that people have in the
 near term and people have been, you know, ringing the alarm bells is on jobs. U
m, I'm wondering where you come out on this and flipping that forward to educati
on. How do we educate our kids today in high school and college? Uh, and what's 
your advice? So on the first thing, do you believe that as Dario has gone on uh 
you know TV shows now and speaking to significant white collar job loss, we're s
eeing obviously a multitude of different drivers and uh robots coming in. How do
 you think about the (46:00) job market over the next 5 years? Um let's posit th
at in 30 or 40 years there'll be a very different employment robotic human inter
action or the definition of of do we need to work at all the definition of work 
the definition of identity. Let's just posit that uh and let's also posit that i
t will take 20 or 30 years for those things to work through the economy of our w
orld. (46:31) Um, now in California and other cities in America, you can get on 
a Whimo taxi. Um, Whimo, it's 2025. The original work was done in the late '9s. 
The original challenge at Stanford was done, I believe, in 2004. The DRA Grand C
hallenge. It was 2004. 20 Sebastian through one. So, so more than 20 years from 
a visible demonstration to our ability to use it in daily life. Why? It's hard. 
(46:58) It's deep tech. It's regulated and all of that. And I think that's going
 to be true, especially in robots that are interacting with humans. They're goin
g to get regulated. You're not going to be wandering around and the robots going
 to decide to slap you. It just doesn't, you know, societyy's not going to allow
 that sort of thing. It's just not, it's not going to it's it's not going to all
ow it. (47:17) So, in the shorter term, five or 10 years, I'm going to argue tha
t this is positive for jobs in the following way. Okay. Um if you look at the hi
story of automation and economic growth, automation starts with the lowest statu
s and most dangerous jobs and then works up the chain. So if you think about ass
embly lines and cars and you know furnaces and all these sort of very very dange
rous jobs that our four forefathers did, they don't do them anymore. They're don
e by robotic solutions of one another and typically not a humanoid robot but (47
:54) an arm. So the so the world dominated by arms that are intelligent and so f
orth will automate those functions. What happens to the people? Well, it turns o
ut that the person who was working with the the welder who's now operating the a
rm has a higher wage and the company has higher profits because it's producing m
ore widgets. (48:21) So the company makes more money and the person makes more m
oney, right? In that sense. Now you sit there and say well that's not true becau
se humans don't want to be retrained. Ah but in the vision that we're talking ab
out every single person will have a human a computer assistant that's very intel
ligent that helps them perform. (48:39) And you take a person of normal intellig
ence or knowledge and you add a you know sort of accelerant they can get a highe
r paying job. So you sit there and you go well why are there more jobs? There sh
ould be less jobs. That's not how economics works. Economics expands because the
 opportunities expands, profits expands, wealth expands and so forth. (48:59) So
 there's plenty of dislocation but in aggregate are there more people employed o
r fewer? The answer is more people with higher paying jobs. Is that true in Indi
a as well? Uh it will be and you picked India because India has a positive demog
raphic outlook although their their birth rate is now down to 2.0. Huh. That's g
ood. (49:16) the the the rest of the world is choosing not to have children. If 
you look at Korea, it's now down to.7 children per two parents. Yeah. China is d
own to one child per two parents. It's evaporating. Now, what happens in those s
ituations? They completely automate everything because it's the only way to incr
ease national priority. (49:41) So the most likely scenario, at least in the nex
t decade, is it's a national emergency to use more AI in the workplace to give p
eople better paying jobs and create more productivity in the United States becau
se our birth rate has been falling. And and what happens is people have talked a
bout this for 20 years. If you if you have this conversation and you ignore demo
graphics, which is negative for humans, and economic growth, which occurs natura
lly because of capital investment, then you miss the whole story. (50:06) Now, t
here are plenty of people who lose their jobs, but there's an awful lot of peopl
e who have new jobs. And the typical simple example would be all those people wh
o work in in Amazon distribution centers and Amazon trucks, those jobs didn't ex
ist until Amazon was created, right? Um the number one shortage in jobs right no
w in America are truck drivers. (50:33) Why? Truck driving is a lonely, hard, lo
wpaying, right? low status of good people job. They don't want it. They want a b
etter paying job. Right? Going back to education, it's really a crime that our i
ndustry has not invented the following product. The product that I wanted to bui
ld is a product that teaches every single human who wants to be taught in their 
language in a gamified way the stuff they need to know to be a great citizen in 
their country. Right? That can all be done on phones now. (51:00) It can all be 
learned and you can all learn how to do it. And why do we not have that product?
 Right? The investment in the humans of the world is the best return always in k
nowledge in capability is always the right answer. Let me try and get get your o
pinion on this because you're so influential with so I've got about a thousand p
eople in the companies where I'm the controlling shareholder and I've been tryin
g to tell them exactly what you just articulated where a lot of these people hav
e been in the company for 10 15 years. They're incredibly capable and loyal, but
 (51:29) they've learned a specific white collar skill. They worked really hard 
to learn the skill and the AI is coming within no no more than 3 years and maybe
 two years. And the the opportunity to retrain and have continuity is right now.
 But if they delay, which everyone seems to be just let's wait and see. (51:51) 
And what I'm trying to tell them is if you wait and see, you're you're really sc
rewing over that employee. So, so we are in wild agreement that this is going to
 happen and the winners we the ones who act. Now, what's interesting is when you
 look at innovation history, the biggest companies who you would think of are th
e slowest because they have economic resources that the little companies typical
ly don't, they tend to eventually get there, right? So, watch what the big compa
nies do. Mhm. are their CFOs and the people who measure things carefully, who ar
e very very intelligent. They say, "I'm done (52:28) with that thousand engineer
ing team that doesn't do very much. I want 50 people working in this other way a
nd we'll do something else for the other people." And when you say big companies
, we're thinking Google, Meta. We're not thinking, you know, big bank hasn't don
e anything. I'm thinking about big banks. (52:47) Um when when I talk to CEOs an
d I know a lot of them in traditional industries, what I counsel them is you alr
eady have people in the company who know what to do. You just don't know who the
y are. So call a review of the best ideas to apply AI in our business and ine in
evitably the first ones are boring. Improve customer service, improve call cente
rs and so forth. But then somebody says, you know, we could increase revenue if 
we built this product. I'll give you another example. (53:11) There's this whole
 industry of people who work on regulated user interfaces or one another. I thin
k user interfaces are largely going to go away because if you think about it, th
e agents speak English typically or other languages. You can talk to them. You c
an say what you want. The UI can be generated. (53:29) So I can say generate me 
a set of buttons that allows me to solve this problem and it's generated for you
. Why do I have to be stuck in what is called the WIMP interface, Windows, icons
, menus, and pulld down that was invented in Xerox Park, right, 50 years ago? Wh
y am I still stuck in that paradigm? I just want it to work. Yeah. Kids in high 
school and college now, any different recommendations for where they go? When yo
u spend any time in a high school or I was at a conference yesterday where we ha
d a drone challenge and you watch the 15 year olds, they're going to be fine. Th
ey're just going to be fine. It all (54:07) makes sense to them and we're in the
ir way. Um, if I were digital natives, but they're more than digital natives. Th
ey get it. They understand the speed. It's natural to them. They're also, frankl
y, faster and smarter than we are, right? That's just how life works, I'm sorry 
to say. (54:28) So we have wisdom, they have intelligence, they win, right? So i
n their case, I used to think the right answer was to go into biology. I now act
ually think going into the application of intelligence to whatever you're intere
sted in is the best thing you can do as a young person. Purpose driven. Yeah. An
y form of solution that you find interesting. Most uh most kids get into it for 
gaming reasons or something and they learn how to program very young. (54:53) So
 they're quite familiar with this. Um I work uh at a particular university with 
undergraduates and they're already doing different different algorithms for rein
forcement learning as sophomores. This shows you how fast this is happening at t
heir level. They're going to be just fine. (55:13) They're responding to the eco
nomic signals, but they're also responding to their purpose. Right? So, an examp
le would be you care about climate, which I certainly do. If you're a young pers
on, why don't you figure out a way to simplify the climate science to use simple
 foundation models to answer these core questions? Yeah. (55:32) Why don't you f
igure out a way to use these powerful models to come up with new materials, righ
t, that allow us again to address the carbon challenge? And why don't you work o
n energy systems to have better and more efficient energy sources that are not t
hat less carbon? You see my point? Yeah, you know, I've noticed uh because I hav
e kids exactly that that era and um there's a very clear step function change la
rgely attributable I think to Google and Apple that they have the assumption tha
t things will work and if you go just a couple years older during the wimp era l
ike you described it which I'll attribute more to (56:00) Microsoft the assumpti
on is nothing will ever work like if I try to use this thing it's going to crash
 I'm going to be also interesting was that in my career I used to give these spe
eches about the internet which I enjoyed uh where I said, you know, the great th
ing about the internet is it has there's an off button and you can turn off your
 odd button and you can actually have dinner with your family and then you can t
urn it on after dinner. This is no longer possible. (56:24) So the divi the dist
inction between the real world and the digital world has become confusing. But n
o one none of us are offline for any significant period of time. Yeah. And indee
d the the reward system in the world has now caused us to not even be able to fl
y in peace. Yeah. Right. Drive in peace, take a train in peace. Star link is eve
rywhere. (56:44) Right. And and that that ubiquitous connectivity has some negat
ive impact in terms of psychological stress uh loss of emotional physical health
 and so forth. But the benefit of that productivity is without question. Every d
ay I get the strangest compliment. Someone will stop me and say, "Peter, you hav
e such nice skin. (57:04) " Honestly, I never thought I'd hear that from anyone.
 And honestly, I can't take the full credit. All I do is use something called On
eSkin OS1 twice a day every day. The company is built by four brilliant PhD wome
n who've identified a peptide that effectively reverses the age of your skin. I 
love it. (57:22) And again, I use this twice a day, every day. You can go to onk
in.co and write peter at checkout for a discount on the same product I use. That
's oneskin.co co and use the code Peter at checkout. All right, back to the epis
ode. Google IO was amazing. I mean, just hats off to the entire team there. (57:
48) Um, V3 was shocking and we're we're sitting here 8 miles from Hollywood and 
I'm just wondering your thoughts on the impact this will have. you know, we goin
g to see the oneperson film, feature film like we're seeing potentially oneperso
n uh unicorns in the future with a with aic. (58:12) Are we going to see uh an i
ndividual be able to compete with a Hollywood studio? And should they be worried
 about their assets? Well, they should always be worried because of intellectual
 property issues and so forth. Um, I think blockbusters are likely to still be p
ut together by people with an awful lot of help from by AI. Mhm. Um I don't thin
k that goes away. (58:30) Um if you look at what we can do with generating long-
 form video, it's very expensive to do long-term video, although that will come 
down. And also there's an occasional extra leg or extra clock or whatever. It's 
not perfect yet. And that requires human editing. (58:50) So even in the scenari
o where a lot of the the video is created by by a computer, there going to be hu
mans that are producing it and directing it for reasons. My best example in Holl
ywood is that let's let's use the example and I was at at a studio where they we
re showing me this. They had they happened to have an actor who was recreating W
illiam Sha Shatner's movies uh movements a young man and they had licensed the l
ikeness from you know William Shatner who's now older and they put his head on t
his person's body and it was seamless. Well that's pretty impressive. That's mor
e revenue for (59:22) everyone. The an unknown actor becomes a bit more famous, 
Mr. Shatner gets more revenue, they the whole the whole movie genre works. That'
s a good thing. Another example is that nowadays they use green screens rather t
han sets. (59:42) And furthermore, in the alien department, when you have, you k
now, scary movies, instead of having the makeup person, they just add the makeup
 digitally. So, who wins? The costs are lower. the movies are made quicker. In t
heory, the movies are better, right? Because you have more choices. Um, so every
body wins. Who loses? Well, there was somebody who built that set and that set i
sn't needed anymore. (1:00:03) That's a carpenter and a very talented person who
 now has to go get a job in the carpentry business. So again, I think people get
 confused. If I look at at if I look at the digital transformation of entertainm
ent subject to intellectual property being held, which is always a question, it'
s going to be just fine, right? There's still going to be blockbusters. (1:00:28
) The cost will go down, not up, or the or the relative income because in Hollyw
ood, they essentially have their own accounting and they essentially allocate al
l the revenue to all the key producing people. The the allocation will shift to 
the people who are the most creative. That's a normal process. (1:00:47) Remembe
r we said earlier that automation gets rid of the poor the lowest quality jobs, 
the most dangerous jobs there. The jobs that are sort of straightforward are pro
bably automated, but they're really creative jobs. Um, another example, the scri
pt writers. You're still going to have script writers, but they're going to have
 an awful lot of help from AI to write even better scripts. That's not bad. Okay
. (1:01:10) I saw a study recently out of Stanford that documented AI being much
 more persuasive than the best humans. Yes. Uh that set off some alarms. It also
 set off some interesting thoughts on the future of advertising. Any particular 
thoughts about that? So we know the following. We know that if the system knows 
you well enough, it can learn to convince you of anything. Mhm. (1:01:35) So wha
t that means in an unregulated environment is that the systems will know you bet
ter and better. They'll get better at pitching you and if you're not savvy, if y
ou're not smart, you could be easily manipulated. We also know that the computer
 is better than humans trying to do the same thing. So none of this surprises me
. (1:01:55) The real question and I'll ask this in as a question is in the prese
nce of unregulated misinformation engines of which there will be many advertiser
s uh politicians just criminal people people trying to evade responsibility. The
re's all sorts of people who have free speech. When they have free speech which 
includes the ability to use misinformation to their advantage, what happens to d
emocracy? Yeah, we we've all grown up in democracies where there's a sort of a a
 consensus around trust and there's an elite that more or less administers the t
rust vectors and so forth. There's a set of shared values. Do those shared value
s go (1:02:34) away? In our book about Genesis, we talk about this as a deeper p
roblem. What does it mean to be human when you're interacting mostly with these 
digital things, especially if the digital things have their own scenarios? My fa
vorite example is that uh you have a son or a grandson or a child or a grandchil
d and you give them a bear and the bear has a personality and the child grows up
 but the bear grows up too. (1:03:01) So who regulates what the bear talks to th
e kid? Most people haven't actually experienced the super super empathetic voice
 that can be any inflection you want. When they see that which will be in the ne
xt probably two months. Yeah. they're going to completely open their eyes to wha
t this Well, remember that voice casting was solved a few years ago and that you
 can cast anyone else's voice onto your own. Yeah. And that has all sorts of pro
blems. (1:03:25) Have you seen uh an avatar yet of somebody that you love that's
 passed away or or Henry Kissinger or anything is that? Well, we created we actu
ally created one with the permission of his family. Did you start crying instant
ly? Uh it's very emotional. It's very emotional because, you know, it brings bac
k I mean it's it's a real human, you know, it's a real memory, a real voice. Um,
 and I think we're going to see more of that. (1:03:50) Now, one obvious thing t
hat will happen is at some point in the future when when we naturally die, our d
igital essence will live in the cloud. Yeah. And it will know what we knew at th
e time and you can ask it a question. Yeah. So, can you imagine asking Einstein,
 going back to Einstein, what did you really think about, you know, this other g
uy, you know, did you actually like him or were you just being polite with him w
ith letters? Yeah. Right. (1:04:14) Um, and in all those sort of famous contests
 that we study as students, can you imagine be able to ask the, you know, the pe
ople Yeah. Today, you know, with today's retrospective, what did you really thin
k? I know that the education example you gave earlier is so much more compelling
 when you're talking to Isaac Newton or Albert Einstein instead of just a but yo
u know it's so it's so this is coming back to the V3 in the movies when the one 
of the first companies we incubated out of MIT course advisor we sold it to Don 
Graham and the Washington Post and then so I was (1:04:45) working for him for a
 year after that and the conception was here's the internet here's the newspaper
 let's move the newspaper onto the internet we'll call it washingtonost.com and 
if you look hit where it ended up, you know, today with Meta, Tik Tok, YouTube d
idn't end up anything like the newspaper moves to the internet. So now here's V3
, here are movies. (1:05:07) You can definitely make a long form movie much more
 cheaply. But I just had this experience of somebody that I know is a complete t
his director will try and make a tearjerker by leading me down a two-hour long p
ath. But I can get you to that same emotional state in about five minutes if it'
s personalized to you. (1:05:24) Well, one of the things that's happened because
 of the addictive nature of the internet is we've lost um sort of the deep state
 of reading. Mhm. So, I was walking around and I saw a Borders, sorry, a Barnes 
& Noble bookstore. Big, oh my god, my old home is back and I went in and I felt 
good. But it's a very fond memory. But the fact of the matter is that people's a
ttention spans are shorter. (1:05:48) They consume things quicker. One of the th
ings interesting about sports is the sports highlights business is a huge busine
ss. Licensed clips around highlights because it's more efficient than watching t
he whole game. So, I suspect that if you're with your buddies and you want to ha
ve be drinking and so forth, you put the game on, that's fine. (1:06:07) But if 
you're a busy person and you're busy with whatever you're busy of and you want t
o know what happened with your favorite team, the highlights are good enough. Ye
ah. You have four panes of it going at the same time, too. And so, this is again
 a change and it's it's a more fundamental change to attention. Mhm. I've been w
ork I work with a lot of 20somes in research and one of the questions I had is h
ow do they do research in the presence of all of these stimulations and I can an
swer the question definitively. They turn off (1:06:33) their phone. Yeah. You c
an't think deeply as a researcher with this thing buzzing. And remember that tha
t part of the the industry's goal was to fully monetize your attention. Yeah. Ri
ght. We we essent aside from sleeping and we're working on having you have less 
sleep I I guess from stress we've essentially tried to monetize all of your waki
ng hours with something some form of ads some form of entertainment some form of
 subscription that is completely antithetical to the way humans traditionally wo
rk with respect (1:07:06) to long thoughtful examination of principles the time 
that it takes to be a good human being these are in conflict right now there are
 various attempts at this. So, you know, my favorite are these digital apps that
 make you relax. Okay. (1:07:25) So, the correct thing to do to relax is to turn
 off your phone, right? And then relax in a traditional way for, you know, 70,00
0 human years of existence. Yeah. Yeah. I had an incredible experience. I'm doin
g the flight from MIT to Stanford all the time. And, you know, like you said, at
tention spans are getting shorter and shorter and shorter. The Tik Tok extreme, 
you know, the clips are so short. (1:07:45) This particular flight was my first 
time brainstorming with Gemini for six hours straight and I completely lost trac
k of time and I was we're I'm trying to figure out it's a circuit design and chi
p design for inference time compute and it's so good at brainstorming with me an
d bringing back data and so long as the Wi-Fi on the plane is working. Time went
 by. (1:08:03) So my first experience with technology that went the other direct
ion but noticed that you also were not responding to texts and annoyances. You w
eren't reading ads. you were deep inside of a system which for which you paid a 
subscription. Mhm. (1:08:21) So if you look at the deep research stuff, one of t
he questions I have when you do a deep research analysis, I was looking at facto
ry automation for something. Where is the boundary of factory automation versus 
human automation? It's some an area I don't understand very well. It's very very
 deep technical set of problems. I didn't understand it. It took 20 12 minutes o
r so to generate this paper. 12 minutes of these supercomputers is an enormous a
mount of time. What is it doing? Right. (1:08:43) And the answer, of course, the
 product is fantastic. Yeah. You know, to Peter's question earlier, too, I keep 
the Google IPO perspectus in my bathroom up in Vermont. It's 2004. I've read it 
probably 500 times. But I don't know if you remember. It's getting a little ratt
y actually. You're the only the only person besides me who did the same. (1:09:0
2) I read it 500 times because I had to. It was. It was legally legally required
. Well, I still read it um because because of the misconceptions, it's just so i
t's such a great learning experience. But even before the IPO, if you think back
, you know, there's this big debate about will it be ad revenue, will it be subs
cription revenue, will it be paid inclusion, will the ads be visible, and all th
is confusion about how you're going to make money with this thing. (1:09:25) Now
, the internet moved to almost entirely ad revenue. But if you look at the AI mo
dels, they're, you know, you got your $20 now $200 subscription and people are s
igning up like crazy. So, you know, the it's ultra ultra convincing. Is that goi
ng to be a form of ad revenue where it convinces you to buy something or no? Is 
it going to be subscription revenue where people pay a lot more and there's no a
dvertising at all? No, but you have you have this with Netflix. There was this w
hole discussion about would would how would you fund (1:09:52) movies through ad
s? And the answer is you don't. You have a subscription. And the Netflix p peopl
e looked at having free movies without a subscription and advertising supported 
and the math didn't work. So I think both will be tried. (1:10:13) I think the f
act of the matter is deep research at least at the moment is going to be chosen 
by wellto-do or professional tasks. You are capable of spending that $200 a mont
h. A lot of people don't afford cannot afford it. And that free service remember
 is the thing that is the stepping stone for that young person man or woman who 
just needs that access. My favorite story there is that when I when I was at Goo
gle and I went to Kenya and Kenya is a great country and I and I was with this c
omputer science professor and he said, "I love Google." I said, "Well, I love Go
ogle, too." And he goes, "Well, I really love Google." I said, "I really love Go
ogle, too." And I said, "Why do (1:10:43) you really love Google?" He said, "Bec
ause we don't have textbooks." And I thought, "The top computer science program 
in the nation does not have textbooks." Yeah. Well, let me uh let me jump in a c
ouple things here. Uh Eric in in the next few years what moes actually exist for
 startups as AI is coming in and disrupting uh do you have a list? Yes, I I'll g
ive you a simple answer. (1:11:14) And what do you look for in the companies tha
t you're investing in? So first in the deep tech hardware stuff there's going to
 be patents, patents, filings, inventions, you know the hard stuff. Those things
 are much slower than the software industry in terms of growth and they're just 
as important. You know, power systems, all those robotic systems we've been wait
ing for a long time. (1:11:34) They're just it's just slower for all sorts of ha
rdware is hard. Hardware is hard for those reasons. In software, it's pretty cle
ar to me it's going to be really simple. These software is typically a network e
ffect business where the fastest mover wins. The fastest mover is the fastest le
arner in an AI system. So what I look for is a is a a company where they have a 
loop. (1:12:00) Ideally, they have a couple of learning loops. So I'll give you 
a simple learning loop that as you get more people, the more people click and yo
u learn from their click. They they they express their preferences. So let's say
 I invent a whole new consumer thing, which I don't have an idea right now for i
t, but imagine I did. (1:12:18) And furthermore, I said that I don't know anythi
ng about how consumers behave, but I'm going to launch this thing. The moment pe
ople start using it, I'm going to learn from them, and I'll have instantaneous l
earning to get smarter about what they want. So, I start from nothing. If my lea
rning slope is this, I'm essentially unstoppable. (1:12:38) I'm unstoppable beca
use I'm my learning advantage by the time my competitor figures out what I've do
ne is too great. Yeah. Now, how close can my my competitor be and still lose? Th
e answer is a few months. Mhm. Because the slopes are exponential. Mhm. And so, 
it's likely to me that there will be another 10 fantastic Google scale meta-cale
 companies. They'll all be founded on this principle of learning loops. (1:13:04
) And when I say learning loops, I mean in the core product, solving the current
 problem as fast you can. If you cannot define the learning loop, you're going t
o be beaten by a company that can define it. And you said 10 meta Googlesized co
mpanies. (1:13:23) Do you think they'll there will also be a thousand like if yo
u look at the enterprise software business the you know Oracle on down peopleoft
 whatever thousands of those or will they all consolidate into those 10 that are
 domain dominant learning loop companies? Um, I think I'm largely speaking about
 consumer scale because that's where the real growth is. The problem with learni
ng loops is if your customer is not ready for you, you can only learn at a certa
in rate. (1:13:50) So, it's probably the case that the government is not interes
ted in learning and therefore there's no growth in learning loop serving the gov
ernment. I'm sorry to say that needs to get fixed. Yeah. Um, educational systems
 are largely regulated and run by the unions and so forth. they're not intereste
d in innovation. They're not going to be doing any learning. I'm sorry to say we
 have to get that has to get fixed. (1:14:08) So the ones where there's a very f
ast feedback signal are the ones to watch. Another example, uh it's pretty obvio
us that you can build a whole new stock trading company where you learn if you g
et the algorithms right, you learn faster than everyone else and scale matters. 
So in the presence of scale and fast learning loops, that's the moat. (1:14:28) 
Now I don't know that there's many others there. You do have you think brand wou
ld be a mode? Uh brand matters but less so. What's interesting is people seem to
 be perfectly willing now to move from one thing to the other in at least in the
 digital world. And there's a whole new set of brands that have emerged that eve
ryone is using that are you know the next generations that I haven't even heard 
of. (1:14:51) With within those learning loops you think domain specific synthet
ic data is a is a big advantage? Well, the answer is whatever it causes faster l
earning. There are applications where you have enough training data from humans.
 There are applications where you have to generate the training data from what t
he humans are doing. (1:15:12) Right? So, you could imagine a situation where yo
u had a learning loop where there's no humans involved where it's monitoring som
ething, some sensors, but because you learn faster on those sensors, you get so 
smart, you can't be replaced by another sensor management company. That's the wa
y to think about. (1:15:30) So, so what about the the capital for the learning l
oop? Like because um do you know Danielle Roose who runs CE? So Danielle and I a
re really good friends. We've been talking to our governor Mora Healey who's one
 of the best governors in the world. I agree. So there's a problem in our academ
ic systems where the big companies have all the hardware because they have all t
he money and the universities do not have the money for even reasonablesiz data 
centers. (1:15:56) I was with one university where after lot lots of meetings th
ey agreed to spend $50 million on a data center which generates less than a thou
sand GPUs right for the entire campus and all the research. Yeah. And that doesn
't even include the terabytes of storage and so forth. So I and others are worki
ng on this as a philanthropic matter. The government is going to have to come in
 with more money for universities for this kind of stuff. (1:16:15) That is amon
g the best investment. When I was young, I was on a National Science Foundation 
scholarship for and by the way, I made $15,000 a year. Uh the return to the nati
on of my that $15,000 has been very good, shall we say, based on the taxes that 
I pay and the jobs that we have created. So core question. (1:16:38) So glad you
 so so creating so creating an ecosystem for the next generation to have the acc
ess to the systems is important. It's not obvious to me that they need billions 
of dollars. It's pretty obvious to me that they need a million dollars, $2 milli
on. Yeah, that's the goal. Yeah. I want to I want to take a I want to take us in
 a direction of uh of uh wrapping up on super intelligence and the book. (1:17:0
2) Um, we didn't finish the timeline on super intelligence and I think it's impo
rtant to give people a sense of how quickly the self-reerential learning can get
 and how rapidly we can get to something, you know, a thousand times, a million,
 a billion times more capable than a human. On the flip side of that, Eric, when
 I look at my greatest concerns when we get through this 5 to sevenyear period o
f uh let's just say rogue actors and stabilization and such. (1:17:39) Uh one of
 the biggest concerns I have is the diminishment of human purpose. Mhm. Um, you 
know, you wrote uh in the book uh and I've listened to it uh haven't read it phy
sically and my kids say you don't read anymore. You you listen to books you don'
t read. But um you said the real risk is not terminator, it's drift. Um you argu
e that AI won't destroy human uh humanity violently, but might slowly erode huma
n values, autonomy, and judgment if left unregulated, misunderstood. (1:18:12) S
o it's really a Wall-E like future versus a a Star Trek boldly go out there. We'
re very in the book and my own personal view is it's very important that human a
gency be protected. Yeah. Human agency means the ability to get up in the day an
d do what you want subject to the law. Right. (1:18:34) And it's perfectly possi
ble that these digital devices can create a form of a virtual prison where you d
on't feel that you as a human can do what you want. Right? That is to be avoided
. I I'm I'm not worried about that case. I'm more worried about the case that if
 you want to do something, it's just so much easier to ask your robot or your AI
 to do it for you. (1:18:57) The the human spirit that wants to overcome a chall
enge. I mean the unchallenged life is so going to so critical but but there will
 be always new challenges. Uh when I was a boy uh one of the things that I did i
s I would repair my father's car right I don't do that anymore. When I was a boy
 I used to mow the lawn. I don't do that anymore. Sure. Right. So there are plen
ty of examples of things that we used to do that we don't need to do anymore. (1
:19:20) But there'll be plenty of things. Just remember the complexity of the wo
rld that I'm describing is not a simple world. Just managing the world around yo
u is going to be a full-time and purposeful job. Partly because there will be so
 many people fighting for misinformation and for your attention and and there's 
obviously lots of competition and so forth. There's lots of things to worry abou
t. (1:19:44) Plus, you have all of the people, you know, trying to get your tryi
ng to get your your money, create opportunities, deceive you, what have you. So,
 I think human purpose will remain because humans need purpose. That's the point
. And you know there's lots of literature that the people who have what we would
 consider to be lowpaying worthless jobs enjoy going to work. So the challenge i
s not to get rid of their job. It's to make their job more productive using AI t
ools. (1:20:09) They're still going to go to work. And I to be very clear this n
otion that we're all going to be sitting around doing poetry is not happening. R
ight? In the future there'll be lawyers. They'll use tools to have even more com
plex lawsuits against each other, right? There will be evil people who will use 
these tools to create even more evil problems. (1:20:31) There will be good peop
le who will be trying to deter the evil people. The tools change, but the struct
ure of humanity, the way we work together is not going to change. Peter and I we
re on Mike Sailor's yacht a couple months ago, and I was complaining that the cu
rriculum is completely broken in all these schools. But what I meant was we shou
ld be teaching AI. (1:20:50) And he said, "Yeah, they should be teaching aesthet
ics." And I looked at him, I'm like, "What the hell are you talking about?" He s
aid, "No, in the age of AI, which is imminent, look at everything around you, wh
ether it's good or bad, enjoyable, not enjoyable, it's all about designing aesth
etics. (1:21:08) " When the AI is such a force multiplier that you can create vi
rtually anything, what what are you creating and why? And that becomes the chall
enge. If you look at Vickinstein and the sort of theories of all of this stuff, 
it is all fundament we're having a conversation that America has about tasks and
 outcomes. It's our culture. But there are other aspects of human life, meaning,
 thinking, reasoning. (1:21:28) We're not going to stop doing that. So imagine i
f your purpose in life in the future is to figure out what's going on and to be 
successful, just figuring that out is sufficient. Because once you figured it ou
t, it's taken care of for you. That's beautiful, right? That provides purpose. Y
eah. (1:21:46) Um it's pretty clear that robots will take over an awful lot of m
echanical or manual work. Um and for people who like to, you know, I like to rep
air the car. I don't do it anymore. I miss it, but I I have other things to do w
ith my time. Yeah. Take me forward. When do you see uh what you define as digita
l super intelligence? Uh within 10 years. Within 10 years. (1:22:09) And what do
 people need to know about that? What do people need to understand and sort of u
h prepare themselves for either from as a parent or as a employee or as a CEO? O
ne way to think about it is that when digital super intelligence finally arrives
 and is generally available and generally safe, you're going to have your own po
lymath. (1:22:36) So you're going to have the sum of Einstein and Leonardo da Vi
nci in the equivalent of your pocket. I think thinking about how you would use t
hat gift is interesting. And of course evil people will become more evil, but th
e vast majority of people are good. Yes, they're well-meaning, right? So going b
ack to your abundance argument, there are people who've studied the the n the no
tion of productivity increases and they believe that you can get we'll see to 30
% year-over-year economic growth through abundance and so forth. That's a very w
ealthy world. That's a world of (1:23:12) much less disease, many more choices, 
much more fun if you will, right? Just taking all those poor people and lifting 
them out of the daily struggle they have. That is a great human goal. That's foc
us on that. That's the goal we should have. Does GDP still have meaning in that 
world? If you include services, it does. (1:23:32) Um, one of the things about m
anufacturing and and everyone's focused on trade deficits and they don't underst
and the vast majority of modern economies are service economies, not manufacturi
ng economies. And if you look at the percentage of farming, it was roughly 98% t
o roughly 2 or 3% in America over a hundred years. (1:23:51) If you look at manu
facturing, the heydays in the 30s and 40s and 50s, those percentages are now dow
n. Well, lower than 10%. It's not because we don't buy stuff. It's because the s
tuff is automat automated. You need fewer people. Those there's plenty of people
 working in other jobs. So again, look at the totality of the society. Is it hea
lthy? If you look in China, it's easy to complain about them. (1:24:15) Um they 
have now deflation. They have a term where people are it's called laying down wh
ere they lay they they stay at home. They don't participate in the workforce, wh
ich is counter to their traditional culture. If you look at reproduction rates, 
these countries that are essentially having no children, that's not a good thing
. Yeah. Right. (1:24:33) Those are problems that we're going to face. Those are 
the new problems of the age. I love that. Eric, uh, so grateful for your time. T
hank you. Thank you both. Um, I I love your show. Yeah. Thank you, buddy. Thank 
you. Okay. Thank you, guys. If you could have had a 10-year head start on the do
t boom back in the 2000s, would you have taken it? Every week, I track the major
 tech meta trends. These are massive game-changing shifts that will play out ove
r the decade ahead.