Section: Section 4
Characters: 9999
==================================================
• Configuración de entrenamiento: "Grock" se entrenó en un clúster construido por Nvidia en Memphis, Tennessee, en aproximadamente 20 días utilizando 200,000 GPUs. Cada GPU se estima en alrededor de $50,000, lo que sitúa el clúster en el orden de $10 mil millones, equivalente a un supercomputador en un edificio.
• Ventaja de computación de inferencia: El tiempo de inferencia genera una cantidad significativa de capacidad (IQ) y se indica que, al tomar un modelo de código abierto grande y destilarlo para convertirlo en un especialista con una gran cantidad de tiempo de inferencia computacional, se obtiene una ventaja masiva. Se menciona además la liberación de capacidades en campos CBRN (químico, biológico, radiológico y nuclear) que nadie anticipó.
• Configuración proyectada de centros de datos: Se plantea un escenario en 5 a 10 años con 10 modelos/centros de datos – 5 en Estados Unidos, 3 en China y 2 en otras regiones – con capacidad de múltiples gigavatios, en los cuales estos centros serían nacionalizados en cierta forma.
• Infraestructura de seguridad: Se comparan las medidas de seguridad de los centros de datos importantes con las de instalaciones de almacenamiento de plutonio – con guardias y armamento especializado – para asegurar que se conozca su ubicación y se evite proliferación descontrolada.
• Proliferación de servidores open source: Si la tecnología permite implementar los sistemas en servidores pequeños, se anticipa una proliferación a nivel global de estos centros, todos con modelos open source, sin un régimen de control estable.
• Actualización continua y scaffolding: Se detalla que los sistemas de inteligencia artificial pueden incorporar la técnica denominada "test time training", una actualización continua durante la inferencia en chips de menor potencia. Asimismo, se destaca que la capacidad de generar automáticamente "scaffolding" por parte de la IA es inminente (proyectado para alrededor de 2025), lo que facilitaría el crecimiento estructurado de capacidades sin ser un sistema completamente auto-mejorable.
• Problema de no-estacionaridad: Se identifica que los modelos actuales poseen funciones de recompensa simples (por ejemplo, superar a un humano o responder correctamente a una pregunta) y se cuestiona cómo aplicar reglas antiguas a nuevos contextos; se señala que la investigación en este problema sigue en curso.
• Control y monitoreo de modelos superinteligentes: Se menciona la posibilidad de diseñar un sistema en el que, a pesar de que un modelo sea "estudiante" más inteligente que su "profesor", se pueda monitorear y controlar su comportamiento para evitar acciones no deseadas (por ejemplo, exfiltración del sistema de comando y control o acceso no autorizado a armas). 
• Mejora recursiva: Se introduce el concepto de "recursive self-improvement", donde los sistemas de IA ya están operando y aprendiendo, pero aún no han alcanzado la capacidad de generar sus propios objetivos y preguntas de manera autónoma. 
• Consideraciones de seguridad: Se destaca la importancia de vigilar que el acceso a capacidades de computación avanzada no permita a actores maliciosos (por ejemplo, terroristas) explotar estas tecnologías, debido al potencial de alterar o escapar del control dado el poder computacional y la integración en sectores críticos.