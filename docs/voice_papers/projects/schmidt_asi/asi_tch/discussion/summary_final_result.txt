# Título: "Ex-Google CEO: What Artificial Superintelligence Will Actually Look Lik"

## I. Predicciones de Superinteligencia Digital  
- La superinteligencia digital estará disponible en 10 años.  
- La inteligencia artificial generará su propio scaffolding, proyectado para alrededor de 2025.  
- La capacidad intelectual se equiparará a la de un polímata, combinando las habilidades de Einstein y Leonardo da Vinci.

## II. Infraestructura Nuclear y Requerimientos de Energía  
- Se requiere potencia adicional de 92 gigavatios en Estados Unidos (1 gigavatio ≈ salida de una gran central nuclear).  
- Meta tiene un contrato nuclear de 20 años con Constellation Energy.  
- Google, Microsoft y Amazon están adquiriendo capacidad nuclear.  
- En los últimos 30 años se han construido dos plantas nucleares.  
- Se planea un reactor modular pequeño (SMR) de 300 megavatios con operación a partir de 2030.

## III. Sistemas GPU y Centros de Datos  
- El modelo “Grock” se entrenó en un clúster de Nvidia en Memphis, Tennessee, durante aproximadamente 20 días utilizando 200,000 GPUs.  
- Cada GPU tiene un costo aproximado de US$50,000.  
- El clúster “Grock” tiene un costo aproximado de US$10 mil millones, equivalente a un supercomputador en un edificio.  
- Se requieren cientos de miles de chips de alto rendimiento (ej. Blackwell, AMD’s 350) para operar un centro de datos.  
- Se considera que centros de datos con capacidades de 1 gigavatio son esenciales para las funciones de “supercerebro” digital.

## IV. Arquitecturas de IA y Métodos de Aprendizaje  
- La arquitectura transformer se actualiza con variantes optimizadas para inferencia.  
- Startups desarrollan cómputo de inferencia de menor complejidad.  
- El “test time training” implica actualización continua de modelos durante la inferencia en chips de menor potencia.  
- La técnica de distillation utiliza un modelo grande para generar 10,000 preguntas y emplear las respuestas como material de entrenamiento.  
- La técnica “stealing the weights” exporta los pesos del modelo para posteriores procesos de distilación o cuantización, mejorando la velocidad de inferencia (aceleración de hasta 100×).  
- Se introduce la noción de “recursive self-improvement”, en la que los sistemas de IA aprenden continuamente sin generar de forma autónoma sus propios objetivos.  
- Se emplean “learning loops” que permiten la adaptación en tiempo real mediante interacciones de usuario.

## V. Escalabilidad y Diseño de Modelos  
- El entrenamiento de grandes modelos requiere aproximadamente 10^26 a 10^28 flops.  
- El “cerebro” final del modelo se puede ejecutar en una configuración compacta de 4 a 8 GPUs.  
- Se prevé una arquitectura en cascada: 10 modelos principales que se expanden en subconjuntos de 100, 1,000, 1,000,000 o 1,000,000,000 unidades.  
- Se identifican tres leyes de escalamiento:
  1. Ley del crecimiento de los modelos fundacionales.  
  2. Ley del entrenamiento en tiempo de prueba (“test time training”).  
  3. Ley del entrenamiento mediante refuerzo.

## VI. Sistemas de Seguridad y Monitoreo  
- Se implementan medidas de seguridad en centros de datos comparables a instalaciones de almacenamiento de plutonio (con guardias y armamento especializado).  
- Se proponen mecanismos criptográficos en chips para identificar ubicación y estado de las ejecuciones de entrenamiento.  
- Se diseñan sistemas para monitorear y controlar modelos superinteligentes, evitando acciones no deseadas (ej. exfiltración o acceso no autorizado a armas).  
- Se plantean pruebas significativas para información nuclear, biológica y para ciertos ciberataques, en cumplimiento de requisitos legales.  
- Se asume la disponibilidad suficiente de electricidad y cómputo en EE. UU. y China para alcanzar la superinteligencia.

## VII. Aplicaciones Empresariales y Automatización  
- Valor por conversación de voz en atención al cliente o ventas: entre US$10 y US$1,000.  
- Requerimiento de cómputo para cada conversación: 2 a 3 GPUs concurrentes (costo aproximado de 10 a 20 centavos).  
- Se estima que 10 millones de llamadas telefónicas concurrentes se migrarán a soluciones de IA en el próximo año.  
- Google Cloud Platform ofrece una solución empresarial basada en el “model context protocol” para conectar bases de datos a un modelo de lenguaje grande.  
- 100,000 empresas de software empresarial y middleware creadas en los últimos 30 años se verán afectadas por la automatización de tareas.  
- En arquitecturas modernas (ej. ERP y MRP) se utilizan bibliotecas de código abierto junto a herramientas como BigQuery o Amazon Redshift para la generación automática de código.  
- Las computadoras podrán reemplazar gran parte de tareas de programación y matemáticas, dado el uso de conjuntos de lenguajes limitados y cálculos simplificados.  
- Se predice la aparición de matemáticos y programadores de clase mundial basados en IA en aproximadamente 1 a 2 años.  
- Se proyecta que surgirán agentes especializados (“soants”) en cada campo dentro de 5 años para mejorar procesos empresariales y gubernamentales.

## VIII. Robótica, Automatización y Transformación del Trabajo  
- La automatización eliminará trabajos de alto riesgo y los supervisores de sistemas robóticos podrán tener mayores ingresos.  
- La transición de demostraciones a la aplicación diaria en robótica puede tomar más de 20 años.  
- La interacción directa de robots humanoides con personas podrá estar restringida por la regulación.  
- Los asistentes computacionales inteligentes permitirán que trabajadores con conocimientos “normales” accedan a empleos mejor remunerados.  
- Se sugiere que grandes empresas reestructuren equipos reduciéndolos a grupos más pequeños (ej. 50 personas).

## IX. Transformación Digital en Medios y Cine  
- La generación de video de formato largo con IA es costosa y requiere edición humana para corregir imperfecciones.  
- Un actor fue utilizado para recrear digitalmente movimientos característicos (ej. cabeza de William Shatner sobre cuerpo de otro actor) de forma “seamless”.  
- Se utilizan pantallas verdes en lugar de sets físicos en la producción cinematográfica.  
- Se aplica maquillaje digital en efectos especiales para películas de género “scary”.  
- La transformación digital en cine permite reducir costos, acortar tiempos de producción y aumentar opciones de edición y personalización.  
- La tecnología de “voice casting” asigna la voz de una persona a otra, permitiendo réplicas digitales o avatares, incluso de personas fallecidas con el permiso familiar.  
- Se plantea que la “esencia digital” de una persona pueda continuar en la nube, permitiendo interacciones basadas en conocimientos almacenados.

## X. Diseño de Circuitos, Chips y Cómputo en Tiempo de Inferencia  
- Se implementan diseños de circuitos y chips específicamente para el cómputo en tiempo de inferencia.  
- La conectividad (ej. Wi-Fi en vuelos) posibilita sesiones prolongadas de brainstorming con sistemas como Gemini.  
- Los algoritmos actuales requieren personalización para lograr estados emocionales o resultados deseados en períodos de inferencia reducidos.  
- La abundancia de estímulos digitales ha reducido el tiempo de atención, lo que demanda desconexión de dispositivos para concentrarse.  
- La generación de un “paper” tomó aproximadamente 12 minutos utilizando supercomputadoras, evidenciando el uso intensivo de cómputo.

## XI. Inversión y Escalabilidad del Aprendizaje  
- Solicitudes de inversión mencionadas: US$1 millón y US$2 millones.  
- El autoaprendizaje autorreferencial en IA puede alcanzar capacidades 1,000, 1,000,000 o incluso 1,000,000,000 veces superiores a las de un ser humano.  
- Riesgo de disminución de la agencia humana al delegar tareas a robots o IA, lo que puede afectar la capacidad para actividades físicas o desafiantes.  
- Ejemplos de tareas automatizadas: reparación de automóviles, corte de césped, entre otras.  
- Preocupación por que la omnipresencia de dispositivos digitales cree ambientes virtuales restrictivos y disminuya la determinación humana para superar desafíos.  
- Aplicaciones en sectores específicos, como el legal (gestión de demandas complejas mediante algoritmos) y la organización del trabajo (reducción de grandes equipos en favor de grupos pequeños y uso de asistentes digitales).

## XII. Componentes del Sistema y Arquitectura de Despliegue  
- Clústeres de hardware:
  • Clústeres de Nvidia con 200,000 GPUs (ej. clúster “Grock” en Memphis, Tennessee).  
  • Centros de datos proyectados para 5–10 años: 10 centros (5 en EE. UU., 3 en China, 2 en otras regiones) con capacidades de múltiples gigavatios.
- Diseños de chips:
  • Circuitos y chips especializados para el cómputo en tiempo de inferencia.  
  • Prioridad a diseños no tradicionales para aumentar la eficiencia energética.
- Infraestructura de seguridad:
  • Protocolos de seguridad en centros de datos comparables a instalaciones de plutonio (guardias, armamento especializado).  
  • Mecanismos criptográficos en chips para registrar ubicación y estado durante el entrenamiento.
- Arquitectura de despliegue:
  • Diferenciación entre modelos open source y closed source, con consideraciones regulatorias (límite de 10^26 flops).  
  • Despliegue en cascada e implantación jerárquica para escalar modelos en distintos niveles de complejidad.
- Integración empresarial:
  • Uso del “model context protocol” para vincular bases de datos empresariales (ej. vía Google Cloud Platform).  
  • Integración con herramientas de Big Data como BigQuery y Amazon Redshift para automatizar la generación de código.
- Sistemas en robótica y automatización:
  • Automatización de trabajos de alto riesgo mediante sistemas de IA y despliegue de brazos robóticos.  
  • Creación de interfaces de usuario (UI) generadas por IA a partir de comandos simples.
- Sistemas de producción digital:
  • Empleo de pantallas verdes, maquillaje digital y composición de imágenes para efectos en cine.
- Múltiples “learning loops” que permiten actualizaciones continuas, asegurando ventajas competitivas a través del aprendizaje exponencial.

Cada punto expuesto se presenta con datos y especificaciones técnicas, sin interpretación, manteniendo la fidelidad a la información original.