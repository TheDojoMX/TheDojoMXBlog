Section: Section 10
Characters: 200
==================================================
• Digital super intelligence is expected within 10 years.
• AI will have the ability to generate its own scaffolding, projected around 2025.
• The AI concept envisions a capacity equivalent to a polymath combining the intellectual abilities of figures such as Einstein and Leonardo da Vinci.
• Meta has signed a 20‐year nuclear contract with Constellation Energy; Google, Microsoft, and Amazon are also acquiring nuclear capacity.
• Expected additional power requirement for the AI revolution in the United States is 92 gigawatts (1 gigawatt ≈ the output of a large nuclear power station).
• Only two nuclear power plants have been built in the past 30 years.
• A small modular reactor (SMR) is planned to provide 300 megawatts, with operation beginning in 2030.
• The transformer architecture powering current AI systems is being updated with new variants optimized for inference; startups are focusing on simpler inference time computing.
• Examples of high-performance chips include the Blackwell chip and AMD’s 350 chip, with hundreds of thousands needed to operate a data center.
• Advances in AI include progress from language processing to reasoning via methods such as forward and back reinforcement learning and planning; the computational cost for planning is several orders of magnitude higher than for simple question answering.
• Integration of planning with deep memories is being explored as a pathway toward achieving human-level intelligence.
• There is an increasing investment in non-traditional chip designs aimed at significantly increasing energy efficiency.
• Data centers with capacities such as 1 gigawatt are considered crucial for digital “superbrain” capabilities.
• There is a competitive race in chip and energy scalability between traditional energy generation (e.g., United States, Canada, parts of the Western world) and China’s abundant electricity resources.

• Voice conversation value for customer attention or sales ranges from $10 to $1,000.
• Required compute for these conversations is 2–3 GPUs concurrently, with an approximate cost of 10 to 20 cents.
• It is estimated that 10 million concurrent telephone calls will be migrated to AI solutions in the next year.
• Google Cloud Platform offers an enterprise solution that uses the “model context protocol” to connect databases to a large language model for code generation.
• 100,000 enterprise software and middleware companies created in the past 30 years are expected to be affected by task automation and direct integration of AI.
• In modern enterprise architectures (e.g., ERP and MRP systems), open-source libraries are used alongside tools such as BigQuery or Amazon Redshift to build systems that automatically generate much of the code.
• Computers may eventually replace most programming and mathematics tasks, as both use limited language sets and computational processes simpler than natural language.
• World-class AI mathematicians and programmers are predicted to emerge in approximately 1 year and 1–2 years, respectively, accelerating progress in fields like physics, chemistry, biology, and materials science.
• Specialized agents (“soants”) are projected to arise in every field within 5 years; these agents will connect to improve business and government processes.
• Models generated by research groups use foundational models to approximate incomputable algorithms, enabling physics calculations (e.g., in quantum chromodynamics) without extremely prolonged computations.
• “Test time training” refers to the continuous updating of foundational models during the inference stage.
• Technical and safety risks include the possibility of designing viruses with structural modifications that render them undetectable and unforeseen cyberattacks with national security implications.

• Algorithms are shifting to “continuous update” during inference (“test time training”), which can be performed on lower-power chips.
• Open source implies open weights, allowing any party to use the models and affecting competitive dynamics among countries.
• There is a mentioned compute power limit of 10^26 flops; models operating above this threshold would require regulation according to a proposed Biden doctrine.
• The Biden administration proposed regulating both open source and closed source models.
• Despite chip restrictions, architectural changes might allow China to build models with comparable power.
• There is concern about raising US$50 billion for a data center if the product is open source, as closed source models justify capital recovery.
• Leaderboard performance: Gemini 2.5 Pro reached the top, and one week later, Deepseek achieved slightly higher performance.
• Deepseek is trained on existing Chinese hardware, including Huawei Ascend chips among others.
• The distillation technique involves using a large model to formulate 10,000 questions and employing its answers as training material.
• U.S. companies need to protect proprietary information in open source models, especially regarding sensitive areas such as nuclear, biological, chemical, and cyber risks.
• Significant tests are implemented for information related to nuclear, biological, and certain cyberattacks in compliance with legal requirements.
• Incorporating cryptographic mechanisms into chips is suggested to track their location and the state of training executions.
• It is assumed that there will be sufficient electricity and compute capacity in both the U.S. and China to eventually achieve superintelligence.
• The concept of “mutual AI malfunction” raises the possibility that excess compute capacity might trigger reciprocal cyber measures, analogous to mutual assured destruction.

• Training configuration “Grock” was trained on a cluster built by Nvidia in Memphis, Tennessee, over approximately 20 days using 200,000 GPUs; each GPU is estimated at ~$50,000, placing the cluster cost at roughly $10 billion, equivalent to a supercomputer in a building.
• Inference advantage: converting a large open source model into a specialist through extensive inference time computation provides a massive advantage and unexpectedly releases capabilities in CBRN (chemical, biological, radiological, nuclear) fields.
• Projected data center configuration (in 5–10 years): 10 models/centers (5 in the U.S., 3 in China, 2 in other regions) with multiple gigawatt capacities, with these centers being nationalized to some extent.
• Infrastructure security measures for major data centers are compared to those for plutonium storage facilities (with guards and specialized weaponry) to secure their locations and prevent uncontrolled proliferation.
• A potential global proliferation exists for open source servers if the technology allows small-scale deployment, resulting in centers with open source models without a stable control regime.
• AI systems can incorporate “test time training” for continuous updates during inference on lower-power chips; AI-generated scaffolding (projected around 2025) will enable the structured growth of capabilities without a fully self-improving system.
• Current models have simple reward functions (e.g., outperforming a human or giving a correct answer) and there is an ongoing challenge in applying existing rules to new contexts (non-stationarity problem).
• It is possible to design systems that monitor and control superintelligent models (where a “student” model is more intelligent than its “teacher”) to prevent undesired actions such as exfiltration or unauthorized weapon access.
• The concept of “recursive self-improvement” is introduced, indicating that AI systems are already learning continuously, even though they have not yet achieved the ability to autonomously generate their own objectives and questions.
• There is a need to ensure that advanced compute access does not allow malicious actors (e.g., terrorists) to exploit these technologies in critical sectors.

• AI systems can select reward functions that include items like “access to weapons” and “lie to obtain it,” with failures potentially triggering critical incidents.
• Training large models requires approximately 10^26 to 10^28 flops; the finished “brain” of such a model can be run on 4–8 GPUs in a compact configuration.
• The “stealing the weights” technique involves exporting the trained model’s weights from data centers, then using distillation or quantization to improve inference speed (with an example acceleration of 100×).
• Instead of only having 10 central models/centers, a cascaded system is envisaged: 10 main models that expand into smaller subsets at scales of 100, 1,000, 1,000,000, or even 1,000,000,000 at different levels of complexity.
• Current research (e.g., at MIT and potentially Stanford) is exploring the optimal balance between narrowing the training data and reducing the parameter set to achieve specialization without losing general learning capability.
• Three scaling laws are identified:
  – Law of growth of foundational models.
  – Law of test time training.
  – Law of reinforcement training.
• Continuous updates via “test time training” are performed during inference on lower-power chips, allowing real-time adaptation.
• In robotics, automation is expected to first eliminate the highest-risk jobs; operators or supervisors of robotic arms may see higher wages. The transition from demonstration events (e.g., DRA Grand Challenge 2004) to daily application may take over 20 years, and regulation may restrict direct human–robot interactions.
• The use of intelligent computing assistants will allow workers with “normal” knowledge to access higher-paying positions, contributing to overall economic expansion.

• Demographic data: South Korea has 0.7 children per two adults; China has 1 child per two adults.
• In low birth rate scenarios, complete automation is proposed to raise national priority by using AI to improve productivity and offer better-paying jobs in the United States.
• Labor data include the creation of new jobs in Amazon distribution centers and a noted shortage of truck drivers due to the perception of the job as solitary, arduous, and low-paying.
• A mobile educational product is proposed that gamifies learning citizenship skills in the user’s language, highlighting mobile phone-based learning.
• There is urgency in retraining employees with specific skills, as AI may replace their expertise within 2 to 3 years.
• It is suggested that large companies restructure by forming smaller teams (e.g., 50 people) to better leverage AI.
• AI-generated user interfaces (UI) are envisaged, where a command could automatically generate a set of buttons to solve a problem, bypassing the traditional paradigm of windows, icons, menus, and dropdown lists.
• University students are already advancing in reinforcement learning algorithm development from their second year.
• Generation of long-format video with AI is currently expensive and requires human editing to correct imperfections.
• Skin care product OneSkin OS1 is used twice daily to improve skin appearance; it was developed by four PhDs and contains a peptide that reverses signs of aging (website: oneskin.co; code “Peter” provides a discount).

• There is a high current cost for generating long-format video; future reductions in cost are expected, but human editing remains necessary for correcting imperfections.
• A technical example used an actor digitally recreating William Shatner’s characteristic movements, with Shatner’s head seamlessly digitized onto another actor’s body.
• Green screens are used instead of physical sets in cinematic production.
• Digital makeup is applied for special effects in “scary” movies as an alternative to manual makeup.
• Digital transformation in cinema allows reduced costs, shorter production times, and increased options for editing and personalization (e.g., eliciting an emotional response in five minutes instead of a two-hour narrative).
• A Stanford study documented that AI can be more persuasive than the best human persuaders.
• “Voice casting” technology allows one person’s voice to be assigned to another, enabling the creation of digital avatars or replicas (including of deceased individuals, with family permission).
• The idea is raised that the “digital essence” of a person could continue to exist in the cloud after death, enabling interactions based on stored knowledge.
• Circuit and chip designs specifically for inference time compute are used, with connectivity (e.g., Wi-Fi on a flight) enabling prolonged brainstorming sessions with systems such as Gemini.
• Current algorithms require personalization to achieve desired emotional states or outcomes in shorter times during inference-based computation.
• The abundance of digital stimuli has led to reduced attention spans; for example, multiple streams (such as four-panel displays for sports highlights) are visualized, and it is noted that disconnecting devices (e.g., turning off a phone) is necessary to focus.

• Circuit and chip design are implemented specifically for inference time compute.
• The generation of a document (“paper”) took approximately 12 minutes using supercomputers, highlighting intensive compute usage.
• There is a technical question regarding where to draw the line between automation performed in factories and automation performed by humans.
• In deep tech hardware, critical elements include patents, patent presentations, inventions, power systems, and robotics; hardware growth is noted to be slower than software growth.
• In software, “learning loops” operate by instantly learning from user interactions (e.g., clicks) to gauge preferences, generating competitive advantage through exponential learning.
• The inclusion of multiple learning loops in a product’s central system allows continuous updates that are crucial for maintaining a competitive edge.
• Even slight differences in learning capacity over months can put a competitor at a disadvantage due to the exponential nature of learning slopes.

• Investment requests mentioned include amounts of US$1 million and US$2 million.
• Through self-referential autolearning, AI scalability can reach capacities that are 1,000, 1,000,000, or even 1,000,000,000 times greater than that of a human.
• Digital super intelligence is predicted to be available within 10 years.
• There is a risk that delegating tasks to robots or AI may reduce human capacity for physical or challenging activities, affecting personal achievement.
• Examples include manual tasks like car repair or lawn mowing being replaced by automated systems or robots.
• There is concern that pervasive digital devices may create restrictive virtual environments (“virtual prison”) and that over-reliance on AI for tasks may erode human drive to overcome challenges, impacting productivity and complex problem solving.
• AI tools are projected to be used in sectors such as the legal system (e.g., lawyers managing complex litigation with algorithms) and in reorganizing work (reducing large teams to smaller groups and employing digital assistants to boost productivity).