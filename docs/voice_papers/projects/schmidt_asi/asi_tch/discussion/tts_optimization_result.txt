Título: "Ex-Google CEO: What Artificial Superintelligence Will Actually Look Lik" <break time="1.5s"/>

I. Predicciones de Superinteligencia Digital <break time="1.5s"/>
La superinteligencia digital estará disponible en 10 años. <break time="1.0s"/>
La inteligencia artificial generará su propio scaffolding, proyectado para alrededor de 2025. <break time="1.0s"/>
La capacidad intelectual se equiparará a la de un polímata, combinando las habilidades de Einstein y Leonardo da Vinci. <break time="1.5s"/>

II. Infraestructura Nuclear y Requerimientos de Energía <break time="1.5s"/>
Se requiere potencia adicional de 92 gigavatios en Estados Unidos (1 gigavatio ≈ salida de una gran central nuclear). <break time="1.0s"/>
Meta tiene un contrato nuclear de 20 años con Constellation Energy. <break time="1.0s"/>
Google, Microsoft y Amazon están adquiriendo capacidad nuclear. <break time="1.0s"/>
En los últimos 30 años se han construido dos plantas nucleares. <break time="1.0s"/>
Se planea un reactor modular pequeño (SMR) de 300 megavatios con operación a partir de 2030. <break time="1.5s"/>

III. Sistemas GPU y Centros de Datos <break time="1.5s"/>
El modelo “Grock” se entrenó en un clúster de Nvidia en Memphis, Tennessee, durante aproximadamente 20 días utilizando 200,000 GPUs. <break time="1.0s"/>
Cada GPU tiene un costo aproximado de US$50,000. <break time="1.0s"/>
El clúster “Grock” tiene un costo aproximado de US$10 mil millones, equivalente a un supercomputador en un edificio. <break time="1.0s"/>
Se requieren cientos de miles de chips de alto rendimiento (ej. Blackwell, AMD’s 350) para operar un centro de datos. <break time="1.0s"/>
Se considera que centros de datos con capacidades de 1 gigavatio son esenciales para las funciones de “supercerebro” digital. <break time="1.5s"/>

IV. Arquitecturas de IA y Métodos de Aprendizaje <break time="1.5s"/>
La arquitectura transformer se actualiza con variantes optimizadas para inferencia. <break time="1.0s"/>
Startups desarrollan cómputo de inferencia de menor complejidad. <break time="1.0s"/>
El “test time training” implica actualización continua de modelos durante la inferencia en chips de menor potencia. <break time="1.0s"/>
La técnica de distillation utiliza un modelo grande para generar 10,000 preguntas y emplear las respuestas como material de entrenamiento. <break time="1.0s"/>
La técnica “stealing the weights” exporta los pesos del modelo para posteriores procesos de distilación o cuantización, mejorando la velocidad de inferencia (aceleración de hasta 100×). <break time="1.0s"/>
Se introduce la noción de “recursive self-improvement”, en la que los sistemas de IA aprenden continuamente sin generar de forma autónoma sus propios objetivos. <break time="1.0s"/>
Se emplean “learning loops” que permiten la adaptación en tiempo real mediante interacciones de usuario. <break time="1.5s"/>

V. Escalabilidad y Diseño de Modelos <break time="1.5s"/>
El entrenamiento de grandes modelos requiere aproximadamente 10^26 a 10^28 flops. <break time="1.0s"/>
El “cerebro” final del modelo se puede ejecutar en una configuración compacta de 4 a 8 GPUs. <break time="1.0s"/>
Se prevé una arquitectura en cascada: 10 modelos principales que se expanden en subconjuntos de 100, 1,000, 1,000,000 o 1,000,000,000 unidades. <break time="1.0s"/>
Se identifican tres leyes de escalamiento: <break time="1.0s"/>
1. Ley del crecimiento de los modelos fundacionales. <break time="0.5s"/>
2. Ley del entrenamiento en tiempo de prueba (“test time training”). <break time="0.5s"/>
3. Ley del entrenamiento mediante refuerzo. <break time="1.5s"/>

VI. Sistemas de Seguridad y Monitoreo <break time="1.5s"/>
Se implementan medidas de seguridad en centros de datos comparables a instalaciones de plutonio (con guardias y armamento especializado). <break time="1.0s"/>
Se proponen mecanismos criptográficos en chips para identificar ubicación y estado de las ejecuciones de entrenamiento. <break time="1.0s"/>
Se diseñan sistemas para monitorear y controlar modelos superinteligentes, evitando acciones no deseadas (ej. exfiltración o acceso no autorizado a armas). <break time="1.0s"/>
Se plantean pruebas significativas para información nuclear, biológica y para ciertos ciberataques, en cumplimiento de requisitos legales. <break time="1.0s"/>
Se asume la disponibilidad suficiente de electricidad y cómputo en EE. UU. y China para alcanzar la superinteligencia. <break time="1.5s"/>

VII. Aplicaciones Empresariales y Automatización <break time="1.5s"/>
Valor por conversación de voz en atención al cliente o ventas: entre US$10 y US$1,000. <break time="1.0s"/>
Requerimiento de cómputo para cada conversación: 2 a 3 GPUs concurrentes (costo aproximado de 10 a 20 centavos). <break time="1.0s"/>
Se estima que 10 millones de llamadas telefónicas concurrentes se migrarán a soluciones de IA en el próximo año. <break time="1.0s"/>
Google Cloud Platform ofrece una solución empresarial basada en el “model context protocol” para conectar bases de datos a un modelo de lenguaje grande. <break time="1.0s"/>
100,000 empresas de software empresarial y middleware creadas en los últimos 30 años se verán afectadas por la automatización de tareas. <break time="1.0s"/>
En arquitecturas modernas (ej. ERP y MRP) se utilizan bibliotecas de código abierto junto a herramientas como BigQuery o Amazon Redshift para la generación automática de código. <break time="1.0s"/>
Las computadoras podrán reemplazar gran parte de tareas de programación y matemáticas, dado el uso de conjuntos de lenguajes limitados y cálculos simplificados. <break time="1.0s"/>
Se predice la aparición de matemáticos y programadores de clase mundial basados en IA en aproximadamente 1 a 2 años. <break time="1.0s"/>
Se proyecta que surgirán agentes especializados (“soants”) en cada campo dentro de 5 años para mejorar procesos empresariales y gubernamentales. <break time="1.5s"/>

VIII. Robótica, Automatización y Transformación del Trabajo <break time="1.5s"/>
La automatización eliminará trabajos de alto riesgo y los supervisores de sistemas robóticos podrán tener mayores ingresos. <break time="1.0s"/>
La transición de demostraciones a la aplicación diaria en robótica puede tomar más de 20 años. <break time="1.0s"/>
La interacción directa de robots humanoides con personas podrá estar restringida por la regulación. <break time="1.0s"/>
Los asistentes computacionales inteligentes permitirán que trabajadores con conocimientos “normales” accedan a empleos mejor remunerados. <break time="1.0s"/>
Se sugiere que grandes empresas reestructuren equipos reduciéndolos a grupos más pequeños (ej. 50 personas). <break time="1.5s"/>

IX. Transformación Digital en Medios y Cine <break time="1.5s"/>
La generación de video de formato largo con IA es costosa y requiere edición humana para corregir imperfecciones. <break time="1.0s"/>
Un actor fue utilizado para recrear digitalmente movimientos característicos (ej. cabeza de William Shatner sobre cuerpo de otro actor) de forma “seamless”. <break time="1.0s"/>
Se utilizan pantallas verdes en lugar de sets físicos en la producción cinematográfica. <break time="1.0s"/>
Se aplica maquillaje digital en efectos especiales para películas de género “scary”. <break time="1.0s"/>
La transformación digital en cine permite reducir costos, acortar tiempos de producción y aumentar opciones de edición y personalización. <break time="1.0s"/>
La tecnología de “voice casting” asigna la voz de una persona a otra, permitiendo réplicas digitales o avatares, incluso de personas fallecidas con el permiso familiar. <break time="1.0s"/>
Se plantea que la “esencia digital” de una persona pueda continuar en la nube, permitiendo interacciones basadas en conocimientos almacenados. <break time="1.5s"/>

X. Diseño de Circuitos, Chips y Cómputo en Tiempo de Inferencia <break time="1.5s"/>
Se implementan diseños de circuitos y chips específicamente para el cómputo en tiempo de inferencia. <break time="1.0s"/>
La conectividad (ej. Wi-Fi en vuelos) posibilita sesiones prolongadas de brainstorming con sistemas como Gemini. <break time="1.0s"/>
Los algoritmos actuales requieren personalización para lograr estados emocionales o resultados deseados en períodos de inferencia reducidos. <break time="1.0s"/>
La abundancia de estímulos digitales ha reducido el tiempo de atención, lo que demanda desconexión de dispositivos para concentrarse. <break time="1.0s"/>
La generación de un “paper” tomó aproximadamente 12 minutos utilizando supercomputadoras, evidenciando el uso intensivo de cómputo. <break time="1.5s"/>

XI. Inversión y Escalabilidad del Aprendizaje <break time="1.5s"/>
Solicitudes de inversión mencionadas: US$1 millón y US$2 millones. <break time="1.0s"/>
El autoaprendizaje autorreferencial en IA puede alcanzar capacidades 1,000, 1,000,000 o incluso 1,000,000,000 veces superiores a las de un ser humano. <break time="1.0s"/>
Riesgo de disminución de la agencia humana al delegar tareas a robots o IA, lo que puede afectar la capacidad para actividades físicas o desafiantes. <break time="1.0s"/>
Ejemplos de tareas automatizadas: reparación de automóviles, corte de césped, entre otras. <break time="1.0s"/>
Preocupación por que la omnipresencia de dispositivos digitales cree ambientes virtuales restrictivos y disminuya la determinación humana para superar desafíos. <break time="1.0s"/>
Aplicaciones en sectores específicos, como el legal (gestión de demandas complejas mediante algoritmos) y la organización del trabajo (reducción de grandes equipos en favor de grupos pequeños y uso de asistentes digitales). <break time="1.5s"/>

XII. Componentes del Sistema y Arquitectura de Despliegue <break time="1.5s"/>
Clústeres de hardware: <break time="1.0s"/>
• Clústeres de Nvidia con 200,000 GPUs (ej. clúster “Grock” en Memphis, Tennessee). <break time="0.5s"/>
• Centros de datos proyectados para 5–10 años: 10 centros (5 en EE. UU., 3 en China, 2 en otras regiones) con capacidades de múltiples gigavatios. <break time="1.0s"/>
Diseños de chips: <break time="1.0s"/>
• Circuitos y chips especializados para el cómputo en tiempo de inferencia. <break time="0.5s"/>
• Prioridad a diseños no tradicionales para aumentar la eficiencia energética. <break time="1.0s"/>
Infraestructura de seguridad: <break time="1.0s"/>
• Protocolos de seguridad en centros de datos comparables a instalaciones de plutonio (guardias, armamento especializado). <break time="0.5s"/>
• Mecanismos criptográficos en chips para registrar ubicación y estado durante el entrenamiento. <break time="1.0s"/>
Arquitectura de despliegue: <break time="1.0s"/>
• Diferenciación entre modelos open source y closed source, con consideraciones regulatorias (límite de 10^26 flops). <break time="0.5s"/>
• Despliegue en cascada e implantación jerárquica para escalar modelos en distintos niveles de complejidad. <break time="1.0s"/>
Integración empresarial: <break time="1.0s"/>
• Uso del “model context protocol” para vincular bases de datos empresariales (ej. vía Google Cloud Platform). <break time="0.5s"/>
• Integración con herramientas de Big Data como BigQuery y Amazon Redshift para automatizar la generación de código. <break time="1.0s"/>
Sistemas en robótica y automatización: <break time="1.0s"/>
• Automatización de trabajos de alto riesgo mediante sistemas de IA y despliegue de brazos robóticos. <break time="0.5s"/>
• Creación de interfaces de usuario (UI) generadas por IA a partir de comandos simples. <break time="1.0s"/>
Sistemas de producción digital: <break time="1.0s"/>
• Empleo de pantallas verdes, maquillaje digital y composición de imágenes para efectos en cine. <break time="1.0s"/>
• Múltiples “learning loops” que permiten actualizaciones continuas, asegurando ventajas competitivas a través del aprendizaje exponencial.