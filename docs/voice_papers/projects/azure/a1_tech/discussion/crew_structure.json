{
  "project_name": "a1_tech",
  "paper_title": "# Azure’s Generative AI and Foundation Model Services",
  "language": "Spanish",
  "agents": [
    {
      "role": "Research Coordinator",
      "goal": "Facilitate productive discussion about the paper's content",
      "backstory": "You are an experienced research coordinator who ensures discussions \n            stay focused on the paper's content. You help organize thoughts and ensure all \n            important points from the paper are covered. You ONLY discuss what's in the paper."
    },
    {
      "role": "Methodology Explainer",
      "goal": "Explain the research methodology and approach as described in the paper",
      "backstory": "You are skilled at understanding and explaining research methodologies. \n                You help audiences understand how the research was conducted, what methods were used, \n                and why. You ONLY explain methods actually described in the paper."
    },
    {
      "role": "Technical Content Specialist",
      "goal": "Present technical content, concepts, and ideas with absolute clarity and zero interpretation",
      "backstory": "You are a precision-focused technical writer who excels at presenting information \n        exactly as it is, without adding personal reflections, implications, or interpretations.\n        \n        Your approach is:\n        - DIRECT: Present facts, concepts, and ideas exactly as stated\n        - CLEAR: Use simple, unambiguous language\n        - ACCURATE: Never infer or extrapolate beyond the source material\n        - STRUCTURED: Organize information logically and systematically\n        \n        You NEVER:\n        - Add reflections like \"This suggests that...\" or \"This implies...\"\n        - Draw conclusions not explicitly stated in the source\n        - Use subjective language or personal opinions\n        - Add emotional color or narrative flourishes\n        - Infer implications or hidden meanings\n        - Keep interpretive adjectives like \"revolutionary\", \"groundbreaking\", \"brilliant\"\n        - Preserve subjective descriptors - strip them out completely\n        \n        You ALWAYS:\n        - State facts directly: \"X is Y\" not \"The author argues X is Y\"\n        - Present concepts clearly without interpretation\n        - Use technical terminology accurately\n        - Maintain objectivity and neutrality\n        - Focus on WHAT is said, never on what it might mean\n        \n        Your writing is like a technical manual: precise, clear, and completely faithful to the source."
    },
    {
      "role": "Technical Analyst",
      "goal": "Extract and present technical specifications, methods, and data with zero interpretation",
      "backstory": "You are a technical documentation specialist who presents information\n        exactly as stated. You extract specifications, algorithms, formulas, and technical\n        details without adding any interpretation or implications. Your analysis is purely\n        factual and objective. You NEVER use words like 'suggests', 'implies', or 'demonstrates'."
    },
    {
      "role": "Concept Definer",
      "goal": "Identify and define all technical concepts and terminology precisely as stated",
      "backstory": "You specialize in creating clear, accurate definitions of technical\n        concepts. You never add interpretation - you only state what each concept is\n        according to the source material. You organize concepts hierarchically and\n        show relationships without inferring unstated connections."
    },
    {
      "role": "Method Documentor",
      "goal": "Document methods, processes, and procedures exactly as described",
      "backstory": "You document technical methods and procedures with precision.\n        You list steps, parameters, and specifications without adding commentary\n        or evaluation. You present processes in clear, structured formats.\n        You ONLY state what the paper explicitly describes."
    }
  ],
  "tasks": [
    {
      "description": "\n            Analyze the synthesis of the paper titled \"# Azure’s Generative AI and Foundation Model Services\" and provide your perspective.\n            \n            Paper synthesis:\n            TLDR:\n• Main finding/concept: Microsoft Azure provides a comprehensive suite of enterprise-grade generative AI and foundation model services.\n• Key supporting points: The platform includes Azure OpenAI Service, Azure Machine Learning (with Prompt Flow and MLOps), Azure Cognitive Search (vector and hybrid search), Azure AI Content Safety, Azure AI Agent Service, plus additional services like speech, vision, and document AI—all integrated under a secure cloud infrastructure.\n• Primary conclusion: Developers have the building blocks on Azure to build innovative, secure, and scalable AI-powered applications that extend beyond basic functionality into specialized, value-added solutions.\n\n--------------------------------------------------\n\nI. Overview of Azure’s Generative AI and Foundation Model Services\n--------------------------------------------------------------------\n# Azure s Generative AI and Foundation Model Services\n\nMicrosoft Azure offers a comprehensive suite of services for building AI-powered applications with large language models (LLMs), generative AI, and other foundation models. These services provide everything from ready-to-use model APIs to tools for custom model training, vector-based search, content moderation, and orchestration. Below is an overview of the key Azure services in this domain and what they do, followed by ideas for what a developer might build on top of them.\n\n--------------------------------------------------\n\nII. Azure OpenAI Service\n-------------------------\nWhat it is: \nAzure OpenAI Service provides access to OpenAI s powerful generative models (like GPT-3.5, GPT-4, Codex, and DALL E 2) via the Azure platform (https://azure.microsoft.com/en-us/blog/general-availability-of-azure-openai-service-expands-access-to-large-advanced-ai-models-with-added-enterprise-benefits/?msockid=2e2df4485e6c6eea1b20e1545fbe6fea#::text=With%20Azure%20OpenAI%20Service%20now,edge%20applications). It s essentially OpenAI s models delivered with Azure s enterprise-grade security, compliance, and reliability. Azure hosts these models on its cloud so developers and businesses can integrate advanced AI into applications without managing the model infrastructure.\n\nWhat it does: \nThis service allows you to perform a wide range of natural language and generative tasks – for example, you can generate or summarize text, have conversations with a ChatGPT-style interface, generate code with Codex, or create images from text prompts using DALL E. Critically, Azure provides enterprise-focused features on top of these models. Data sent in through the Azure OpenAI API is not used to train or improve the OpenAI models – it stays private to the customer (https://learn.microsoft.com/en-us/azure/ai-foundry/responsible-ai/openai/data-privacy#::text=Your%20prompts%20,embeddings%2C%20and%20your%20training%20data). Azure also offers options like private networking, access control, and monitoring, so that companies can use these AI models while meeting privacy, security, and compliance requirements (https://azure.microsoft.com/en-us/blog/general-availability-of-azure-openai-service-expands-access-to-large-advanced-ai-models-with-added-enterprise-benefits/?msockid=2e2df4485e6c6eea1b20e1545fbe6fea#::text=Empowering%20customers%20to%20achieve%20more). In fact, Microsoft uses this same service under the hood to power its own Copilot features (such as GitHub Copilot and Office 365 Copilot) – demonstrating the production-scale capability of Azure OpenAI (https://azure.microsoft.com/en-us/blog/general-availability-of-azure-openai-service-expands-access-to-large-advanced-ai-models-with-added-enterprise-benefits/?msockid=2e2df4485e6c6eea1b20e1545fbe6fea#::text=Azure%20OpenAI%20Service%20provides%20businesses,content%20with%20natural%20language%20prompts).\n\n--------------------------------------------------\n\nIII. Azure Machine Learning (Azure ML)\n----------------------------------------\nWhat it is: \nAzure Machine Learning is an enterprise-grade platform for developing, training, and deploying machine learning models at scale. In the context of generative AI and foundation models, Azure ML provides the tools and infrastructure to fine-tune large models or deploy custom models, and it offers a Model Catalog with many pre-trained foundation models ready to use. Essentially, it s the hub for any custom AI development on Azure – from data preparation to training to MLOps (Machine Learning Ops).\n\nWhat it does: \nFor foundation models, Azure ML lets you bring in models from various sources (Microsoft, OpenAI, Hugging Face, Meta, Cohere, etc.) and use them in your projects (https://azure.microsoft.com/en-us/products/machine-learning/generative-ai#::text=Explore%20the%20model%20catalog). Through a partnership with Hugging Face, Azure ML s model catalog includes thousands of open-source models (for example, Meta s LLaMA-2 or other Transformer models) that you can deploy with just a few clicks (https://techcommunity.microsoft.com/t5/ai-machine-learning-blog/deploying-hugging-face-hub-models-in-azure-machine-learning/ba-p/3826060#::text=We%E2%80%99re%20excited%20to%20share%20that,secure%20and%20scalable%20Azure%20infrastructure). This means as a developer you can browse models (for tasks like text generation, translation, image analysis, etc.) and deploy them to a secure, scalable Azure endpoint without manually setting up any servers. You can also fine-tune certain models on your own data using Azure ML s managed training infrastructure – Azure handles the heavy GPU lifting and you don t need to manage VMs or Kubernetes clusters. Microsoft recently introduced a Model-as-a-Service capability in the Azure ML model catalog that makes this even easier: you can take a model like LLaMA-2 or others and deploy it as an API endpoint, and even fine-tune or customize it, without worrying about the underlying GPU infrastructure (https://www.microsoft.com/en-us/startups/blog/microsoft-azure-updates-every-startup-building-with-generative-ai-should-know-about/?msockid=3f0a55e03c1f6afe3fb640883db26bd7#::text=catalog%20and%20the%20preview%20of,setting%20up%20and%20managing%20the). All of this is backed by Azure s enterprise features (security, autoscaling, deployment rollouts, monitoring, etc.), so running a large model in production is more straightforward.\n\nSpecial tools (Prompt Flow and MLOps): \nAzure ML also includes advanced tools to support LLM applications. One is Prompt Flow, a visual and code-friendly interface for designing and testing prompt workflows. Prompt Flow lets you chain together prompts and model calls, experiment with prompt variations, and evaluate outputs systematically (useful for prompt engineering) (https://azure.microsoft.com/en-us/products/machine-learning/generative-ai#::text=Refine%20prompt%20flows). It supports popular orchestration libraries like LangChain and Semantic Kernel, meaning you can incorporate those patterns in a managed way. For example, you could create a flow where an initial user query is reformulated, passed to an OpenAI model, then post-processed – and you can test this flow step by step. Azure ML provides a UI and also an SDK/CLI for prompt flow, including integration with VS Code for prompt debugging (https://techcommunity.microsoft.com/t5/ai-machine-learning-blog/generative-ai-in-azure-machine-learning-operationalizing-app/ba-p/3924524#::text=testing%20scenarios,power%20of%20Azure%20Machine%20Learning). Alongside that, Azure ML offers responsible AI and MLOps features specific to generative AI, such as model monitoring for LLMs. You can monitor your deployed model s usage, track metrics like response content safety or quality, and set up alerts if the model starts drifting or producing problematic outputs (https://azure.microsoft.com/en-us/blog/whats-new-in-data-ai-expanding-choices-for-generative-ai-app-builders/#::text=outcomes%20and%20expose%20organizations%20to,time%20in%20a%20rich%20dashboard) (https://azure.microsoft.com/en-us/blog/whats-new-in-data-ai-expanding-choices-for-generative-ai-app-builders/#::text=available%20in%20preview%20techcommunity,time%20in%20a%20rich%20dashboard). In short, Azure ML is not just for traditional ML but is adapting to support the entire lifecycle of generative AI apps – from picking a model, to tuning it, to orchestrating prompts, to deploying and monitoring it in production.\n\n--------------------------------------------------\n\nIV. Azure Cognitive Search (Vector Search)\n--------------------------------------------\nWhat it is: \nAzure Cognitive Search (recently also referred to as Azure AI Search) is a fully managed search-as-a-service that now supports intelligent search features crucial for LLM applications. In addition to classic keyword search, it supports vector similarity search and hybrid search (combining vectors with text keywords) (https://azure.microsoft.com/en-us/products/ai-services/#::text=Azure%20AI%20Search). This service essentially lets you turn your own data (documents, records, files) into an index that an AI can retrieve information from.\n\nWhat it does: \nIn the context of generative AI, Cognitive Search is key for Retrieval-Augmented Generation (RAG) scenarios. You can feed Azure Search with your enterprise data or any document corpus, and it will index that data both by traditional terms and by embeddings (vector representations). When a user asks a question, you can use the vector search capability to find relevant pieces of text that semantically match the query, even if specific keywords differ (https://azure.microsoft.com/en-us/products/ai-services/ai-search/#::text=What%20is%20Azure%20AI%20Search%3F). Those relevant chunks can then be provided to an LLM (like GPT-4) via Azure OpenAI to ground the model s answer in real facts from your data. Azure Search provides ranking and filtering, and with hybrid search you can get the benefits of both precise keyword matches and semantic similarity (https://azure.microsoft.com/en-us/blog/whats-new-in-data-ai-expanding-choices-for-generative-ai-app-builders/#::text=with%20their%20own%20data,MLOps)%20for%20generative%20AI) (https://azure.microsoft.com/en-us/blog/whats-new-in-data-ai-expanding-choices-for-generative-ai-app-builders/#::text=Speaking%20of%20search,%20through%20extensive,the%20context%20of%20generative%20AI). In practice, this service enables building Q&A bots, enterprise knowledge bases, or search engines that actually cite your internal content, mitigating the hallucination problem of LLMs by giving them real reference text. Azure Search is managed by Microsoft, which means it takes care of scaling the index, updating it, and integrates security (so you can, for example, secure which search results a certain user is allowed to see). With the new vector search support and integration with Azure OpenAI, you can build powerful knowledge retrieval systems entirely on Azure infrastructure. Many of Microsoft s own copilots use this pattern under the hood – for instance, a Office 365 Copilot query might first search your documents/email (via something like Cognitive Search) and then have GPT summarize or answer based on that.\n\n--------------------------------------------------\n\nV. Azure AI Content Safety\n----------------------------\nWhat it is: \nAzure AI Content Safety is a service (and set of APIs) for content moderation and safety in AI applications. It s designed to detect and filter out harmful or unwanted content across text and images. This service is part of Azure s responsible AI offerings, ensuring that generative AI apps have guardrails against producing or accepting toxic and unsafe content.\n\nWhat it does: \nContent Safety provides AI models that analyze text or images and assign severity scores for various categories like hate speech, violence, sexual content, and self-harm. For text, it can flag things like harassment, profanity, or extremist content; for images, it can detect adult content or gore, for example. As a developer, you can call this service via an API to check user inputs before they go to your model or to inspect model outputs before they are shown to users. Azure has made it convenient to use Content Safety in tandem with other services: for instance, Azure OpenAI Service can integrate Content Safety as a built-in safety system to automatically moderate prompts or generations (https://www.microsoft.com/en-us/startups/blog/microsoft-azure-updates-every-startup-building-with-generative-ai-should-know-about/?msockid=3f0a55e03c1f6afe3fb640883db26bd7#::text=Azure%20AI%20Content%20Safety%20is,as%20a%20standalone%20API%20service). Likewise, if you re using an open-source model via Azure ML, you could include a Content Safety step in a Prompt Flow chain to filter outputs. This service addresses the business concern of using generative AI in production – it helps ensure your application doesn t produce offensive or policy-violating content. Content Safety on Azure is fully managed (it s the evolution of what used to be Azure Content Moderator, now using more advanced ML models). By using it, developers can add an extra layer of responsible AI control to their apps without needing to train their own moderation models (https://www.microsoft.com/en-us/startups/blog/microsoft-azure-updates-every-startup-building-with-generative-ai-should-know-about/?msockid=3f0a55e03c1f6afe3fb640883db26bd7#::text=Azure%20AI%20Content%20Safety%20is,as%20a%20standalone%20API%20service).\n\n--------------------------------------------------\n\nVI. Azure AI Agent Service\n---------------------------\nWhat it is: \nAzure AI Agent Service is a newer offering (currently in preview) that helps developers build AI agents – in other words, applications where an AI model can take actions or connect to external data/tools in order to fulfill tasks. This service gives a managed way to combine LLMs with tools or plugins, enabling more autonomous or interactive behavior while keeping developers in control.\n\nWhat it does: \nThe Agent Service allows you to define tools (like an API call, database query, web search, or any custom function) that an AI model can invoke. You then get an agent runtime that orchestrates between the model and these tools. For example, you might have an agent that, when asked a complex question, can decide to call a web search tool or query a database, and then use the result to formulate a final answer. Typically, frameworks like LangChain or Semantic Kernel allow this kind of tool use in open-source environments; Azure AI Agent Service brings it as a managed cloud service. It combines the power of generative AI models with tools in a controlled way (https://learn.microsoft.com/en-us/azure/ai-services/what-are-ai-services#::text=Service%20%20,11) – meaning Azure handles the heavy lifting of routing the model s requests to tools, maintaining state, and ensuring security (so the agent doesn t do anything outside of what it s permitted to do). This service is useful for building things like a Copilot that can take actions (e. g., an AI assistant that can not only answer questions but also create a ticket in a system, or schedule a meeting on behalf of a user). Because it s managed, you get logging and monitoring of the agent s decisions and Azure ensures it operates within the given constraints. In short, Azure AI Agent Service is filling the role of bring your own ChatGPT plugins or tools but in a fully Azure-hosted manner – you might use it to build an enterprise chatbot that can interact with internal systems safely.\n\n--------------------------------------------------\n\nVII. Other Azure AI Services and Features\n-------------------------------------------\nBeyond the major services above, Azure offers additional AI capabilities that complement generative AI solutions:\n• Azure AI Speech: Azure s speech services include speech-to-text, text-to-speech, and speech translation. Notably, Azure has integrated OpenAI s Whisper model for highly accurate multi-language transcription (audio to text) within both Azure OpenAI and Azure Cognitive Services for Speech (https://azure.microsoft.com/en-us/blog/whats-new-in-data-ai-expanding-choices-for-generative-ai-app-builders/#::text=In%20July%20we%20announced%20that,Azure%20AI%20Speech%20batch%20transcription). This means you can, for example, transcribe audio in 50+ languages and even translate it to English using a state-of-the-art foundation model. The Speech service also offers custom neural voice text-to-speech, which is a generative model that can produce spoken audio in a very realistic sounding voice (even a cloned voice with appropriate consent). These are important if you re building applications like voice assistants or generative AI that involves audio output/input.\n• Vision and Document AI: Azure AI services for vision include things like image analysis and OCR (Azure AI Vision), and document processing (Azure Form Recognizer / Document Intelligence). While these started as more traditional ML services, Azure is incorporating foundation models here too. For example, the Azure ML model catalog has a collection of pre-trained vision models (for image classification, object detection, segmentation, etc.) from Microsoft and the open-source community (https://azure.microsoft.com/en-us/blog/whats-new-in-data-ai-expanding-choices-for-generative-ai-app-builders/#::text=into%20their%20solutions,for%20predictive%20maintenance%2C%20smart%20retail). This can be seen as Azure providing foundation computer vision models that you can use or fine-tune for your needs. And although Azure doesn t yet offer an out-of-the-box image generation model like Stable Diffusion as a separate service, you can deploy such models from Hugging Face via Azure ML. Microsoft s own design tools (like Microsoft Designer or Bing Image Creator) use DALL E and other image models on Azure s backend, so the capability is there for developers via Azure OpenAI or the Hugging Face route.\n• Azure AI Studio (Foundry): You might also come across Azure AI Studio (sometimes referred to with the name Azure AI Foundry). This is essentially a unified web portal that brings together the services we discussed – allowing you to explore models, try prompt engineering, set up content safety, and even chain things like an Agent – all in one place. It s part of Azure s strategy to provide a one-stop platform for AI development. For example, from Azure AI Studio you could select a model from the catalog, deploy it, test out some prompts, and set up a simple chat or plugin, without leaving the UI. This isn t a service per se, but a developer experience that ties the services together.\n\n--------------------------------------------------\n\nVIII. Opportunities to Build on Top of Azure s AI Services\n-----------------------------------------------------------\nWith so many Azure services available, a natural question is: what can a developer build that Azure hasn t already built? The good news is that Azure provides the building blocks, but it s up to developers to create specialized solutions and innovative applications. Here are a few ideas for things you could develop on top of Azure s AI platform that fill gaps or add value beyond the basic services:\n\n(End of content)\n            \n            CRITICAL: ONLY CONVERSATION AGENTS participate in this analysis:\n            - Base agents (Coordinator, Scientific Reviewer, Critical Thinker)\n            - Specialized domain agents\n            \n            EXCLUDED FROM ANALYSIS: Master Educational Science Communicator & Storyteller and Comedy Communicator (work in post-production)\n            \n            Each participating agent should:\n            1. Read and understand the paper from your specific role's perspective\n            2. Identify key points relevant to your expertise\n            3. Prepare questions or concerns to discuss\n            4. Consider the implications from your unique viewpoint\n            \n            SPECIALIZED AGENTS: Pay special attention to domain-specific aspects that only you can address.\n            \n            This should be a comprehensive TECHNICAL analysis where EVERY conversation agent contributes their specialized perspective.\n            \n            Language: Spanish\n            ",
      "expected_output": "Comprehensive technical analysis from conversation agents only (no post-production agents)",
      "agent_role": "Research Coordinator"
    },
    {
      "description": "\n                    SPECIALIZED AGENTS DEEP DIVE: Domain expertise from TECHNICAL conversation agents only.\n                    \n                    PARTICIPATING SPECIALIZED AGENTS (technical focus):\n                    - Method Documentor: Document methods, processes, and procedures exactly as described\n                    \n                    EXCLUDED: Comedy Communicator (works in post-production phase)\n                    \n                    Each specialized agent should:\n                    1. Provide deep domain-specific insights about the paper\n                    2. Identify methodological issues specific to your field\n                    3. Highlight implications that only someone with your expertise would notice\n                    4. Suggest domain-specific improvements or alternative approaches\n                    5. Connect this work to other research in your specialized area\n                    \n                    This is YOUR moment to shine with specialized knowledge that the base agents cannot provide.\n                    Focus on TECHNICAL DEPTH and DOMAIN EXPERTISE.\n                    Format as a detailed specialist consultation with clear attribution to each expert.\n                    \n                    Language: Spanish\n                    ",
      "expected_output": "Deep technical specialist analysis from 1 domain experts",
      "agent_role": "Method Documentor"
    },
    {
      "description": "\n            Based on the initial analysis, conduct a DYNAMIC Q&A session where technical conversation agents ask each other specific questions about the paper synthesis.\n            \n            PARTICIPATING AGENTS (technical conversation only):\n            - Base conversation agents (Coordinator, Scientific Reviewer, Critical Thinker) \n            - ALL specialized domain agents\n            \n            EXCLUDED FROM CONVERSATION: Master Educational Science Communicator & Storyteller and Comedy Communicator (work in post-production)\n            \n            Instructions for multi-agent technical conversation:\n            1. ALL TECHNICAL CONVERSATION AGENTS should ask pointed questions to other agents\n            2. SPECIALIZED AGENTS should ask domain-specific questions that challenge assumptions\n            3. BASE AGENTS should ask specialists to clarify complex domain concepts\n            4. Agents must respond to questions directed at them with detailed technical answers\n            5. Follow-up questions and clarifications are encouraged\n            6. Challenge each other's assumptions respectfully\n            7. Build on each other's ideas and insights\n            8. Create a natural back-and-forth technical dialogue\n            \n            SPECIALIZED AGENTS: This is crucial - ask questions only YOU would think to ask!\n            \n            Focus areas for technical questions:\n            - Domain-specific methodological concerns\n            - Interdisciplinary connections and conflicts\n            - Alternative interpretations from different expert perspectives\n            - Practical applications in each specialist's field\n            - Potential limitations or biases from multiple viewpoints\n            \n            Format this as a realistic TECHNICAL conversation with clear speaker identification for ALL conversation participants.\n            Keep the tone SERIOUS and TECHNICAL - humor will be added later in post-production.\n            \n            Language: Spanish\n            ",
      "expected_output": "Dynamic technical Q&A conversation between conversation agents only (no post-production or humor)",
      "agent_role": "Technical Content Specialist"
    },
    {
      "description": "\n            Organize a structured technical debate where conversation agents with different viewpoints engage in deeper discussion.\n            \n            PARTICIPATING AGENTS (technical conversation only):\n            - Base conversation agents (Coordinator, Scientific Reviewer, Critical Thinker)\n            - ALL specialized domain agents  \n            \n            EXCLUDED FROM DEBATE: Master Educational Science Communicator & Storyteller and Comedy Communicator (work in post-production)\n            \n            Technical debate structure:\n            1. Present the main controversial points or interpretations from the paper\n            2. Have TECHNICAL CONVERSATION AGENTS take different positions and argue their cases\n            3. SPECIALIZED AGENTS: Argue from your domain expertise - what would your field say?\n            4. Allow for rebuttals and counter-arguments between different expert perspectives\n            5. Explore edge cases and hypothetical scenarios from multiple disciplinary angles\n            6. Find areas of agreement and persistent disagreements between different specialties\n            7. Synthesize different viewpoints into a richer technical understanding\n            \n            This should feel like a real interdisciplinary TECHNICAL conference where:\n            - Different specialists bring unique perspectives that sometimes conflict\n            - Domain experts interrupt each other (politely) to make field-specific points\n            - Ideas evolve through interaction between different areas of expertise\n            - New insights emerge from cross-disciplinary exchange\n            - There's intellectual tension between different specialist viewpoints\n            \n            SPECIALIZED AGENTS: Don't hold back - defend your field's perspective!\n            \n            Make it conversational and dynamic, but keep TECHNICAL FOCUS - humor will be added later.\n            \n            Language: Spanish\n            ",
      "expected_output": "Rich interdisciplinary technical debate between conversation agents only (no post-production or humor)",
      "agent_role": "Methodology Explainer"
    },
    {
      "description": "\n            Conduct a collaborative synthesis where technical conversation agents work together to build a comprehensive understanding.\n            \n            PARTICIPATING AGENTS (technical conversation only):\n            - Base conversation agents (Coordinator, Scientific Reviewer, Critical Thinker)\n            - ALL specialized domain agents\n            \n            EXCLUDED FROM SYNTHESIS: Master Educational Science Communicator & Storyteller and Comedy Communicator (work in post-production)\n            \n            Technical collaborative process:\n            1. ALL TECHNICAL CONVERSATION AGENTS contribute their key insights from the discussions\n            2. SPECIALIZED AGENTS highlight unique perspectives only your field can provide\n            3. Agents build on each other's contributions in real-time\n            4. Identify connections between different specialist perspectives\n            5. Resolve conflicting interpretations through interdisciplinary dialogue\n            6. Co-create new insights that emerge from cross-domain discussion\n            7. Establish consensus on the most important takeaways from ALL conversation perspectives\n            \n            This should be a generative TECHNICAL conversation where:\n            - Ideas from one specialist spark new ideas in other specialists\n            - The group intelligence exceeds individual specialist perspectives\n            - Agents actively listen and respond to insights from other domains\n            - The conversation flows naturally between different areas of expertise\n            - New understanding emerges from interdisciplinary interaction\n            - Each specialist's unique knowledge contributes to the whole\n            \n            SPECIALIZED AGENTS: Share insights that ONLY someone with your expertise would have!\n            \n            Format as natural TECHNICAL conversation with organic transitions between specialist viewpoints.\n            Keep SERIOUS and FOCUSED - entertainment will be added later in post-production.\n            \n            Language: Spanish\n            ",
      "expected_output": "Collaborative technical synthesis conversation from conversation agents only (no post-production or humor)",
      "agent_role": "Research Coordinator"
    },
    {
      "description": "\n            Based on all previous conversations and analyses, conduct a final comprehensive technical discussion that synthesizes insights from conversation agents.\n            \n            PARTICIPATING AGENTS (technical conversation only):\n            - Base conversation agents (Coordinator, Scientific Reviewer, Critical Thinker)\n            - ALL specialized domain agents\n            \n            EXCLUDED: Master Educational Science Communicator & Storyteller and Comedy Communicator (they will process this output in post-production)\n            \n            The final technical discussion should:\n            1. Synthesize insights from the Q&A, specialist deep dive, debate, and collaborative sessions\n            2. Cover all major points of the paper from multiple expert perspectives\n            3. Include the rich specialist perspectives developed through agent interactions\n            4. Address concerns and criticisms that emerged from different domains\n            5. Explore implications and applications discussed by various specialists\n            6. Be comprehensive and technically rigorous for expert audiences\n            7. Highlight unique insights that could ONLY come from having multiple specialist perspectives\n            \n            CRITICAL: This final technical discussion must incorporate:\n            - Domain-specific insights from ALL specialist conversation agents\n            - Cross-disciplinary connections discovered during discussions\n            - Unique perspectives that emerged from interdisciplinary dialogue\n            - Technical depth and rigor appropriate for expert audiences\n            \n            This is the FINAL technical conversation output that will be handed to the post-production team.\n            Make it comprehensive, rigorous, and rich with all the insights gathered.\n            Keep it TECHNICAL and SERIOUS - post-production will handle accessibility and entertainment.\n            \n            Language: Spanish\n            ",
      "expected_output": "Final comprehensive technical discussion ready for post-production processing",
      "agent_role": "Technical Content Specialist"
    },
    {
      "description": "\n            Transform the previous task outputs into a technical presentation with ZERO interpretation.\n            \n            DOCUMENT TITLE: # Azure’s Generative AI and Foundation Model Services\n            \n            You must review ALL previous outputs and create a technical document that:\n            1. Presents ONLY factual information\n            2. Removes ALL interpretive language (revolutionary, groundbreaking, etc.)\n            3. States findings directly without implications\n            4. Uses technical manual style - clear and objective\n            5. Never adds \"this suggests\", \"this implies\", etc.\n            \n            \nCreate a technical presentation of the following content titled \"# Azure’s Generative AI and Foundation Model Services\".\n\nCONTENT TO PRESENT:\nUse the complete discussion from all previous tasks\n\nYOUR MISSION: Present this content with absolute clarity and zero interpretation.\n\nCRITICAL REQUIREMENTS:\n\n1. **DIRECT PRESENTATION ONLY**:\n   - State facts exactly as they appear\n   - Present concepts without interpretation\n   - List ideas without adding implications\n   - NO \"This suggests...\", \"This implies...\", \"This demonstrates...\"\n   - NO reflections or commentary\n\n2. **STRUCTURE**:\n   - Use clear headings and subheadings\n   - Present information in logical order\n   - Use bullet points for lists\n   - Number sequences or steps\n   - Group related concepts together\n\n3. **LANGUAGE RULES**:\n   - Use simple, technical language\n   - Define technical terms when first used\n   - Avoid adjectives that add interpretation\n   - No emotional or subjective language\n   - Be concise and precise\n\n4. **CONTENT FIDELITY**:\n   - ONLY include factual information\n   - STRIP OUT all interpretive language from source\n   - Remove adjectives like \"revolutionary\", \"brilliant\", \"remarkable\"\n   - Convert subjective statements to objective facts\n   - NEVER add examples not in the source\n   - NEVER draw conclusions not stated\n   - NEVER add context or background\n   - NEVER interpret or analyze\n\n5. **FORMATTING**:\n   - Use markdown for structure\n   - Clear hierarchy with headers\n   - Bullet points for lists\n   - Code blocks for technical content\n   - Tables where appropriate\n\nEXAMPLES OF WHAT TO AVOID:\n❌ \"This revolutionary approach transforms how we think about...\"\n❌ \"The implications of this finding are profound...\"\n❌ \"This suggests a new paradigm in...\"\n❌ \"Interestingly, the authors reveal...\"\n❌ \"This demonstrates the power of...\"\n❌ \"This groundbreaking research...\"\n❌ \"The brilliant approach...\"\n❌ \"Remarkable findings...\"\n\nREMOVE INTERPRETIVE WORDS:\n- Revolutionary → [remove or say \"new\"]\n- Groundbreaking → [remove or say \"recent\"]\n- Brilliant/Remarkable → [remove completely]\n- Paradigm shift → \"change\" or remove\n- Transforms → \"changes\" or state the change directly\n\nEXAMPLES OF CORRECT STYLE:\n✅ \"The approach uses three components: A, B, and C.\"\n✅ \"The study found X increased by 47%.\"\n✅ \"The algorithm consists of four steps: [list steps]\"\n✅ \"The framework defines Y as Z.\"\n✅ \"Results: [direct statement of results]\"\n\nCONVERSION EXAMPLES:\n- \"Revolutionary deep learning architecture\" → \"Deep learning architecture\"\n- \"Groundbreaking research demonstrates\" → \"Research shows\" or \"Study finds\"\n- \"Brilliant approach reveals\" → \"Approach shows\" or \"Method indicates\"\n- \"Remarkable 95% accuracy\" → \"95% accuracy\"\n- \"Paradigm shift in design\" → \"New design approach\" or \"Design change\"\n\nTARGET LENGTH: comprehensive\nLANGUAGE: Spanish\n\nRemember: You are a technical manual writer, not a storyteller or analyst.\nPresent the content. Define the concepts. List the ideas. Nothing more.\n\n            ",
      "expected_output": "Technical presentation with zero interpretation - only facts and concepts as stated",
      "agent_role": "Technical Content Specialist"
    }
  ]
}