Section: Section 4
Characters: 264
==================================================
The section boldly reframes the idea of evolution by proposing that complexity increases universally—not just within living organisms but across all systems, including nonliving matter. It begins by invoking the Fermi paradox, traditionally used to question why alien civilizations have not been observed, and turns this on its head with the provocative suggestion that intelligent life might be far more common than previously assumed. Central to this argument is the concept of “functional information”: a measure not of raw data, but of information that directly contributes to an entity’s capacity to perform useful tasks. This notion, first articulated by biologist Jack Szostak in 2003, distinguishes between mere complexity and the kind of complexity that results in function. For instance, experimental evolution with RNA aptamers demonstrated that as these molecules are evolved in the lab, their ability to perform specific binding functions increases toward a theoretical maximum, suggesting that evolution is an active process of accumulating function.

The discussion builds on work by researchers such as mineralogist Robert Hazen and astrobiologist Michael Wong, who extend the implications of functional information well beyond traditional biology, proposing that even chemical and mineral systems evolve by accumulating such information. Hazen’s research, driven by origins-of-life questions, argues that the commonly assumed divide between the living and the nonliving is artificial when viewed through the lens of an evolving system driven by a universal principle. Computer simulations and interdisciplinary experiments further support the hypothesis that, irrespective of the initial chemical or physical framework, systems naturally progress toward states of higher functional information—challenging the predictive limits of classic Darwinian evolution.

A critical nuance in this section is the incorporation of ideas reminiscent of Gödel’s incompleteness theorem. Just as no formal mathematical system can prove every true statement without new axioms, the process of evolution is seen as “open‐ended” and self‐referential. As new components emerge within an evolving system, they feed back into the system and reshape its phase space, effectively creating a continual expansion of possible functions and strategies. This self‐reinforcing process implies that complexity is not merely a passive accumulation of parts; it is an active, dynamic progression where new, previously unimagined possibilities emerge. This “magic of life” becomes even more pronounced when complex cognition is involved, further accelerating the evolution toward higher complexity.

The section also introduces assembly theory—a framework developed in collaboration with figures like Lee Cronin and Sara Walker—to quantify complexity using an “assembly index.” This index measures the number of steps required to construct an object from basic components, offering a tangible way to assess the emergence of function. Nonetheless, the authors acknowledge significant challenges. Quantifying functional information remains inherently context-dependent, and critics argue that such measures, while philosophically appealing, may prove untestable by conventional scientific methods.

Zooming out, the text highlights broad and profound implications. If functional information truly drives evolution in both living and nonliving systems, it suggests that increasing complexity might be as fundamental a law of nature as the second law of thermodynamics (which governs the increase of entropy). In other words, just as entropy provides a directional “arrow of time,” the selective accumulation of useful information could define an “arrow of complexity.” This paradigm not only blurs the boundaries between biology and physics but also opens exciting interdisciplinary avenues—from astrobiology (using biosignatures of organic molecule repertoires to detect life elsewhere) to fields such as oncology, soil science, and the study of language evolution.

Finally, the section confronts controversy head-on. Critics caution that applying the concept of functional information beyond biological systems may be overextending the term and that the inherent difficulties in measuring such information could render the theory nearly untestable. Yet, the authors maintain that the conceptual framework, even if imperfectly quantifiable, is robust enough to encourage a radical reassessment of evolution. It is a call to view evolution not as a confined biological process, but as a universal trend where the emergence of new causal laws may eventually overtake old ones—as seen when cognitive processes influence technology or when the evolution of life reshapes planetary and even cosmic systems.

In summary, this section articulates a transformative view of evolution as an open-ended, universally applicable process that functions by accumulating functional information. It links detailed experimental evidence—like the evolution of RNA aptamers and computational simulations—with deep philosophical ideas reminiscent of Gödel’s theorem, ultimately arguing for a shift in our understanding of natural laws. Whether viewed as a new stage in Darwinian evolution or as a supplementary law that governs the rise of complexity across all matter, this perspective has far-reaching implications for our understanding of life, intelligence, and the universe itself.