TLDR:
• The paper proposes that complexity increases universally over time—not just in biological evolution but across all systems—driven by an accumulation of "functional information."
• Key insights include experimental evidence from RNA aptamer evolution, computer simulations, and the introduction of assembly theory, all of which reveal that evolution is an open‐ended process akin to a universal physical law.
• The primary implication is that this novel perspective unifies biological evolution with physical processes (like entropy increase) and suggests that new emergent laws and perhaps abundant intelligent life might be inevitable outcomes of the universe’s drive toward complexity.

The paper presents a transformative view on evolution by arguing that complexity is not just a quirk of life but a fundamental, universal process. It begins by challenging the traditional boundaries that restrict evolution to biological systems. Instead, it posits that a mechanism—centered on the selective accumulation of “functional information”—underpins the entire progression of complexity in both living organisms and nonliving systems. The story is opened by revisiting the Fermi paradox, typically a puzzle over the absence of extraterrestrial signals despite the long time available for life to evolve. The authors flip the script by suggesting that if evolution universally favors complexity via functional information, then intelligent life might be widespread, even if its manifestations are unpredictable and evolve in diverse forms.

The notion of functional information, originally articulated by Jack Szostak in 2003, becomes a cornerstone of the argument. Unlike classical measures of information that quantify data without regard to its use, functional information refers to the specific, measurable capacity a system has to perform a task. The lab evolution of RNA aptamers illustrates this concept: as these molecules are iteratively refined, not only does their binding performance improve, but their functional information approaches a theoretical limit—a concrete demonstration that evolution is about quality, not merely quantity.

Building on this, researchers such as Robert Hazen and Michael Wong employ an interdisciplinary approach to blur the line between living and nonliving systems. Their work—integrating insights from mineralogy, astrobiology, and even computer simulations—suggests that the spontaneous accumulation of functional information is a ubiquitous process. This means that traditional Darwinian evolution may be just one manifestation of a broader physical principle where evolving systems continuously “climb to a next floor” of complexity by unlocking new functionalities and strategies.

A further layer is added by drawing an analogy with Gödel’s incompleteness theorem. Just as no formal mathematical system can encapsulate all truths without the need for additional axioms, evolution is seen as open‐ended and self‐referential. As new components emerge in a system, they reshape the “phase space”—the landscape of possibilities—thereby creating unforeseen opportunities for new functions. This idea elegantly encapsulates the “magic of life,” where each evolutionary step not only builds on the past but also redefines the very rules of progression.

The discussion is enriched with the introduction of assembly theory, particularly through the concept of an “assembly index.” This metric quantifies complexity by counting the minimum number of building steps needed to construct an object from basic components. Although this idea is promising in potentially providing a measurable framework for functional information, the paper does not shy away from the controversy it raises. Critics argue that context-dependent measures of functionality make the universal application of such a law problematic, noting that while the idea is philosophically compelling, it remains challenging to test and validate empirically.

By integrating experimental results (from RNA aptamer work and computer simulations) with deep philosophical reflections, the paper advocates a profound synthesis: evolution, defined by the accumulation of functional information, might be as fundamental and inevitable as the second law of thermodynamics. This perspective not only bridges biology with physics but also extends into cosmology, suggesting that, much like entropy, there exists an "arrow of complexity." Such an arrow implies that as the universe evolves, systems naturally trend toward higher complexity and enhanced capability, whether in the formation of minerals, the emergence of cellular life, or even the development of higher intelligence and technological evolution.

In conclusion, the paper calls for a radical rethinking of evolution as a universal, open‐ended, and self‐reinventing process. It forces us to reconsider the conventional boundaries between living and nonliving systems and to view evolution through the twin lenses of functional information and emergent new causal laws. This not only reshapes our understanding of life’s origins and its potential proliferation across the cosmos but also provides a fertile conceptual framework for future interdisciplinary research in fields ranging from astrobiology to oncology and beyond.