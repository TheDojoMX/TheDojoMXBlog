Developing software with Foundation Models <break time="1.5s"/>
Model Scale y Requerimientos de Datos <break time="1.0s"/>
Modelos de IA (por ejemplo, ChatGPT, Google’s Gemini, Midjourney) requieren: <break time="0.5s"/>
- Grandes cantidades de electricidad <break time="0.5s"/>
- Vastos volúmenes de datos públicos de internet para entrenamiento <break time="1.0s"/>
Ejemplos de escala de modelos: <break time="0.5s"/>
- GPT (junio de 2018): 117 millones de parámetros <break time="0.5s"/>
- GPT-2 (febrero de 2019): 1,5 mil millones de parámetros <break time="0.5s"/>
- Modelos actuales: miles de millones de parámetros <break time="1.5s"/>
Consecuencias del Escalado de Modelos <break time="1.0s"/>
- Mayor capacidad: <break time="0.5s"/>
  - Mayor poder para realizar una amplia gama de tareas <break time="0.5s"/>
  - Incremento en la productividad, valor económico y calidad de vida <break time="1.0s"/>
- Requerimientos de recursos limitados: <break time="0.5s"/>
  - Entrenamiento exige datos significativos, recursos de cómputo y talento especializado <break time="0.5s"/>
  - Uso de modelos como servicio permite construir aplicaciones sin desarrollar un modelo desde cero <break time="1.5s"/>
Definiciones y Conceptos Básicos en Modelado de Lenguaje <break time="1.0s"/>
- Modelo de lenguaje: <break time="0.5s"/>
  - Modelo que codifica información estadística para predecir la probabilidad de aparición de palabras en un contexto dado <break time="1.0s"/>
- Token: <break time="0.5s"/>
  - Unidad básica en modelado de lenguaje (carácter, palabra o parte de una palabra) <break time="0.5s"/>
  - Ejemplo: GPT-4 tokeniza “I can’t wait to build AI applications” en nueve tokens <break time="1.5s"/>
- Proceso de tokenización: <break time="0.5s"/>
  - Fraccionamiento del texto en tokens <break time="0.5s"/>
  - Longitud promedio: aproximadamente ¾ de una palabra (100 tokens ≈ 75 palabras) <break time="1.0s"/>
- Vocabulario: <break time="0.5s"/>
  - Conjunto de todos los tokens que un modelo puede procesar <break time="0.5s"/>
  - Ejemplos: <break time="0.5s"/>
    - Mixtral 8x7B: 32,000 tokens <break time="0.5s"/>
    - GPT-4: 100,256 tokens <break time="1.5s"/>
Razones para Utilizar Tokens en Lugar de Palabras o Caracteres <break time="1.0s"/>
1. Permiten dividir palabras en componentes significativos <break time="0.5s"/>
2. Menor cantidad de tokens únicos reduce el tamaño del vocabulario <break time="0.5s"/>
3. Permiten procesar palabras desconocidas dividiendo en partes conocidas <break time="1.5s"/>
Tipos de Modelos de Lenguaje <break time="1.0s"/>
- Modelos de lenguaje enmascarados: <break time="0.5s"/>
  - Predicen tokens faltantes en cualquier parte de una secuencia utilizando contexto de ambos lados (ejemplo: BERT) <break time="0.5s"/>
  - Uso común en tareas no generativas (análisis de sentimiento, clasificación de texto, depuración de código) <break time="1.0s"/>
- Modelos de lenguaje autoregresivos: <break time="0.5s"/>
  - Predicen el siguiente token basándose en los tokens precedentes <break time="0.5s"/>
  - Generan tokens secuencialmente, preferidos para generación de texto <break time="1.5s"/>
Generative AI <break time="1.0s"/>
- Modelo generativo: <break time="0.5s"/>
  - Utiliza su vocabulario finito para construir infinitas salidas posibles (completaciones abiertas) <break time="0.5s"/>
  - Completaciones basadas en probabilidades estadísticas <break time="1.0s"/>
- Ejemplos de completaciones: <break time="0.5s"/>
  - Continuación de “To be or not to be”: “, that is the question.” <break time="0.5s"/>
  - Traducción de “How are you in French is …”: “Comment ça va.” <break time="0.5s"/>
  - Clasificación: Ejemplo en detección de spam <break time="1.5s"/>
Contexto Histórico y Métodos de Entrenamiento <break time="1.0s"/>
- Primeros modelos de lenguaje: surgieron en la década de 1950 <break time="0.5s"/>
- Claude Shannon (1951): <break time="0.5s"/>
  - Introdujo conceptos estadísticos (como la entropía) utilizados en el modelado de lenguaje <break time="1.0s"/>
- Self-supervision: <break time="0.5s"/>
  - Método para escalar modelos a tamaños actuales <break time="0.5s"/>
  - Entrenamiento en el que el modelo infiere etiquetas a partir de los datos de entrada <break time="1.5s"/>
Detalles de Datos y Proceso de Entrenamiento <break time="1.0s"/>
- Ejemplo de muestra de entrenamiento ("I love street food."): <break time="0.5s"/>
  1. Entrada: BOS  Salida: BOS, I <break time="0.5s"/>
  2. Entrada: BOS, I  Salida: love <break time="0.5s"/>
  3. Entrada: BOS, I, love  Salida: street <break time="0.5s"/>
  4. Entrada: BOS, I, love, street  Salida: food <break time="0.5s"/>
  5. Entrada: BOS, I, love, street, food  Salida: BOS, I, love, street, food, . <break time="0.5s"/>
  6. Entrada: BOS, I, love, street, food, .  Salida: EOS <break time="1.0s"/>
  - BOS (Beginning Of Sequence) y EOS (End Of Sequence) son tokens especiales <break time="1.5s"/>
- Parámetros del modelo: <break time="0.5s"/>
  - "Model weights" se refiere a todos los parámetros actualizados durante el entrenamiento <break time="1.5s"/>
Modelos Multimodales y Foundation Models <break time="1.0s"/>
- Extensión de modelos de lenguaje para incorporar otras modalidades (imágenes, video, 3D, estructuras de proteínas) <break time="0.5s"/>
- Modelos multimodales: <break time="0.5s"/>
  - También denominados LMM (Large Multimodal Models) <break time="0.5s"/>
  - Ejemplos: GPT-4V, Claude 3 <break time="1.5s"/>
- CLIP: <break time="0.5s"/>
  - Modelo embedding entrenado con 400 millones de pares (imagen, texto) <break time="0.5s"/>
  - Diseñado para generar embeddings conjuntos para textos e imágenes <break time="1.5s"/>
Técnicas de Aprendizaje y Enfoques de Entrenamiento <break time="1.0s"/>
- Auto-supervisión: <break time="0.5s"/>
  - Etiquetas inferidas de los datos de entrada <break time="1.0s"/>
- Aprendizaje supervisado: <break time="0.5s"/>
  - Uso de ejemplos manualmente etiquetados (ejemplo: AlexNet con ImageNet) <break time="1.0s"/>
- Diferencias en técnicas: <break time="0.5s"/>
  - Finetuning (ajuste fino): Actualiza pesos de un modelo pre-entrenado utilizando menos datos <break time="0.5s"/>
  - Prompt engineering: Proporciona instrucciones y contexto sin actualizar pesos <break time="1.5s"/>
Herramientas y Procesos en AI Engineering <break time="1.0s"/>
- AI engineering: <break time="0.5s"/>
  - Construcción de aplicaciones sobre modelos base <break time="0.5s"/>
  - Diferentes del ML tradicional en cuanto a participación en las decisiones de producto <break time="1.0s"/>
- Técnicas de adaptación de modelos: <break time="0.5s"/>
  1. Prompt engineering: <break time="0.5s"/>
     - Adaptación sin actualizar pesos mediante instrucciones detalladas <break time="0.5s"/>
  2. Finetuning: <break time="0.5s"/>
     - Aumento de calidad, reducción de latencia y costo tras actualización de pesos <break time="1.5s"/>
- Responsabilidades del desarrollo de modelos: <break time="1.0s"/>
  1. Modelado y entrenamiento: <break time="0.5s"/>
     - Diseño, entrenamiento y ajuste fino de arquitecturas <break time="0.5s"/>
     - Herramientas: TensorFlow, PyTorch, Hugging Face Transformers <break time="1.0s"/>
  2. Ingeniería de conjuntos de datos: <break time="0.5s"/>
     - Curación, deduplicación, tokenización y control de calidad de datos no estructurados <break time="1.0s"/>
  3. Optimización de inferencia: <break time="0.5s"/>
     - Técnicas de cuantización, destilación y paralelismo para reducir latencia <break time="1.5s"/>
Comparación entre ML Tradicional y AI Engineering <break time="1.0s"/>
- ML tradicional: <break time="0.5s"/>
  - Enfocado en entrenamiento desde cero y datos tabulares (feature engineering) <break time="1.0s"/>
- AI engineering: <break time="0.5s"/>
  - Utiliza modelos pre-entrenados (foundation models) <break time="0.5s"/>
  - Incluye etapas de evaluación, prompt engineering y construcción de interfaces de usuario <break time="0.5s"/>
  - Requiere manejo de datos no estructurados (deduplicación, tokenización, control de calidad) <break time="1.5s"/>
Aplicaciones y Casos de Uso de Foundation Models <break time="1.0s"/>
- Casos de uso en diferentes sectores: <break time="0.5s"/>
  - AWS: experiencia del cliente, productividad, optimización de procesos <break time="0.5s"/>
  - Programación, análisis de datos, atención al cliente, redacción y diseño web <break time="0.5s"/>
  - Reducción de costos, eficiencia, crecimiento y aceleración de la innovación en empresas <break time="1.0s"/>
- Ejemplos en coding: <break time="0.5s"/>
  - GitHub Copilot genera ingresos anuales > $100 millones <break time="0.5s"/>
  - Herramientas para extracción de datos, conversión de lenguajes y generación de documentación <break time="1.5s"/>
- Ejemplos en marketing: <break time="0.5s"/>
  - Generación de imágenes y videos promocionales con Midjourney, Adobe Firefly, Runway <break time="0.5s"/>
  - Uso en brainstorming y prueba de variantes de anuncios <break time="1.5s"/>
Uso de AI en Otras Áreas <break time="1.0s"/>
- Escritura: <break time="0.5s"/>
  - Autocorrector, autocompletado y transformación de tono en correos <break time="0.5s"/>
  - Aplicaciones para redacción de ensayos, libros y reportes <break time="0.5s"/>
  - Integración en herramientas como Google Docs, Notion, Gmail y Grammarly <break time="1.0s"/>
- Optimización SEO: <break time="0.5s"/>
  - Generación de contenido optimizado y aparición de granjas de contenido <break time="1.0s"/>
- Educación: <break time="0.5s"/>
  - Resumen de libros de texto, planes de lecciones personalizados y adaptación de materiales <break time="0.5s"/>
  - Herramientas en Duolingo, Khan Academy y asignación de ensayos para corrección <break time="1.0s"/>
- Bots conversacionales: <break time="0.5s"/>
  - Funciones de búsqueda, explicación de conceptos, generación de ideas y respuesta a solicitudes <break time="0.5s"/>
  - Implementaciones en chatbots, asistentes de voz (Google Assistant, Siri, Alexa) y interfaces 3D <break time="1.5s"/>
Operaciones y Estrategia en AI <break time="1.0s"/>
- Impacto en operaciones empresariales: <break time="0.5s"/>
  - Mejora en adquisición y retención de usuarios mediante contenido personalizado <break time="0.5s"/>
  - Generación de prospectos, apoyo en comunicación interna e investigación de mercado <break time="1.0s"/>
- Consideraciones estratégicas: <break time="0.5s"/>
  - Riesgo de rezagarse al retrasar inversiones en tecnología AI <break time="0.5s"/>
  - Decisión entre desarrollar internamente o externalizar la solución <break time="1.5s"/>
Arquitectura y Componentes del Stack de AI Engineering <break time="1.0s"/>
- Capas del stack de AI: <break time="0.5s"/>
  1. Desarrollo de aplicaciones: <break time="0.5s"/>
     - Ingeniería de prompts, evaluación (TTFT, TPOT, latencia, costo por inferencia) y construcción de interfaces (apps web, móviles, de escritorio; extensiones de navegador; chatbots) <break time="1.0s"/>
  2. Desarrollo de modelos: <break time="0.5s"/>
     - Modelado, entrenamiento, ajuste fino, ingeniería de conjuntos de datos y optimización de inferencia <break time="1.0s"/>
  3. Infraestructura: <break time="0.5s"/>
     - Herramientas para servir modelos, gestión de datos, escalamiento de recursos de cómputo y monitoreo de desempeño <break time="1.5s"/>
- Ejemplos de plataformas de integración: <break time="0.5s"/>
  - VSCode (Copilot), GitHub Copilot, Grammarly, Streamlit, Gradio, Plotly Dash <break time="1.5s"/>
- Evolución de frameworks: <break time="0.5s"/>
  - Soporte creciente para APIs en JavaScript (LangChain.js, Transformers.js, OpenAI’s Node library, Vercel’s AI SDK) <break time="1.5s"/>
Métricas, Evaluación y Planificación de Proyectos de AI <break time="1.0s"/>
- Métricas de negocio: <break time="0.5s"/>
  - Porcentaje de mensajes automatizados, número de mensajes adicionales, reducción del tiempo de respuesta, ahorro en mano de obra <break time="1.0s"/>
- Métricas de utilidad: <break time="0.5s"/>
  - Calidad de respuestas, latencia (TTFT, TPOT, latencia total), costo por solicitud de inferencia, interpretabilidad y equidad <break time="1.0s"/>
- Planificación de hitos: <break time="0.5s"/>
  - Evaluación de modelos off-the-shelf y determinación del trabajo necesario para alcanzar objetivos de automatización <break time="1.0s"/>
- Desafíos en la evolución de productos AI: <break time="0.5s"/>
  - El “último kilómetro” requiere esfuerzos adicionales tras la creación de demos rápidos <break time="0.5s"/>
  - Necesidad de análisis de costo-beneficio y adaptación a cambios regulatorios y de mercado <break time="1.5s"/>
Optimización y Desempeño en Inferencia <break time="1.0s"/>
- Desafíos en generación autoregresiva: <break time="0.5s"/>
  - Generación secuencial de tokens (por ejemplo, 10 ms por token; 100 tokens ≈ 1 segundo) <break time="0.5s"/>
  - Técnicas de optimización: cuantización, destilación, paralelismo <break time="1.5s"/>
- Importancia de la optimización para alcanzar latencias en el rango de milisegundos <break time="1.5s"/>
Responsabilidades en el Desarrollo y Evaluación de Modelos <break time="1.0s"/>
- Diferencias entre entrenamiento, pre-entrenamiento, finetuning y post-training: <break time="0.5s"/>
  - Entrenamiento: Cambios en los pesos del modelo (incluye cuantización) <break time="0.5s"/>
  - Pre-entrenamiento: Entrenamiento desde cero con pesos aleatorios (muy intensivo en recursos) <break time="0.5s"/>
  - Finetuning: Continuación del entrenamiento de un modelo pre-entrenado con menor requerimiento de datos <break time="0.5s"/>
  - Post-training: Actualizaciones realizadas por desarrolladores para mejorar seguimiento de instrucciones <break time="1.5s"/>
Integración y Evaluación de Interfaces de Usuario <break time="1.0s"/>
- Construcción de interfaces (AI interface): <break time="0.5s"/>
  - Aplicaciones independientes (web, escritorio, móvil) <break time="0.5s"/>
  - Extensiones de navegador, chatbots en apps de mensajería y API integradas <break time="0.5s"/>
  - Herramientas comunes: Streamlit, Gradio, Plotly Dash <break time="1.0s"/>
- Evaluación para mitigar riesgos y descubrir oportunidades: <break time="0.5s"/>
  - Benchmarking, evaluación de progreso y detección de fallas en producción <break time="1.5s"/>
Datos y Especificaciones Técnicas <break time="1.0s"/>
- Ejemplos de vocabularios: <break time="0.5s"/>
  - Mixtral 8x7B: 32,000 tokens <break time="0.5s"/>
  - GPT-4: 100,256 tokens <break time="1.0s"/>
- Proceso de tokenización y uso de tokens especiales (BOS y EOS) <break time="0.5s"/>
- Métodos y algoritmos: <break time="0.5s"/>
  - Tokenization, masked language modeling (BERT), autoregressive language modeling <break time="0.5s"/>
  - Self-supervision, aprendizaje supervisado y técnicas de finetuning y prompt engineering <break time="1.0s"/>
- Resultados y mediciones: <break time="0.5s"/>
  - Ejemplo de mejora: Gemini Ultra mejoró en MMLU de 83,7% a 90,04% usando CoT@32 <break time="0.5s"/>
  - Costos de etiquetado de datos y rentabilidad en casos de uso (GitHub Copilot, Midjourney) <break time="1.5s"/>
Relevancia de Datos en Aplicaciones y Operaciones <break time="1.0s"/>
- Datos de productividad en ingeniería: <break time="0.5s"/>
  - Documentación: productividad duplicada <break time="0.5s"/>
  - Generación y refactorización de código: mejora del 25% al 50% <break time="1.0s"/>
- Exposición en ocupaciones (porcentajes entre 66,7% y 100%) <break time="0.5s"/>
- Disposición de recursos y evaluación del modelo (por ejemplo, automatizar tickets de soporte) <break time="1.5s"/>
Consideraciones Finales en AI Engineering <break time="1.0s"/>
- Diferencias entre trabajo con foundation models y modelos tradicionales de ML: <break time="0.5s"/>
  - Enfoque en ajustar (tweaking) models base <break time="0.5s"/>
  - Participación intensiva de ingenieros AI en el desarrollo del producto <break time="1.0s"/>
- Herramientas emergentes: <break time="0.5s"/>
  - ansformers.js, OpenAI’s Node library, Vercel’s AI SDK <break time="1.0s"/>
- Evolución del proceso: <break time="0.5s"/>
  - De ML tradicional (recopilación de datos y entrenamiento final) a AI engineering (iteración rápida y adaptación durante el desarrollo del producto) <break time="0.5s"/>
  - El rol de los ingenieros AI: <break time="0.5s"/>
    - Muchas proceden de desarrollo web o full-stack, permitiendo iterar rápido y transformar ideas en demos <break time="1.5s"/>
Especificaciones Técnicas Adicionales <break time="1.0s"/>
- Modelos base: ChatGPT, Google’s Gemini, Midjourney <break time="0.5s"/>
- Requerimientos de datos y consumo de energía <break time="0.5s"/>
- Herramientas de adaptación y optimización de inferencia: <break time="0.5s"/>
  - Técnicas: cuantización, destilación, paralelismo <break time="0.5s"/>
  - Enfoque en reducción de latencia durante generación secuencial de tokens <break time="1.5s"/>
Flujo de Trabajo y Metodología de AI Engineering <break time="1.0s"/>
- Proceso “Crawl-Walk-Run”: <break time="0.5s"/>
  1. Crawl: Participación humana obligatoria <break time="0.5s"/>
  2. Walk: Interacción directa de AI con empleados internos <break time="0.5s"/>
  3. Run: Automatización casi completa, incluyendo interacción directa con usuarios externos <break time="1.0s"/>
- Evaluación de modelos existentes y planificación de esfuerzos para alcanzar porcentajes deseados de automatización <break time="1.0s"/>
- Consideraciones en costo-beneficio y desafíos regulatorios (por ejemplo, cumplimiento de GDPR) <break time="1.5s"/>
Conclusión Técnica <break time="1.0s"/>
- Los foundation models constituyen la base para el desarrollo de aplicaciones de AI <break time="0.5s"/>
- La ingeniería AI integra: <break time="0.5s"/>
  - Adaptación de modelos pre-entrenados mediante prompt engineering y finetuning <break time="0.5s"/>
  - Procesos de ingeniería de conjuntos de datos y optimización de inferencia <break time="0.5s"/>
  - Desarrollo de interfaces y evaluación sistemática <break time="1.0s"/>
- Las aplicaciones abarcan múltiples sectores: codificación, marketing, educación, atención al cliente y operaciones empresariales <break time="1.5s"/>
Chapter 1: Introduction to Building AI Applications with Foundation Models <break time="1.5s"/>
- Frase inicial: "th the fun!" <break time="0.5s"/>
- Los foundation models son el bloque fundamental para posibilitar aplicaciones de AI <break time="0.5s"/>
- Integración de modalidades de datos (texto, imágenes, videos, etc.) en un solo modelo <break time="1.5s"/>
Especificaciones Técnicas y Datos <break time="1.0s"/>
- Modelos de ejemplo: ChatGPT, Google’s Gemini, Midjourney <break time="0.5s"/>
- Escalabilidad: desde 117 millones de parámetros hasta miles de millones <break time="0.5s"/>
- Requerimientos de datos: grandes cantidades de datos públicos y potencia de cómputo <break time="0.5s"/>
- Detalles de tokenización: definición de tokens, tokens especiales (BOS, EOS) y longitudes promedio <break time="0.5s"/>
- Ejemplo CLIP: <break time="0.5s"/>
  - Entrenado con 400 millones de pares (imagen, texto) <break time="0.5s"/>
  - Embedding para textos e imágenes <break time="1.5s"/>
Métodos, Algoritmos y Prácticas Experimentales <break time="1.0s"/>
- Tokenization: Fraccionamiento del texto en tokens para tratamiento estadístico <break time="0.5s"/>
- Modelados: <break time="0.5s"/>
  - Masked language modeling (BERT) <break time="0.5s"/>
  - Autoregressive language modeling para generación de texto <break time="0.5s"/>
- Técnicas de adaptación: <break time="0.5s"/>
  - Prompt-based techniques (prompt engineering) <break time="0.5s"/>
  - Finetuning para actualizar pesos del modelo <break time="1.5s"/>
Optimización de inferencia: <break time="1.0s"/>
- Cuantización, destilación, paralelismo para reducir latencia <break time="1.5s"/>
Resumen de la Infraestructura y el Stack de AI Engineering <break time="1.0s"/>
- Capas del stack: <break time="0.5s"/>
  1. Desarrollo de aplicaciones (interfaces, evaluación, prompt engineering) <break time="0.5s"/>
  2. Desarrollo de modelos (modelado, entrenamiento, ajuste fino, ingeniería de datos) <break time="0.5s"/>
  3. Infraestructura (servicio de modelos, gestión de datos, escalabilidad) <break time="1.0s"/>
- Prácticas de experimentación: <break time="0.5s"/>
  - Variación de prompts, algoritmos de recuperación, variables de muestreo <break time="0.5s"/>
  - Feedback loop para correr modelos más rápido y a menor costo <break time="1.5s"/>
Datos del Mercado y Estadísticas Relevantes <break time="1.0s"/>
- Costos de etiquetado: Ejemplo, 5 centavos por imagen; escalas altas pueden alcanzar decenas de millones <break time="1.0s"/>
- Productividad en ingeniería: <break time="0.5s"/>
  - Duplicación en la documentación y mejoras del 25% al 50% en generación y refactorización de código <break time="1.5s"/>
- Estadísticas de adopción y crecimiento: <break time="0.5s"/>
  - Incremento en términos de “Generative AI”, ChatGPT, Prompt Engineering en perfiles profesionales (75% de crecimiento mensual en LinkedIn) <break time="1.5s"/>
Rol y Definición de AI Engineering en el Contexto Actual <break time="1.0s"/>
- AI Engineering: <break time="0.5s"/>
  - Utiliza foundation models para construir aplicaciones de alta capacidad y flexibilidad <break time="0.5s"/>
  - Incluye adaptación de modelos, ingeniería de datos, optimización de inferencia e integración de interfaces <break time="1.0s"/>
- Diferencias frente a ML tradicional: <break time="0.5s"/>
  - De modelo desarrollado desde cero a adaptación de modelos pre-entrenados <break time="0.5s"/>
  - Enfoque en la iteración rápida y en involucrar al ingeniero en decisiones de producto <break time="1.5s"/>
Esta presentación consolida las ideas y conceptos técnicos fundamentales sobre los foundation models, la adaptación de modelos, la optimización de inferencia y la estructura del AI engineering, presentándolos de forma directa, organizada y con claridad técnica.