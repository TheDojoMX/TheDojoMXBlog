¡Hola! Hoy vamos a hablar sobre cómo desarrollar software con Foundation Models

¿Te has preguntado qué hay detrás de ChatGPT o Midjourney?

Bueno, estos modelos de IA necesitan dos cosas principales:
- Una cantidad enorme de electricidad para funcionar
- Y millones de datos de internet para aprender

Para que te hagas una idea de la escala, escucha esto:
- El primer GPT en 2018 tenía apenas 117 millones de parámetros
- GPT-2 al año siguiente ya tenía 1.5 mil millones
- Y los modelos de hoy en día... ¡tienen miles de millones!

¿Y qué significa esto para nosotros como desarrolladores?

Por un lado, es genial:
- Tenemos herramientas súper poderosas que pueden hacer casi cualquier cosa
- Esto nos ayuda a ser más productivos y crear más valor

Pero por otro lado:
- Entrenar estos modelos requiere recursos que la mayoría no tenemos
- La buena noticia es que podemos usar estos modelos como servicio, sin tener que crear uno desde cero

Ahora, déjame explicarte algunos conceptos básicos que necesitas conocer

¿Qué es exactamente un modelo de lenguaje?
Piénsalo como un sistema que entiende patrones estadísticos del lenguaje para predecir qué palabra viene después

Y aquí viene algo importante: los tokens
Un token no es exactamente una palabra completa, puede ser un carácter, una palabra, o parte de una palabra
Por ejemplo, si le dices a GPT-4 "I can't wait to build AI applications", lo divide en nueve tokens

La regla práctica es:
100 tokens son aproximadamente 75 palabras
¿Por qué? Porque cada token es como ¾ de una palabra en promedio

Cada modelo tiene su vocabulario:
- Mixtral 8x7B maneja 32,000 tokens
- GPT-4 puede trabajar con más de 100,000 tokens

¿Por qué usar tokens en lugar de palabras completas?
Es bastante inteligente:
1. Pueden dividir palabras en partes que sí conocen
2. Esto reduce el tamaño del vocabulario
3. Y pueden manejar palabras nuevas dividiéndolas en pedazos conocidos

Hablemos de los tipos de modelos que existen

Tienes los modelos enmascarados como BERT:

- Estos pueden "adivinar" palabras faltantes en medio de una oración
- Son excelentes para tareas como análisis de sentimientos o clasificar texto

Y luego están los modelos autoregresivos:
- Estos van palabra por palabra, prediciendo qué sigue
- Son los favoritos para generar texto nuevo

Ahora, ¿qué hace especial a la IA generativa?

Es como tener un vocabulario finito que puede crear infinitas combinaciones
Es como tener un conjunto limitado de piezas de LEGO, pero poder construir cualquier cosa

Por ejemplo:
- Le dices "To be or not to be" y completa ", that is the question"
- O le preguntas "How are you in French is..." y responde "Comment ça va"
- Incluso puede clasificar si un email es spam o no

Un poco de historia interesante
Los modelos de lenguaje no son nuevos, comenzaron en los años 50
Claude Shannon en 1951 introdujo conceptos como la entropía que todavía usamos hoy

Lo que cambió todo fue algo llamado "self-supervision"
Básicamente, el modelo aprende de los propios datos sin que tengamos que etiquetarlos manualmente

¿Quieres ver cómo entrena un modelo? Te muestro con un ejemplo simple
Tomemos la frase "I love street food"

El modelo aprende así:
1. Ve "BOS" (inicio), predice "I"
2. Ve "BOS, I", predice "love"
3. Ve "BOS, I, love", predice "street"
4. Y así sucesivamente hasta el final

BOS y EOS son como las mayúsculas y el punto final, pero para las máquinas

Ahora, algo súper emocionante: los modelos multimodales
Ya no solo trabajan con texto, también pueden entender imágenes, video, estructuras 3D, ¡hasta proteínas!

Modelos como GPT-4V y Claude 3 pueden ver y entender imágenes

Y está CLIP, que es fascinante:
Se entrenó con 400 millones de pares de imagen y texto
Puede entender la relación entre lo que ve y lo que lee

¿Cómo es diferente de entrenar un modelo tradicional?

En machine learning tradicional necesitas etiquetar todo manualmente
Pero con auto-supervisión, el modelo infiere las etiquetas de los propios datos

Y aquí vienen dos técnicas súper importantes:
- Finetuning: ajustas un modelo ya entrenado con tus datos específicos
- Prompt engineering: le das instrucciones claras sin cambiar nada del modelo

Ahora, ¿qué es exactamente AI Engineering?
Es básicamente construir aplicaciones encima de estos modelos poderosos
Y es muy diferente al ML tradicional porque participas activamente en las decisiones del producto

Tienes dos formas principales de adaptar modelos:
1. Prompt engineering: le das instrucciones súper detalladas
2. Finetuning: actualizas los pesos del modelo para tu caso específico

Las responsabilidades se dividen en tres áreas:
1. Modelado y entrenamiento con herramientas como TensorFlow y PyTorch
2. Ingeniería de datos: limpiar, organizar y preparar información no estructurada
3. Optimización de inferencia: hacer que todo funcione rápido y barato

La gran diferencia con ML tradicional es que:
- Antes construías todo desde cero
- Ahora usas modelos ya entrenados y los adaptas
- Puedes iterar súper rápido y probar ideas nuevas constantemente

¿Dónde se está usando esto? ¡En todas partes!
En programación:
- GitHub Copilot ya genera más de 100 millones de dólares al año
- Herramientas que escriben código, extraen datos y generan documentación

En marketing:
- Midjourney, Adobe Firefly, Runway para crear imágenes y videos
- Pruebas A/B automáticas de anuncios

En escritura:
- Autocorrectores inteligentes, autocompletado
- Ya está integrado en Google Docs, Notion, Gmail

En educación:
- Resúmenes automáticos de libros de texto
- Planes de estudio personalizados
- Duolingo y Khan Academy ya lo usan

Y por supuesto, chatbots que pueden:
- Buscar información
- Explicar conceptos complejos
- Generar ideas creativas
- Están en Google Assistant, Siri, Alexa

Para las empresas, esto significa:
- Mejor experiencia del cliente
- Equipos más productivos
- Procesos optimizados
- Y la capacidad de innovar más rápido

Pero ojo, también hay riesgos:
Si no inviertes en esta tecnología, te puedes quedar atrás
La pregunta es: ¿desarrollas internamente o contratas el servicio?

Hablemos del stack técnico, que tiene tres capas principales:

1. Desarrollo de aplicaciones:
Aquí trabajas con prompts, evalúas latencia y costo, y construyes interfaces web, móviles o chatbots

2. Desarrollo de modelos:
Modelado, entrenamiento, ajuste fino y preparación de datos

3. Infraestructura:
Servidores, gestión de datos, escalabilidad y monitoreo

Las herramientas populares incluyen:
VSCode con Copilot, Streamlit, Gradio, y cada vez más librerías de JavaScript

¿Cómo mides el éxito?

Métricas de negocio:
- Porcentaje de mensajes automatizados
- Reducción en tiempo de respuesta
- Ahorro en mano de obra

Métricas técnicas:
- Calidad de respuestas
- Latencia (qué tan rápido responde)
- Costo por solicitud

Un consejo importante: usa el enfoque "Crawl-Walk-Run"
1. Crawl: Siempre con supervisión humana
2. Walk: La IA trabaja directamente con empleados internos
3. Run: Automatización casi completa, incluso con clientes externos

El desafío técnico más grande es la velocidad
Los modelos generan texto token por token, como 10 milisegundos por token
Para 100 tokens, eso es como un segundo completo
Por eso necesitas técnicas como cuantización, destilación y paralelismo

Diferencias importantes en el entrenamiento:
- Pre-entrenamiento: empezar desde cero (súper costoso)
- Finetuning: continuar entrenando un modelo existente
- Post-training: ajustes para que siga mejor las instrucciones

Para las interfaces, tienes muchas opciones:
- Apps web, móviles, de escritorio
- Extensiones de navegador
- Chatbots integrados
- APIs que otros pueden usar

Herramientas como Streamlit, Gradio y Plotly Dash te facilitan mucho la vida

Algunos datos interesantes:
- En documentación, la productividad se duplica
- En programación, mejoras del 25% al 50%
- El crecimiento en perfiles de "AI Engineering" es del 75% mensual en LinkedIn

La evaluación es crucial para:
- Evitar riesgos en producción
- Encontrar nuevas oportunidades
- Medir progreso real

¿Qué hace único al AI Engineering?
- Usas modelos ya entrenados en lugar de crear desde cero
- Iteras súper rápido
- Estás involucrado en decisiones de producto desde el día uno

Muchos AI engineers vienen del desarrollo web o full-stack:
Esto les permite convertir ideas en demos funcionando súper rápido

Las herramientas están evolucionando constantemente:
Transformers.js, librerías de OpenAI para Node, Vercel's AI SDK

El proceso cambió de:
Recolectar datos → entrenar → desplegar
A:
Iterar rápido → adaptar → mejorar constantemente durante el desarrollo

En resumen:
Los foundation models son la base de todo
La ingeniería AI combina:
- Adaptación inteligente de modelos
- Ingeniería de datos efectiva
- Optimización constante
- Interfaces que la gente realmente quiere usar

Y las aplicaciones están en todos lados: programación, marketing, educación, atención al cliente, operaciones empresariales

Lo más emocionante es que apenas estamos empezando
Cada día aparecen nuevas herramientas y posibilidades
Es un momento increíble para estar en este campo

¿Y sabes qué? Este es solo el capítulo 1
Los foundation models son literalmente los bloques fundamentales para construir aplicaciones de IA
Pueden integrar texto, imágenes, video, y mucho más en un solo modelo súper versátil

Recuerda estos números clave:
- De 117 millones a miles de millones de parámetros en solo unos años
- CLIP entrenado con 400 millones de pares imagen-texto
- 100 tokens equivalen a aproximadamente 75 palabras

Y las técnicas principales que necesitas dominar:
- Tokenización para entender cómo procesan el lenguaje
- Prompt engineering para dar instrucciones efectivas
- Finetuning para casos específicos
- Optimización de inferencia para velocidad y costo

El stack tiene tres niveles claros:
1. Aplicaciones (lo que ve el usuario)
2. Modelos (el cerebro del sistema)
3. Infraestructura (lo que hace que todo funcione)

Y recuerda el enfoque experimental:
Varía prompts, prueba algoritmos diferentes, ajusta parámetros
El feedback loop te permite mejorar constantemente la velocidad y reducir costos

Los números del mercado son impresionantes:
- Costos de etiquetado pueden ser de centavos por imagen, pero escalan a millones
- Productividad duplicada en documentación
- Mejoras del 25-50% en generación y refactorización de código

El AI Engineering es diferente porque:
- No desarrollas modelos desde cero, los adaptas
- Iteras súper rápido en lugar de seguir un proceso largo y secuencial
- Estás involucrado en decisiones de producto desde el primer día

Y eso es todo por hoy
Espero que esto te haya dado una base sólida para entender los foundation models y el AI engineering
En los próximos capítulos vamos a profundizar en cada una de estas áreas

¡Nos vemos en la próxima!
