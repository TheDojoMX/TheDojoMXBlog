• Technical specifications and data:
 – Model examples: ChatGPT, Google’s Gemini, Midjourney. 
 – Model scale: Models range from 117 million parameters (GPT, June 2018) to over 1.5 billion parameters (GPT-2, Feb 2019) and now extend to billions of parameters. 
 – Data requirements: Large amounts of publicly available internet data and significant compute power (including vast electricity consumption) are required. 
 – Vocabulary sizes: Mixtral 8x7B model has 32,000 tokens; GPT-4 has 100,256 tokens. 
 – Tokenization: Average token length is approximately ¾ of a word (100 tokens ≈ 75 words); GPT-4 tokenizes “I can’t wait to build AI applications” into nine tokens.
 – Special tokens: BOS (Beginning Of Sequence) and EOS (End Of Sequence) are used in forming training sequences. 
 – CLIP model: Trained on 400 million (image, text) pairs; serves as an embedding model for texts and images.

• Methods and algorithms:
 – Tokenization process: Breaks original text into tokens for statistical treatment.
 – Masked language modeling (e.g., BERT): Predicts missing tokens using bidirectional context.
 – Autoregressive language modeling: Predicts the next token based on preceding tokens.
 – Self-supervision: Inference of labels from input data (e.g., in language modeling each text provides both context and tokens to predict).
 – Supervised learning: Uses manually labeled data (e.g., AlexNet on ImageNet with 1 million labeled images, 1,000 categories).
 – Finetuning: Updates model weights from a pre-trained model using less data than pre-training.
 – Prompt-based techniques: Provide detailed instructions and context (prompt engineering) without updating weights.
 – Inference optimization: Techniques include quantization, distillation, and parallelism for reducing latency in autoregressive generation.
 – Model adaptation techniques: Two categories – (1) Prompt engineering and (2) Finetuning.
 – AI engineering responsibilities:
  1. Modeling and training: Designing model architectures; frameworks include TensorFlow, PyTorch, Hugging Face Transformers.
  2. Dataset engineering: Curating, deduplicating, tokenizing, and quality-controlling unstructured data.
  3. Inference optimization: Improving speed, reducing cost (e.g., reducing first token time, TPOT, and total latency).

• Results and measurements:
 – Training sample example (“I love street food.”) yields six training samples with defined inputs and outputs: 
  1. Input: BOS  Output: BOS, I 
  2. Input: BOS, I  Output: love 
  3. Input: BOS, I, love  Output: street 
  4. Input: BOS, I, love, street  Output: food 
  5. Input: BOS, I, love, street, food  Output: BOS, I, love, street, food, . 
  6. Input: BOS, I, love, street, food, .  Output: EOS 
 – Gemini Ultra’s performance on MMLU benchmark improved from 83.7% to 90.04% using a prompt technique (CoT@32).
 – Data labeling costs: At 5 cents per image, labeling 1 million images costs $50,000; two people per image doubles cost; scaling to 1 million categories may cost ~$50 million.
 – Engineering productivity improvements (from McKinsey study): 
  • Documentation productivity may double.
  • Code generation and refactoring productivity improves between 25% and 50%.
 – Case study outcomes: 
  • GitHub Copilot reached >$100 million in annual recurring revenue within two years.
  • Midjourney generated $200 million in annual recurring revenue within 1.5 years.
 – Survey data: LinkedIn survey (Aug 2023) – professionals adding “Generative AI” and related terms increased by an average of 75% month-over-month.
 – Exposure percentages in occupations (Eloundou et al.): Ranges from 66.7% to 100% exposure (e.g., translators 76.5%-82.4%, tax preparers 100%).

• System components and architecture:
 – Foundation models: Serve as base models capable of handling multiple tasks (e.g., language, image, video processing); examples include GPT-4V and Claude 3.
 – Multimodal models: Process multiple data modalities (text, images, video, 3D assets, protein structures); defined as Large Multimodal Models (LMMs).
 – CLIP architecture: Embedding model that creates joint embeddings of texts and images.
 – AI engineering stack layers:
  1. Application development: Involves prompt engineering, evaluation (benchmarking, TTFT, TPOT, latency, cost per inference) and AI interface construction (web, mobile, desktop apps; browser extensions; chatbots).
  2. Model development: Involves modeling and training, finetuning, dataset engineering (curation, deduplication, tokenization), and inference optimization.
  3. Infrastructure: Tools and systems for serving models, managing data, scaling compute resources, and monitoring performance.
 – Examples of integration platforms: VSCode (Copilot), GitHub Copilot as a plug-in, Grammarly as a browser extension; frameworks including Streamlit, Gradio, and Plotly Dash.
 – Experimentation practices: Varying prompts, retrieval algorithms, and sampling variables to set up iterative feedback loops for running models faster and cheaper.
 – AI system scalability: Increased capacity from improvements in context length, output quality, and reductions in inference cost (illustrated in benchmark evolutions such as MMLU between 2022 and 2024).
 – Additional supporting tools: ansformers.js, OpenAI’s Node library, Vercel’s AI SDK, and increasing support for JavaScript APIs (LangChain.js, Transformers.js).

• Additional technical data points:
 – Data annotation in AI engineering involves dedicated processes (deduplication, tokenization, context retrieval, removal of sensitive/toxic data) compared to traditional ML’s feature engineering on tabular data.
 – Estimated market for intelligent data processing (IDP): ~$12.81 billion projected for 2030 with 32.9% annual growth.
 – Cost and regulatory challenges: GDPR compliance estimated costs of ~$9 billion and potential impacts from compute resource restrictions.
 – Rapid iteration framework (“Crawl-Walk-Run”): 
  1. Crawl – human participation is mandatory.
  2. Walk – direct AI interaction with internal employees.
  3. Run – full or near-full automation including external user interactions.
 – AI product defensibility aspects: Additional layers over foundation models (data, technology, distribution) and continual reliance on user data for competitive advantage.
 – Planning for product evolution: Evaluation of off-the-shelf models’ capabilities to determine additional work needed to reach a target percentage of automation (e.g., moving from 30% to 60%, then to higher levels).
 – Historical context: First language models appeared in the 1950s; Claude Shannon introduced statistical concepts (e.g., entropy) in 1951 that underlie current language models.
 – Use cases in business operations span marketing (copywriting, visual content generation), customer support (chatbots, AI assistants), coding (generation, refactoring, documentation), education (lesson personalization, tutoring, automated evaluation), and enterprise automations (workflow automation, data extraction).