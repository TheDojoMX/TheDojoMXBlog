¡Hola! Hoy vamos a hablar sobre cómo desarrollar software con Foundation Models <break time="1.5s"/>

¿Te has preguntado qué hay detrás de ChatGPT o Midjourney? <break time="1.0s"/>

Bueno, estos modelos de IA necesitan dos cosas principales: <break time="0.5s"/>
- Una cantidad enorme de electricidad para funcionar <break time="0.5s"/>
- Y millones de datos de internet para aprender <break time="1.0s"/>

Para que te hagas una idea de la escala, escucha esto: <break time="0.5s"/>
- El primer GPT en 2018 tenía apenas 117 millones de parámetros <break time="0.5s"/>
- GPT-2 al año siguiente ya tenía 1.5 mil millones <break time="0.5s"/>
- Y los modelos de hoy en día... ¡tienen miles de millones! <break time="1.5s"/>

¿Y qué significa esto para nosotros como desarrolladores? <break time="1.0s"/>

Por un lado, es genial: <break time="0.5s"/>
- Tenemos herramientas súper poderosas que pueden hacer casi cualquier cosa <break time="0.5s"/>
- Esto nos ayuda a ser más productivos y crear más valor <break time="1.0s"/>

Pero por otro lado: <break time="0.5s"/>
- Entrenar estos modelos requiere recursos que la mayoría no tenemos <break time="0.5s"/>
- La buena noticia es que podemos usar estos modelos como servicio, sin tener que crear uno desde cero <break time="1.5s"/>

Ahora, déjame explicarte algunos conceptos básicos que necesitas conocer <break time="1.0s"/>

¿Qué es exactamente un modelo de lenguaje? <break time="0.5s"/>
Piénsalo como un sistema que entiende patrones estadísticos del lenguaje para predecir qué palabra viene después <break time="1.0s"/>

Y aquí viene algo importante: los tokens <break time="0.5s"/>
Un token no es exactamente una palabra completa, puede ser un carácter, una palabra, o parte de una palabra <break time="0.5s"/>
Por ejemplo, si le dices a GPT-4 "I can't wait to build AI applications", lo divide en nueve tokens <break time="1.5s"/>

La regla práctica es: <break time="0.5s"/>
100 tokens son aproximadamente 75 palabras <break time="0.5s"/>
¿Por qué? Porque cada token es como ¾ de una palabra en promedio <break time="1.0s"/>

Cada modelo tiene su vocabulario: <break time="0.5s"/>
- Mixtral 8x7B maneja 32,000 tokens <break time="0.5s"/>
- GPT-4 puede trabajar con más de 100,000 tokens <break time="1.5s"/>

¿Por qué usar tokens en lugar de palabras completas? <break time="1.0s"/>
Es bastante inteligente: <break time="0.5s"/>
1. Pueden dividir palabras en partes que sí conocen <break time="0.5s"/>
2. Esto reduce el tamaño del vocabulario <break time="0.5s"/>
3. Y pueden manejar palabras nuevas dividiéndolas en pedazos conocidos <break time="1.5s"/>

Hablemos de los tipos de modelos que existen <break time="1.0s"/>

Tienes los modelos enmascarados como BERT: <break time="0.5s"/>
- Estos pueden "adivinar" palabras faltantes en medio de una oración <break time="0.5s"/>
- Son excelentes para tareas como análisis de sentimientos o clasificar texto <break time="1.0s"/>

Y luego están los modelos autoregresivos: <break time="0.5s"/>
- Estos van palabra por palabra, prediciendo qué sigue <break time="0.5s"/>
- Son los favoritos para generar texto nuevo <break time="1.5s"/>

Ahora, ¿qué hace especial a la IA generativa? <break time="1.0s"/>

Es como tener un vocabulario finito que puede crear infinitas combinaciones <break time="0.5s"/>
Es como tener un conjunto limitado de piezas de LEGO, pero poder construir cualquier cosa <break time="1.0s"/>

Por ejemplo: <break time="0.5s"/>
- Le dices "To be or not to be" y completa ", that is the question" <break time="0.5s"/>
- O le preguntas "How are you in French is..." y responde "Comment ça va" <break time="0.5s"/>
- Incluso puede clasificar si un email es spam o no <break time="1.5s"/>

Un poco de historia interesante <break time="1.0s"/>
Los modelos de lenguaje no son nuevos, comenzaron en los años 50 <break time="0.5s"/>
Claude Shannon en 1951 introdujo conceptos como la entropía que todavía usamos hoy <break time="1.0s"/>

Lo que cambió todo fue algo llamado "self-supervision" <break time="0.5s"/>
Básicamente, el modelo aprende de los propios datos sin que tengamos que etiquetarlos manualmente <break time="1.5s"/>

¿Quieres ver cómo entrena un modelo? Te muestro con un ejemplo simple <break time="1.0s"/>
Tomemos la frase "I love street food" <break time="0.5s"/>

El modelo aprende así: <break time="0.5s"/>
1. Ve "BOS" (inicio), predice "I" <break time="0.5s"/>
2. Ve "BOS, I", predice "love" <break time="0.5s"/>
3. Ve "BOS, I, love", predice "street" <break time="0.5s"/>
4. Y así sucesivamente hasta el final <break time="1.0s"/>

BOS y EOS son como las mayúsculas y el punto final, pero para las máquinas <break time="1.5s"/>

Ahora, algo súper emocionante: los modelos multimodales <break time="1.0s"/>
Ya no solo trabajan con texto, también pueden entender imágenes, video, estructuras 3D, ¡hasta proteínas! <break time="0.5s"/>

Modelos como GPT-4V y Claude 3 pueden ver y entender imágenes <break time="1.5s"/>

Y está CLIP, que es fascinante: <break time="0.5s"/>
Se entrenó con 400 millones de pares de imagen y texto <break time="0.5s"/>
Puede entender la relación entre lo que ve y lo que lee <break time="1.5s"/>

¿Cómo es diferente de entrenar un modelo tradicional? <break time="1.0s"/>

En machine learning tradicional necesitas etiquetar todo manualmente <break time="1.0s"/>
Pero con auto-supervisión, el modelo infiere las etiquetas de los propios datos <break time="1.0s"/>

Y aquí vienen dos técnicas súper importantes: <break time="0.5s"/>
- Finetuning: ajustas un modelo ya entrenado con tus datos específicos <break time="0.5s"/>
- Prompt engineering: le das instrucciones claras sin cambiar nada del modelo <break time="1.5s"/>

Ahora, ¿qué es exactamente AI Engineering? <break time="1.0s"/>
Es básicamente construir aplicaciones encima de estos modelos poderosos <break time="0.5s"/>
Y es muy diferente al ML tradicional porque participas activamente en las decisiones del producto <break time="1.0s"/>

Tienes dos formas principales de adaptar modelos: <break time="0.5s"/>
1. Prompt engineering: le das instrucciones súper detalladas <break time="0.5s"/>
2. Finetuning: actualizas los pesos del modelo para tu caso específico <break time="1.5s"/>

Las responsabilidades se dividen en tres áreas: <break time="1.0s"/>
1. Modelado y entrenamiento con herramientas como TensorFlow y PyTorch <break time="0.5s"/>
2. Ingeniería de datos: limpiar, organizar y preparar información no estructurada <break time="1.0s"/>
3. Optimización de inferencia: hacer que todo funcione rápido y barato <break time="1.5s"/>

La gran diferencia con ML tradicional es que: <break time="1.0s"/>
- Antes construías todo desde cero <break time="0.5s"/>
- Ahora usas modelos ya entrenados y los adaptas <break time="0.5s"/>
- Puedes iterar súper rápido y probar ideas nuevas constantemente <break time="1.5s"/>

¿Dónde se está usando esto? ¡En todas partes! <break time="1.0s"/>

En programación: <break time="0.5s"/>
- GitHub Copilot ya genera más de 100 millones de dólares al año <break time="0.5s"/>
- Herramientas que escriben código, extraen datos y generan documentación <break time="1.5s"/>

En marketing: <break time="0.5s"/>
- Midjourney, Adobe Firefly, Runway para crear imágenes y videos <break time="0.5s"/>
- Pruebas A/B automáticas de anuncios <break time="1.5s"/>

En escritura: <break time="0.5s"/>
- Autocorrectores inteligentes, autocompletado <break time="0.5s"/>
- Ya está integrado en Google Docs, Notion, Gmail <break time="1.0s"/>

En educación: <break time="0.5s"/>
- Resúmenes automáticos de libros de texto <break time="0.5s"/>
- Planes de estudio personalizados <break time="0.5s"/>
- Duolingo y Khan Academy ya lo usan <break time="1.0s"/>

Y por supuesto, chatbots que pueden: <break time="0.5s"/>
- Buscar información <break time="0.5s"/>
- Explicar conceptos complejos <break time="0.5s"/>
- Generar ideas creativas <break time="0.5s"/>
- Están en Google Assistant, Siri, Alexa <break time="1.5s"/>

Para las empresas, esto significa: <break time="1.0s"/>
- Mejor experiencia del cliente <break time="0.5s"/>
- Equipos más productivos <break time="0.5s"/>
- Procesos optimizados <break time="0.5s"/>
- Y la capacidad de innovar más rápido <break time="1.0s"/>

Pero ojo, también hay riesgos: <break time="0.5s"/>
Si no inviertes en esta tecnología, te puedes quedar atrás <break time="0.5s"/>
La pregunta es: ¿desarrollas internamente o contratas el servicio? <break time="1.5s"/>

Hablemos del stack técnico, que tiene tres capas principales: <break time="1.0s"/>

1. Desarrollo de aplicaciones: <break time="0.5s"/>
Aquí trabajas con prompts, evalúas latencia y costo, y construyes interfaces web, móviles o chatbots <break time="1.0s"/>

2. Desarrollo de modelos: <break time="0.5s"/>
Modelado, entrenamiento, ajuste fino y preparación de datos <break time="1.0s"/>

3. Infraestructura: <break time="0.5s"/>
Servidores, gestión de datos, escalabilidad y monitoreo <break time="1.5s"/>

Las herramientas populares incluyen: <break time="0.5s"/>
VSCode con Copilot, Streamlit, Gradio, y cada vez más librerías de JavaScript <break time="1.5s"/>

¿Cómo mides el éxito? <break time="1.0s"/>

Métricas de negocio: <break time="0.5s"/>
- Porcentaje de mensajes automatizados <break time="0.5s"/>
- Reducción en tiempo de respuesta <break time="0.5s"/>
- Ahorro en mano de obra <break time="1.0s"/>

Métricas técnicas: <break time="0.5s"/>
- Calidad de respuestas <break time="0.5s"/>
- Latencia (qué tan rápido responde) <break time="0.5s"/>
- Costo por solicitud <break time="1.0s"/>

Un consejo importante: usa el enfoque "Crawl-Walk-Run" <break time="0.5s"/>
1. Crawl: Siempre con supervisión humana <break time="0.5s"/>
2. Walk: La IA trabaja directamente con empleados internos <break time="0.5s"/>
3. Run: Automatización casi completa, incluso con clientes externos <break time="1.0s"/>

El desafío técnico más grande es la velocidad <break time="1.0s"/>
Los modelos generan texto token por token, como 10 milisegundos por token <break time="0.5s"/>
Para 100 tokens, eso es como un segundo completo <break time="0.5s"/>
Por eso necesitas técnicas como cuantización, destilación y paralelismo <break time="1.5s"/>

Diferencias importantes en el entrenamiento: <break time="1.0s"/>
- Pre-entrenamiento: empezar desde cero (súper costoso) <break time="0.5s"/>
- Finetuning: continuar entrenando un modelo existente <break time="0.5s"/>
- Post-training: ajustes para que siga mejor las instrucciones <break time="1.5s"/>

Para las interfaces, tienes muchas opciones: <break time="1.0s"/>
- Apps web, móviles, de escritorio <break time="0.5s"/>
- Extensiones de navegador <break time="0.5s"/>
- Chatbots integrados <break time="0.5s"/>
- APIs que otros pueden usar <break time="1.0s"/>

Herramientas como Streamlit, Gradio y Plotly Dash te facilitan mucho la vida <break time="1.5s"/>

Algunos datos interesantes: <break time="1.0s"/>
- En documentación, la productividad se duplica <break time="0.5s"/>
- En programación, mejoras del 25% al 50% <break time="1.0s"/>
- El crecimiento en perfiles de "AI Engineering" es del 75% mensual en LinkedIn <break time="1.5s"/>

La evaluación es crucial para: <break time="0.5s"/>
- Evitar riesgos en producción <break time="0.5s"/>
- Encontrar nuevas oportunidades <break time="0.5s"/>
- Medir progreso real <break time="1.5s"/>

¿Qué hace único al AI Engineering? <break time="1.0s"/>
- Usas modelos ya entrenados en lugar de crear desde cero <break time="0.5s"/>
- Iteras súper rápido <break time="0.5s"/>
- Estás involucrado en decisiones de producto desde el día uno <break time="1.0s"/>

Muchos AI engineers vienen del desarrollo web o full-stack: <break time="0.5s"/>
Esto les permite convertir ideas en demos funcionando súper rápido <break time="1.5s"/>

Las herramientas están evolucionando constantemente: <break time="0.5s"/>
Transformers.js, librerías de OpenAI para Node, Vercel's AI SDK <break time="1.0s"/>

El proceso cambió de: <break time="0.5s"/>
Recolectar datos → entrenar → desplegar <break time="0.5s"/>
A: <break time="0.5s"/>
Iterar rápido → adaptar → mejorar constantemente durante el desarrollo <break time="1.5s"/>

En resumen: <break time="1.0s"/>
Los foundation models son la base de todo <break time="0.5s"/>
La ingeniería AI combina: <break time="0.5s"/>
- Adaptación inteligente de modelos <break time="0.5s"/>
- Ingeniería de datos efectiva <break time="0.5s"/>
- Optimización constante <break time="0.5s"/>
- Interfaces que la gente realmente quiere usar <break time="1.0s"/>

Y las aplicaciones están en todos lados: programación, marketing, educación, atención al cliente, operaciones empresariales <break time="1.5s"/>

Lo más emocionante es que apenas estamos empezando <break time="0.5s"/>
Cada día aparecen nuevas herramientas y posibilidades <break time="0.5s"/>
Es un momento increíble para estar en este campo <break time="1.5s"/>

¿Y sabes qué? Este es solo el capítulo 1 <break time="0.5s"/>
Los foundation models son literalmente los bloques fundamentales para construir aplicaciones de IA <break time="0.5s"/>
Pueden integrar texto, imágenes, video, y mucho más en un solo modelo súper versátil <break time="1.5s"/>

Recuerda estos números clave: <break time="1.0s"/>
- De 117 millones a miles de millones de parámetros en solo unos años <break time="0.5s"/>
- CLIP entrenado con 400 millones de pares imagen-texto <break time="0.5s"/>
- 100 tokens equivalen a aproximadamente 75 palabras <break time="1.5s"/>

Y las técnicas principales que necesitas dominar: <break time="1.0s"/>
- Tokenización para entender cómo procesan el lenguaje <break time="0.5s"/>
- Prompt engineering para dar instrucciones efectivas <break time="0.5s"/>
- Finetuning para casos específicos <break time="0.5s"/>
- Optimización de inferencia para velocidad y costo <break time="1.5s"/>

El stack tiene tres niveles claros: <break time="1.0s"/>
1. Aplicaciones (lo que ve el usuario) <break time="0.5s"/>
2. Modelos (el cerebro del sistema) <break time="0.5s"/>
3. Infraestructura (lo que hace que todo funcione) <break time="1.0s"/>

Y recuerda el enfoque experimental: <break time="0.5s"/>
Varía prompts, prueba algoritmos diferentes, ajusta parámetros <break time="0.5s"/>
El feedback loop te permite mejorar constantemente la velocidad y reducir costos <break time="1.5s"/>

Los números del mercado son impresionantes: <break time="1.0s"/>
- Costos de etiquetado pueden ser de centavos por imagen, pero escalan a millones <break time="1.0s"/>
- Productividad duplicada en documentación <break time="0.5s"/>
- Mejoras del 25-50% en generación y refactorización de código <break time="1.5s"/>

El AI Engineering es diferente porque: <break time="1.0s"/>
- No desarrollas modelos desde cero, los adaptas <break time="0.5s"/>
- Iteras súper rápido en lugar de seguir un proceso largo y secuencial <break time="0.5s"/>
- Estás involucrado en decisiones de producto desde el primer día <break time="1.5s"/>

Y eso es todo por hoy <break time="1.0s"/>
Espero que esto te haya dado una base sólida para entender los foundation models y el AI engineering <break time="0.5s"/>
En los próximos capítulos vamos a profundizar en cada una de estas áreas <break time="1.5s"/>

¡Nos vemos en la próxima! <break time="1.0s"/>