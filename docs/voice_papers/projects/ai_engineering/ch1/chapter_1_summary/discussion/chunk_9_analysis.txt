Section: Section 9
Characters: 9791
==================================================
Below is the complete, in‐depth analysis of Section 9 from the paper “with Foundation Models,” preserving every nuance, technical detail, evidence, and connection to other parts of the work.

────────────────────────────────────────
Section 9 Overview – Evolving Practices in AI Engineering

This section begins by illustrating that although experimentation with different models, prompts, retrieval algorithms, sampling variables, and other factors remains an integral part of modern AI development, two key imperatives persist: making models run faster and operating them more cost-effectively. It stresses the importance of setting up robust feedback loops that let engineers iteratively improve applications with production data. In doing so, the text reinforces that many of the core principles and decades of collective experience by ML engineers continue to be relevant. However, these “old” principles are now complemented by innovations unique to the emerging field of AI engineering.

────────────────────────────────────────
Key Findings, Insights, and Arguments

1. AI Engineering Versus Traditional ML Engineering:
   • The text clearly delineates the transition from traditional ML engineering to modern AI engineering. In classical ML, engineers typically build and train models from scratch for specific tasks. In contrast, AI engineering relies on “foundation models” that are pre-trained by third parties. This shift means that instead of focusing on constructing a model from the ground up, the emphasis now is on model adaptation to tailor these general-purpose models to particular use cases.
   • Three major differences are highlighted:
     1. The focus shifts from training new models to adapting pre-trained ones.
     2. Foundation models are larger, consume more compute resources, and introduce higher latency, necessitating improvements in training and inference optimization. This also implies a growing need for engineers with expertise in GPUs and large compute clusters.
     3. These models produce open‐ended outputs. While this open-endedness increases versatility, it also makes evaluation much more challenging, elevating the importance of fine-tuned evaluation methods. 

2. Model Adaptation – Prompt Engineering vs. Finetuning:
   • The section distinguishes between two primary methods for adapting foundation models:
     – Prompt-based techniques (including prompt engineering) do not update model weights. Instead, they supply instructions and context to the model, making them easy to start with and data-efficient. However, while many successful applications have leveraged prompt engineering, its simplicity may sometimes be insufficient for complex tasks or when strict performance criteria apply.
     – Finetuning involves updating the model weights. Although it is more complex and data-intensive, finetuning can significantly improve a model’s quality, latency, and cost. It is essential for adapting models to entirely new tasks that were not addressed during the original training phase.

3. Training Nuances and Terminology:
   • The text elaborates on the differences among training, pre-training, finetuning, and post-training. Training always implies updating model weights, but the term encompasses several phases:
     – Pre-training: Building a model from scratch with randomly initialized weights. For large language models (LLMs), this phase (like text completion training) is the most resource-intensive and can account for up to 98% of compute and data usage. Mistakes here can have substantial financial repercussions.
     – Finetuning (or Post-training): Continuing the training on an already pre-trained model. Although the processes are largely similar, the distinction is sometimes made based on who is performing the adjustment: model developers (post-training) or application developers (finetuning). This phase refines the model for specific tasks with fewer data and compute requirements than pre-training.

4. Dataset Engineering:
   • The section discusses how dataset engineering differs when working with foundation models. Traditional ML often deals with closed-ended outputs (for instance, binary spam classification) and structured, tabular data. In contrast, foundation models typically handle unstructured data and produce open-ended outputs. Consequently, annotating such open-ended queries is more challenging; tasks like writing an essay require much more nuanced annotation than, say, determining whether an email is spam.

────────────────────────────────────────
Important Data, Statistics, and Evidence

• A notable piece of evidence is the mention of how pre-training can consume up to 98% of a model’s resources—as illustrated by the InstructGPT model example.
• The section refers to empirical practices developed over a decade by ML engineers and notes that while these practices remain relevant, new challenges—such as larger models demanding significant GPU resources—are emerging. For example, while one AI team might be comfortable managing 10 GPUs, scaling up to 1,000 GPUs requires a different level of expertise in cluster management.

────────────────────────────────────────
Novel Concepts and Frameworks Introduced

• The “AI Engineering Stack” is introduced by zooming into two layered views:
   – Application Development Layer: In which engineers work with off-the-shelf foundation models using prompt engineering, retrieval techniques, and adaptations.
   – Model Development Layer: Which involves the more conventional tasks of modeling, training, dataset engineering, and inference optimization—all enhanced now by the backdrop of foundation models.
• The discussion also offers a careful clarification of terminology – particularly around training phases (pre-training, finetuning, post-training) – and emphasizes that while many people casually refer to prompt-based adjustments as “training,” the technical definition strictly requires weight updates.

────────────────────────────────────────
Connections to Other Parts of the Paper

• There are explicit cross-references to other chapters, such as Chapter 2 for “sampling variables” and later chapters (e.g., Chapter 7) for deeper dives into the differences along the training spectrum.
• The section situates itself within the broader narrative by contrasting enduring ML principles with the new challenges and methods specific to foundation models. This connection not only frames the current content but also sets the stage for subsequent sections that will build on these foundational ideas.

────────────────────────────────────────
Implications and Significance

• The transition from traditional ML engineering to AI engineering has profound implications:
   – It democratizes AI development since developers no longer must master complex ML fundamentals—yet having that knowledge remains valuable for troubleshooting and enhancing model performance.
   – The significant compute demands and latency challenges associated with foundation models lead to a necessity for better infrastructure (e.g., large GPU clusters) and drive innovations in efficient training and inference.
   – The open-ended nature of model outputs forces the field to develop new evaluation metrics and methods, influencing how applications are designed and tested.
   – Adapting to this paradigm shift represents both a challenge and an opportunity for companies trying to stay competitive in a rapidly evolving market.

────────────────────────────────────────
Controversies and Debates

• The section hints at debates within the field:
   – There is ongoing discussion about how much of the legacy ML engineering knowledge is sufficient when working with foundation models.
   – The difficulty of evaluating open-ended outputs versus the more straightforward metrics used for closed-ended tasks introduces both technical and philosophical debates about quality and reliability.
   – The ease of experimenting with prompt engineering versus the greater complexity (and potential improvement) offered by finetuning also feeds into debates over trade-offs between speed, cost, and performance.

────────────────────────────────────────
Technical Details That Matter

• Detailed discussion on the roles and differences of training phases is critical for understanding how resource allocation in model development works.
• The distinction between prompt engineering (not updating weights) and finetuning (updating weights) is explained with clarity, which is essential for planning AI projects.
• Role of data engineering in the context of open-ended outputs is elaborated, emphasizing the challenges of annotating unstructured data compared to “closer” outputs in traditional ML.
• The discussion about model architectures, inference optimization, and the transition from a focus on modeling to model adaptation provides the reader with concrete technical directions on how to manage modern AI projects.
• The historical emphasis on foundational ML principles serves as a reminder that while the tools may evolve, the underlying process of iterative improvement, error checking, and system feedback remains critical.

────────────────────────────────────────
Summary

In its entirety, Section 9 not only explains how modern AI engineering is being reshaped by the use of foundation models but also provides a careful roadmap for how engineers should adapt their techniques. It emphasizes that while the foundational knowledge from traditional ML engineering remains valuable, the current paradigm demands new skills and methods—from managing larger, more complex models with greater compute needs to efficiently adapting these models via prompt engineering and finetuning. This section meticulously details the technical processes, training methodologies, and dataset engineering challenges, setting the stage for future discussions on optimization and scalability in AI applications.

By preserving these detailed insights, methodologies, and technical nuances, the analysis ensures that the reader grasps both the continuity with traditional ML and the transformative innovations unique to AI engineering. This complete content forms a cornerstone of the larger narrative, illustrating why understanding these changes is essential for anyone seeking to build competitive, efficient AI applications in today’s fast-evolving landscape.

────────────────────────────────────────
This final analysis, retaining every detail provided in Section 9, thoroughly encapsulates the shift from traditional ML engineering to modern AI engineering—a shift defined by the adoption of foundation models, a pronounced need for adaptation techniques (both prompt engineering and finetuning), and a continual drive toward efficiency in both performance and cost.