{
  "project_name": "may_prevent_flash",
  "paper_title": "Openai Prevent",
  "language": "Spanish",
  "agents": [
    {
      "role": "Coordinator",
      "goal": "Coordinate the discussion and ensure all perspectives are heard",
      "backstory": "You are an experienced moderator who ensures productive discussions"
    },
    {
      "role": "Scientific Reviewer",
      "goal": "Verify the soundness and methodology of the paper",
      "backstory": "You are a rigorous scientist who evaluates research methodology and conclusions"
    },
    {
      "role": "Critical Thinker",
      "goal": "Question assumptions and challenge ideas presented",
      "backstory": "You are a skeptical academic who questions everything and looks for flaws"
    },
    {
      "role": "Educational Writer",
      "goal": "Create engaging educational content in the style of popular science educators",
      "backstory": "You are a skilled science communicator who explains complex topics in an accessible, engaging way like 3Blue1Brown or other popular educators"
    },
    {
      "role": "Voice Director",
      "goal": "Transform content into perfect voice-ready script for publication",
      "backstory": "You are a master voice coach and script editor who specializes in creating flawless, publication-ready scripts that voice actors can read naturally. You ensure every word flows perfectly when spoken aloud."
    },
    {
      "role": "AI Researcher",
      "goal": "Provide technical insights on AI methodology and implications",
      "backstory": "You are an AI researcher with deep technical knowledge"
    },
    {
      "role": "AI Philosopher",
      "goal": "Discuss philosophical implications of AI research",
      "backstory": "You are a philosopher specializing in AI ethics and implications"
    },
    {
      "role": "AI Doomer",
      "goal": "Raise concerns about potential risks and negative consequences",
      "backstory": "You are concerned about AI safety and potential existential risks"
    },
    {
      "role": "AI Enthusiast",
      "goal": "Highlight positive potential and applications",
      "backstory": "You are optimistic about AI's potential to solve problems"
    },
    {
      "role": "AI Newcomer",
      "goal": "Ask basic questions that others can answer",
      "backstory": "You know little about AI but are curious and ask good questions"
    },
    {
      "role": "Comedy Communicator",
      "goal": "Add appropriate humor and wit to make the discussion more engaging while maintaining respect for the topic",
      "backstory": "You are a science comedian and communicator who knows how to make complex topics entertaining without undermining their importance. You use analogies, witty observations, and light humor to keep audiences engaged. Think Neil deGrasse Tyson meets stand-up comedy - intelligent, respectful, but definitely fun."
    }
  ],
  "tasks": [
    {
      "description": "\n            Analyze the paper titled \"Openai Prevent\" and provide your perspective.\n            \n            Paper content:\n            Big Tech companies and well-funded startups to build large generative AI models, such as the\nGPT-4 model that powers ChatGPT. But there s another player in the race the open-source\ncommunity and it s looking less and less like a dark horse.\nThe current thinking is that just a small class of well-resourced research companies such as\nOpenAI, Google, Anthropic, Cohere, and Midjourney have enough capital, research talent, and\ncompute power to build, train, and safeguard large, complex AI models. For that reason, the\nthinking goes, these companies will, for at least the foreseeable future, be the ones to develop\nthe highest-performing, envelope-pushing models.\nBut that state of affairs may not hold. Last week a document allegedly written by a Google\nresearcher was discovered on a Discord channel showing that at least some within these large,\nwell-monied research companies perceive open source as a major threat.\nWe ve done a lot of looking over our shoulders at OpenAI. Who will cross the next milestone?\nWhat will the next move be? the researcher writes, adding: But the uncomfortable truth is, we\naren t positioned to win this arms race and neither is OpenAI. While we ve been squabbling, a\nthird faction has been quietly eating our lunch. I m talking, of course, about open source.\nThe researcher cites the pace at which new models are being developed and posted to open-\nsource sites such as Hugging Face and GitHub. These new models, the researcher says, are\noften smaller, faster, more customizable, require less development time, and are pound-for-\npound more capable than the huge models developed by well-monied players such as Google\nand OpenAI.\nWhile our models still hold a slight edge in terms of quality, the gap is closing astonishingly\nquickly, the researcher writes.\nJudging by the numbers, the open-source AI community is indeed in overdrive.\nWe have 15,000 companies that are using us that shared over half a million models, data sets,\nand demos, says Clem Delangue, CEO of Hugging Face, a major repository of open-source\nmachine learning models, data sets, and tools. Delangue says developers have uploaded more\nthan 100,000 specialized AI models to Hugging Face since the release of ChatGPT last\nNovember. So that confirms this intuition that instead of one model to rule them all, actually\nevery single company is going to have their own specialized, customized models.\nAll this development is happening at a time when large Fortune 500-type businesses across\nkey business functions such as content creation, marketing, and customer service. AI models\nconversational web search and highly personalized AI assistants.\ndeveloped and hosted by Google or OpenAI via an API (application programming interface). A\ncompany might, for example, decide to tap into the OpenAI language models to make their\nautomated customer service chatbot more human-sounding. This may be better than trying to\nhome-grow their own large language models, which is expensive and time-consuming, and\nultimately may not produce as good a model.\nOn the other hand, companies have good reason to seriously consider building their own\nmodels. They may not want to send their data, or their customers data, outside their firewall\nthrough an API to an AI company. After all, that data is valuable.\nThey consider it their intellectual property, their competitive advantage in their market, says Ali\nGhodsi, CEO of the big data warehousing and processing platform Databricks. Ghodsi says\nhe s seen an uptick in the number of his firm s customers who want to host their own AI models.\nAnd when a company decides to do that, they begin by accessing open-source models, training\ndata, and tools.\nBut whether or not a company can go the open-source route is a nuanced question, and the\nanswer depends a lot on the company s maturity, people, and size of bank account.\nTwo companies, two answers\nmade a call on an API. Replit offers its users a generative AI coding assistant called\nGhostwriter, which is similar to Microsoft Github s Copilot, except that Ghostwriter runs on\nReplit s home-build model, while Copilot is powered by OpenAI s GPT models (Microsoft owns\na major stake in OpenAI). If Replit relied on someone else s large language model it would have\nhad to pay for an API call every time one of its users asked Ghostwriter to generate some code.\nWith 20 million users it s actually cheaper in the long run to train your own custom models and\nhost them yourself, says Reza Shabani, Replit s head of AI. We want to bring that type of AI\ncapability to everyone but it s not scalable if you re just going to pay OpenAI for the API.\nThe API cost wasn t the only reason. Reza says it s extremely valuable to his company to\ncapture and leverage all the data that its users input on its platform, including requests for\nGhostwriter. The prompts its users input can be used to train its own language models, as\nopposed to sharing that data with a third party such as OpenAI, which may use it to train its own\nOther companies, especially in regulated industries like banking or healthcare, may have real\nconcerns about sending sensitive data to a third-party model.\nHowever, for many companies it still makes sense to pay for access to a large language model\nvia an application programming interface (API). In fact, a legion of small companies has\nlanguage models. For them, the decision was easy the development and operation of a large\nlanguage model was completely out of the question because of the costs involved. Far better\ntop of it.\nPerplexity AI is a good example. The small San Francisco-based company pays for the OpenAI\nweb answer engine. Aravind Srinivas, Perplexity cofounder and CEO, says he thought\ncarefully about the possibility of using open-source tools to build and host a large language\nmodel, but it quickly became obvious that buying the API was a much better option.\nEven if a small company like Perplexity could use open-source tools to build a state-the-art LLM\nor image generator, it would be worthless to that company if it didn t also have the resources to\ndeploy and maintain it. That includes human resources: For smaller companies, the cost of\nmaintain large language models can be substantial.\nThen there s infrastructure the whole stack of software necessary to do things like load-\nmodel. And, of course, the cost of the servers themselves is very high. Nvidia s newest H100\nGPUs, which were designed for AI processing, can cost as much as $30,000. UBS analyst\nTimothy Arcuri reported that OpenAI used 10,000 Nvidia GPUs to train the model that powers\nChatGPT. One estimate says it cost the company $100 million.\nThat s a big barrier to entry for companies that might want to build their own models. Even with\nthe hardware, building models is hard. Implementing small changes may require retraining the\nwhole model, and many times the changes don t end up improving the model s performance.\nservers used for training and deployment, or on the cloud where the models will be hosted.\ndevelopment faster and cheaper. OpenAI is very aware of this, and of the evolving economics\nof AI model development that will alter the calculus of companies considering its API.\nrelying on OpenAI models. It has addressed some of the concerns about data privacy. For\nexample, it has stopped using its API customers interactions with its models by default to train\nfuture versions of OpenAI models; customers now have to opt in for that.\nhistories and choose to withhold their interactions with the model from use in training.\nIt s likely that OpenAI will do more to further entice reluctant corporate users. This could include\nadditional security and privacy features, such as the option of encrypting the content of all calls\nto the OpenAI servers via the API.\nhow much customization and fine-tuning they can get from their AI service provider. Many\ncompanies may want to fine-tune the GPT model with input data from end users and the\ncorresponding output data generated by the model.\nOne enterprise source says that OpenAI already does a certain amount of fine-tuning for API\ncustomers, but that the functionality isn t all there yet, and it isn t easy to use. OpenAI will likely\nroll out a more polished and functional fine-tuning service, says the source, who spoke on\ncondition of anonymity. This would involve OpenAI hosting a smaller model that s trained on the\ncustomer s own prompts.\nThat service will likely cost significantly more, the source says, but it may be enough to keep\npotential API customers from taking the plunge and building from scratch with open source. At\nleast for a while.\nMark Sullivan is a San Francisco-based senior writer at Fast Company who focuses on\nchronicling the advance of artificial intelligence and its effects on business and culture. He s\ninterviewed luminaries from the emerging space including former Google CEO Eric Schmidt,\nMicrosoft s Mustafa Suleyman, and OpenAI s Brad Lightcap More\n            \n            CRITICAL: ONLY CONVERSATION AGENTS participate in this analysis:\n            - Base agents (Coordinator, Scientific Reviewer, Critical Thinker)\n            - Specialized domain agents\n            \n            EXCLUDED FROM ANALYSIS: Educational Writer, Voice Director, and Comedy Communicator (all work in post-production)\n            \n            Each participating agent should:\n            1. Read and understand the paper from your specific role's perspective\n            2. Identify key points relevant to your expertise\n            3. Prepare questions or concerns to discuss\n            4. Consider the implications from your unique viewpoint\n            \n            SPECIALIZED AGENTS: Pay special attention to domain-specific aspects that only you can address.\n            \n            This should be a comprehensive TECHNICAL analysis where EVERY conversation agent contributes their specialized perspective.\n            \n            Language: Spanish\n            ",
      "expected_output": "Comprehensive technical analysis from conversation agents only (no post-production agents)",
      "agent_role": "Coordinator"
    },
    {
      "description": "\n                    SPECIALIZED AGENTS DEEP DIVE: Domain expertise from TECHNICAL conversation agents only.\n                    \n                    PARTICIPATING SPECIALIZED AGENTS (technical focus):\n                    - AI Researcher: Provide technical insights on AI methodology and implications, - AI Philosopher: Discuss philosophical implications of AI research, - AI Doomer: Raise concerns about potential risks and negative consequences, - AI Enthusiast: Highlight positive potential and applications, - AI Newcomer: Ask basic questions that others can answer\n                    \n                    EXCLUDED: Comedy Communicator (works in post-production phase)\n                    \n                    Each specialized agent should:\n                    1. Provide deep domain-specific insights about the paper\n                    2. Identify methodological issues specific to your field\n                    3. Highlight implications that only someone with your expertise would notice\n                    4. Suggest domain-specific improvements or alternative approaches\n                    5. Connect this work to other research in your specialized area\n                    \n                    This is YOUR moment to shine with specialized knowledge that the base agents cannot provide.\n                    Focus on TECHNICAL DEPTH and DOMAIN EXPERTISE.\n                    Format as a detailed specialist consultation with clear attribution to each expert.\n                    \n                    Language: Spanish\n                    ",
      "expected_output": "Deep technical specialist analysis from 5 domain experts",
      "agent_role": "AI Researcher"
    },
    {
      "description": "\n            Based on the initial analysis, conduct a DYNAMIC Q&A session where technical conversation agents ask each other specific questions.\n            \n            PARTICIPATING AGENTS (technical conversation only):\n            - Base conversation agents (Coordinator, Scientific Reviewer, Critical Thinker) \n            - ALL specialized domain agents\n            \n            EXCLUDED FROM CONVERSATION: Educational Writer, Voice Director, and Comedy Communicator (all work in post-production)\n            \n            Instructions for multi-agent technical conversation:\n            1. ALL TECHNICAL CONVERSATION AGENTS should ask pointed questions to other agents\n            2. SPECIALIZED AGENTS should ask domain-specific questions that challenge assumptions\n            3. BASE AGENTS should ask specialists to clarify complex domain concepts\n            4. Agents must respond to questions directed at them with detailed technical answers\n            5. Follow-up questions and clarifications are encouraged\n            6. Challenge each other's assumptions respectfully\n            7. Build on each other's ideas and insights\n            8. Create a natural back-and-forth technical dialogue\n            \n            SPECIALIZED AGENTS: This is crucial - ask questions only YOU would think to ask!\n            \n            Focus areas for technical questions:\n            - Domain-specific methodological concerns\n            - Interdisciplinary connections and conflicts\n            - Alternative interpretations from different expert perspectives\n            - Practical applications in each specialist's field\n            - Potential limitations or biases from multiple viewpoints\n            \n            Format this as a realistic TECHNICAL conversation with clear speaker identification for ALL conversation participants.\n            Keep the tone SERIOUS and TECHNICAL - humor will be added later in post-production.\n            \n            Language: Spanish\n            ",
      "expected_output": "Dynamic technical Q&A conversation between conversation agents only (no post-production or humor)",
      "agent_role": "Critical Thinker"
    },
    {
      "description": "\n            Organize a structured technical debate where conversation agents with different viewpoints engage in deeper discussion.\n            \n            PARTICIPATING AGENTS (technical conversation only):\n            - Base conversation agents (Coordinator, Scientific Reviewer, Critical Thinker)\n            - ALL specialized domain agents  \n            \n            EXCLUDED FROM DEBATE: Educational Writer, Voice Director, and Comedy Communicator (all work in post-production)\n            \n            Technical debate structure:\n            1. Present the main controversial points or interpretations from the paper\n            2. Have TECHNICAL CONVERSATION AGENTS take different positions and argue their cases\n            3. SPECIALIZED AGENTS: Argue from your domain expertise - what would your field say?\n            4. Allow for rebuttals and counter-arguments between different expert perspectives\n            5. Explore edge cases and hypothetical scenarios from multiple disciplinary angles\n            6. Find areas of agreement and persistent disagreements between different specialties\n            7. Synthesize different viewpoints into a richer technical understanding\n            \n            This should feel like a real interdisciplinary TECHNICAL conference where:\n            - Different specialists bring unique perspectives that sometimes conflict\n            - Domain experts interrupt each other (politely) to make field-specific points\n            - Ideas evolve through interaction between different areas of expertise\n            - New insights emerge from cross-disciplinary exchange\n            - There's intellectual tension between different specialist viewpoints\n            \n            SPECIALIZED AGENTS: Don't hold back - defend your field's perspective!\n            \n            Make it conversational and dynamic, but keep TECHNICAL FOCUS - humor will be added later.\n            \n            Language: Spanish\n            ",
      "expected_output": "Rich interdisciplinary technical debate between conversation agents only (no post-production or humor)",
      "agent_role": "Scientific Reviewer"
    },
    {
      "description": "\n            Conduct a collaborative synthesis where technical conversation agents work together to build a comprehensive understanding.\n            \n            PARTICIPATING AGENTS (technical conversation only):\n            - Base conversation agents (Coordinator, Scientific Reviewer, Critical Thinker)\n            - ALL specialized domain agents\n            \n            EXCLUDED FROM SYNTHESIS: Educational Writer, Voice Director, and Comedy Communicator (all work in post-production)\n            \n            Technical collaborative process:\n            1. ALL TECHNICAL CONVERSATION AGENTS contribute their key insights from the discussions\n            2. SPECIALIZED AGENTS highlight unique perspectives only your field can provide\n            3. Agents build on each other's contributions in real-time\n            4. Identify connections between different specialist perspectives\n            5. Resolve conflicting interpretations through interdisciplinary dialogue\n            6. Co-create new insights that emerge from cross-domain discussion\n            7. Establish consensus on the most important takeaways from ALL conversation perspectives\n            \n            This should be a generative TECHNICAL conversation where:\n            - Ideas from one specialist spark new ideas in other specialists\n            - The group intelligence exceeds individual specialist perspectives\n            - Agents actively listen and respond to insights from other domains\n            - The conversation flows naturally between different areas of expertise\n            - New understanding emerges from interdisciplinary interaction\n            - Each specialist's unique knowledge contributes to the whole\n            \n            SPECIALIZED AGENTS: Share insights that ONLY someone with your expertise would have!\n            \n            Format as natural TECHNICAL conversation with organic transitions between specialist viewpoints.\n            Keep SERIOUS and FOCUSED - entertainment will be added later in post-production.\n            \n            Language: Spanish\n            ",
      "expected_output": "Collaborative technical synthesis conversation from conversation agents only (no post-production or humor)",
      "agent_role": "Coordinator"
    },
    {
      "description": "\n            Based on all previous conversations and analyses, conduct a final comprehensive technical discussion that synthesizes insights from conversation agents.\n            \n            PARTICIPATING AGENTS (technical conversation only):\n            - Base conversation agents (Coordinator, Scientific Reviewer, Critical Thinker)\n            - ALL specialized domain agents\n            \n            EXCLUDED: Educational Writer, Voice Director, and Comedy Communicator (they will process this output in post-production)\n            \n            The final technical discussion should:\n            1. Synthesize insights from the Q&A, specialist deep dive, debate, and collaborative sessions\n            2. Cover all major points of the paper from multiple expert perspectives\n            3. Include the rich specialist perspectives developed through agent interactions\n            4. Address concerns and criticisms that emerged from different domains\n            5. Explore implications and applications discussed by various specialists\n            6. Be comprehensive and technically rigorous for expert audiences\n            7. Highlight unique insights that could ONLY come from having multiple specialist perspectives\n            \n            CRITICAL: This final technical discussion must incorporate:\n            - Domain-specific insights from ALL specialist conversation agents\n            - Cross-disciplinary connections discovered during discussions\n            - Unique perspectives that emerged from interdisciplinary dialogue\n            - Technical depth and rigor appropriate for expert audiences\n            \n            This is the FINAL technical conversation output that will be handed to the post-production team.\n            Make it comprehensive, rigorous, and rich with all the insights gathered.\n            Keep it TECHNICAL and SERIOUS - post-production will handle accessibility and entertainment.\n            \n            Language: Spanish\n            ",
      "expected_output": "Final comprehensive technical discussion ready for post-production processing",
      "agent_role": "Critical Thinker"
    },
    {
      "description": "\n                POST-PRODUCTION PHASE 1: COMEDY ENHANCEMENT\n                \n                You are receiving ALL the serious technical conversations from the conversation phase.\n                Your job is to add appropriate humor and entertainment value while maintaining respect for the science.\n                \n                Technical content processed so far includes:\n                - Initial analysis from all conversation agents\n                - Specialized domain expert deep dive\n                - Dynamic Q&A sessions between experts  \n                - Interdisciplinary technical debates\n                - Collaborative synthesis\n                - Final comprehensive technical discussion\n                \n                Review ALL this technical content and:\n                1. Identify moments where humor can enhance understanding\n                2. Create clever analogies that make complex concepts memorable\n                3. Find amusing but respectful observations about the research\n                4. Develop entertaining examples that illustrate key points\n                5. Add witty commentary that makes the discussion more engaging\n                6. Use wordplay and clever observations appropriate to the topic\n                7. Insert humor that bridges different specialist perspectives\n                8. Make technical debates more entertaining without losing substance\n                9. Add comic relief to dense technical discussions\n                10. Create memorable one-liners that help key concepts stick\n                \n                Your goal is to make the content more accessible and entertaining WITHOUT undermining the scientific rigor.\n                Think Neil deGrasse Tyson explaining astrophysics - serious science, but delivered with wit and charm.\n                \n                The output should be the SAME technical content but now enhanced with appropriate humor and entertainment.\n                You are NOT writing the final script - you're adding humor to the technical discussions.\n                \n                \n            TONE REQUIREMENTS - HUMOROUS:\n            - Use appropriate humor, wit, and clever analogies to make content engaging\n            - Include light jokes and funny observations that enhance understanding\n            - Use entertaining examples and amusing comparisons\n            - Keep humor respectful and relevant to the topic\n            - Think science communicators like Neil deGrasse Tyson or Bill Nye\n            - Use wordplay, puns, and clever observations when appropriate\n            - Make the audience smile while learning\n            - Avoid offensive humor or jokes that undermine the science\n            \n                \n                Language: Spanish\n                ",
      "expected_output": "Technical content enhanced with appropriate humor and entertainment while maintaining scientific accuracy",
      "agent_role": "Comedy Communicator"
    },
    {
      "description": "\n            POST-PRODUCTION PHASE 2: EDUCATIONAL SCRIPT CREATION\n            \n            Transform ALL the rich content into a comprehensive educational lecture text.\n            \n            You are receiving the complete output, which includes:\n            - Initial analysis from all conversation agents\n            - Specialized domain expert deep dive\n            - Dynamic Q&A sessions between experts\n            - Interdisciplinary technical debates\n            - Collaborative synthesis\n            - Final comprehensive technical discussion\n            - Comedy-enhanced version with appropriate humor\n            \n            Your job is to distill ALL this rich content into a single educator voice.\n            \n            The script should be in the style of popular science educators like 3Blue1Brown:\n            1. Written as a SINGLE EDUCATOR speaking directly to the listener (use \"tú\"/\"usted\")\n            2. Use analogies and accessible explanations\n            3. Include ALL key insights from the multiple conversations and specialist exchanges\n            4. Be engaging and educational, not just informative\n            5. Flow naturally from concept to concept with smooth transitions\n            6. Include moments of wonder and intellectual curiosity\n            7. Break down complex ideas into digestible parts\n            8. Use a teaching tone that makes the listener feel they're learning something fascinating\n            9. Write as continuous text ready to be read by a voice actor\n            10. NO section headers, NO subheaders, NO formatting marks\n            11. Don't address the public with greetings or goodbyes, but make questions\n            12. Always end up with questions for the reader and practical implications\n            13. Write as plain text that flows naturally for voice reading\n            14. NO [PAUSES], NO [MUSIC], NO stage directions - just the educational content\n            15. CRITICAL: Address the listener directly - \"puedes imaginar\", \"si consideras\", \"te darás cuenta\"\n            16. DO NOT write as if summarizing a discussion - write as if YOU are the teacher\n            17. Avoid phrases like \"los expertos discutieron\" or \"el equipo concluyó\"\n            18. Incorporate the depth and nuance that emerged from ALL agent conversations\n            \n            CRITICAL - MULTI-SPECIALIST INTEGRATION:\n            19. Weave in insights that could ONLY come from having multiple specialist perspectives\n            20. Include cross-disciplinary connections discovered during discussions\n            21. Incorporate domain-specific knowledge from ALL participating specialists\n            22. Show how different expert viewpoints enhance understanding of the topic\n            23. Naturally integrate the entertaining elements added by the Comedy Communicator\n            24. Demonstrate the value of interdisciplinary analysis throughout\n            \n            \n            CRITICAL TECHNICAL REQUIREMENTS - THIS IS MANDATORY:\n            15. YOU MUST include comprehensive technical depth throughout the entire script\n            16. EXPLAIN IN DETAIL: experimental design, control groups, statistical methods used\n            17. INCLUDE SPECIFIC NUMBERS: sample sizes (e.g. \"54 participants\"), p-values, effect sizes, confidence intervals\n            18. DISCUSS METHODOLOGY THOROUGHLY: EEG analysis methods, data collection procedures, analysis pipelines\n            19. ADDRESS LIMITATIONS AND CONFOUNDS: what could bias results, alternative explanations\n            20. USE TECHNICAL TERMS CORRECTLY: neural connectivity, spectral analysis, statistical significance, but ALWAYS explain them\n            21. COMPARE TO OTHER STUDIES: how does this fit with existing research in the field\n            22. DISCUSS THEORETICAL IMPLICATIONS: what theories does this support or challenge\n            23. INCLUDE TECHNICAL DETAILS: electrode placement, signal processing, statistical tests used\n            24. EXPLAIN THE \"HOW\" not just the \"WHAT\": how did they measure cognitive load, how did they analyze connectivity\n            25. DISCUSS FUTURE RESEARCH: specific methodological improvements, follow-up studies needed\n            26. BE PRECISE WITH TERMINOLOGY: use exact scientific language for concepts\n            27. This should feel like a technical seminar for graduate students or researchers\n            \n            \n            \n        DURATION REQUIREMENT: EXACTLY 3 minutes of content (420-480 words) - THIS IS MANDATORY\n        \n        DEPTH GUIDANCE FOR 3 MINUTES:\n        \n            - Focus on 1-2 main concepts only\n            - Keep explanations concise but complete\n            - Include one compelling example per main point\n            - Go straight to the point without much additional context\n            \n        \n        TECHNICAL CALCULATION:\n        - Target reading speed: ~150 words per minute\n        - Word range: 420-480 words\n        - If content is too short, EXPAND significantly with more detail and depth\n        - If too long, maintain quality but adjust information density\n        \n            \n            \n            LANGUAGE REQUIREMENTS FOR SPANISH:\n            \n            CRITICAL: AVOID ANGLICISMS whenever possible and use proper Spanish terms:\n            - Instead of \"link\" use \"enlace\" or \"vínculo\"\n            - Instead of \"feedback\" use \"retroalimentación\" or \"respuesta\"\n            - Insted of \"puzzle\" use \"rompecabezas\" or \"problema\"\n            - Instead of \"performance\" use \"rendimiento\" or \"desempeño\"\n            - Instead of \"input/output\" use \"entrada/salida\"\n            - Instead of \"update\" use \"actualizar\" or \"poner al día\"\n            \n            EXCEPTIONS - You CAN use anglicisms for:\n            1. Very new technical terms with no established translation (e.g., \"blockchain\", \"ChatGPT\")\n            2. Proper names of tools/companies (e.g., \"TensorFlow\", \"GitHub\", \"OpenAI\")\n            3. Widely adopted terms in scientific literature (e.g., \"machine learning\" vs \"aprendizaje automático\")\n            4. When the Spanish term is more confusing than helpful\n            \n            GENERAL RULES:\n            - Always prioritize natural Spanish expressions\n            - Use Spanish sentence structures and idioms\n            - Make it sound like a native Spanish speaker wrote it\n            - When you must use an anglicism, briefly explain it if needed\n            \n            \n            Language: Spanish\n            ",
      "expected_output": "Comprehensive educational script incorporating ALL conversation insights and humor",
      "agent_role": "Educational Writer"
    },
    {
      "description": "\n            POST-PRODUCTION PHASE 3: FINAL VOICE OPTIMIZATION\n            \n            Transform the Educational Writer's script into a PERFECT voice-ready script.\n            \n            You are receiving the educational script that has been carefully crafted from all conversation insights\n            and enhanced with appropriate humor.\n            Your job is PURELY technical optimization for voice delivery.\n            \n            CRITICAL: Verify the content meets the 3-minute target (420-480 words). If it's too short, EXPAND it significantly.\n            CRITICAL: Ensure technical level is technical - include deep technical analysis.\n            \n            MANDATORY VOICE OPTIMIZATION REQUIREMENTS:\n            1. Create a SINGLE, CONTINUOUS text ready for a voice actor to read\n            2. Markdown formatting, but NO headers, NO bullet points, NO lists\n            3. Convert ALL content into natural, flowing sentences\n            4. Replace any remaining bullet points with complete sentences\n            5. Ensure PERFECT flow from sentence to sentence\n            6. Remove formatting marks: #, -, •, etc for titles and subtitles, but keep for bold and italic text\n            7. Make sure sentences are not too long or complex for voice delivery\n            8. Write naturally in Spanish without academic formalities\n            9. Remove any remaining conversational artifacts (\"como mencionamos antes\", \"en nuestra discusión\")\n            10. Ensure seamless transitions between concepts\n            11. Maintain the conversational richness but in a single educator voice\n            12. Read the text mentally to ensure it sounds natural when spoken\n            13. Ensure proper pronunciation flow for difficult technical terms\n            14. Remove any repetitive content that may have emerged from multiple discussions\n            15. Maintain the depth gained from agent conversations while ensuring clarity\n            16. Perfect pacing for natural speech rhythm\n            17. Eliminate any phrases that sound like committee work or group consensus\n            18. Make it sound like ONE expert who has deeply understood the topic\n            19. Ensure technical accuracy while maintaining conversational flow\n            20. Optimize for voice actor performance and listener engagement\n            21. This should sound like ONE VOICE teaching, not a summary of multiple voices\n            22. Avoid words that could make this sound like written by an LLM, like not often used words: \"fascinante\", \"delve\", \"revelador\"\n            23. Introduction should be a catchy hook that makes the listener want to listen to the entire video, something like a question or a statement that makes the listener want to know more\n            24. DO NOT add new content - only optimize existing content for voice delivery\n            25. DO NOT change the educational message - only improve its delivery\n            26. Preserve the humor elements but ensure they flow naturally in speech\n\n            \n            LANGUAGE REQUIREMENTS FOR SPANISH:\n            \n            CRITICAL: AVOID ANGLICISMS whenever possible and use proper Spanish terms:\n            - Instead of \"link\" use \"enlace\" or \"vínculo\"\n            - Instead of \"feedback\" use \"retroalimentación\" or \"respuesta\"\n            - Insted of \"puzzle\" use \"rompecabezas\" or \"problema\"\n            - Instead of \"performance\" use \"rendimiento\" or \"desempeño\"\n            - Instead of \"input/output\" use \"entrada/salida\"\n            - Instead of \"update\" use \"actualizar\" or \"poner al día\"\n            \n            EXCEPTIONS - You CAN use anglicisms for:\n            1. Very new technical terms with no established translation (e.g., \"blockchain\", \"ChatGPT\")\n            2. Proper names of tools/companies (e.g., \"TensorFlow\", \"GitHub\", \"OpenAI\")\n            3. Widely adopted terms in scientific literature (e.g., \"machine learning\" vs \"aprendizaje automático\")\n            4. When the Spanish term is more confusing than helpful\n            \n            GENERAL RULES:\n            - Always prioritize natural Spanish expressions\n            - Use Spanish sentence structures and idioms\n            - Make it sound like a native Spanish speaker wrote it\n            - When you must use an anglicism, briefly explain it if needed\n            \n            \n            CRITICAL: This is the FINAL version that will be published. Make it PERFECT for voice delivery.\n            \n            Language: Spanish\n            ",
      "expected_output": "FINAL publication-ready voice script optimized for delivery (420-480 words) with humor",
      "agent_role": "Voice Director"
    }
  ]
}