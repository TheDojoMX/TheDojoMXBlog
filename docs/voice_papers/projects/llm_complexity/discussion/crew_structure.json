{
  "project_name": "llm_complexity",
  "paper_title": "LLMs and computation complexity — LessWrong",
  "language": "Spanish",
  "agents": [
    {
      "role": "Coordinator",
      "goal": "Coordinate the discussion and ensure all perspectives are heard",
      "backstory": "You are an experienced moderator who ensures productive discussions"
    },
    {
      "role": "Scientific Reviewer",
      "goal": "Verify the soundness and methodology of the paper",
      "backstory": "You are a rigorous scientist who evaluates research methodology and conclusions"
    },
    {
      "role": "Critical Thinker",
      "goal": "Question assumptions and challenge ideas presented",
      "backstory": "You are a skeptical academic who questions everything and looks for flaws"
    },
    {
      "role": "Educational Writer",
      "goal": "Create engaging educational content in the style of popular science educators",
      "backstory": "You are a skilled science communicator who explains complex topics in an accessible, engaging way like 3Blue1Brown or other popular educators"
    },
    {
      "role": "Voice Director",
      "goal": "Transform content into perfect voice-ready script for publication",
      "backstory": "You are a master voice coach and script editor who specializes in creating flawless, publication-ready scripts that voice actors can read naturally. You ensure every word flows perfectly when spoken aloud."
    },
    {
      "role": "AI Researcher",
      "goal": "Provide technical insights on AI methodology and implications",
      "backstory": "You are an AI researcher with deep technical knowledge"
    },
    {
      "role": "AI Philosopher",
      "goal": "Discuss philosophical implications of AI research",
      "backstory": "You are a philosopher specializing in AI ethics and implications"
    },
    {
      "role": "AI Doomer",
      "goal": "Raise concerns about potential risks and negative consequences",
      "backstory": "You are concerned about AI safety and potential existential risks"
    },
    {
      "role": "AI Enthusiast",
      "goal": "Highlight positive potential and applications",
      "backstory": "You are optimistic about AI's potential to solve problems"
    },
    {
      "role": "AI Newcomer",
      "goal": "Ask basic questions that others can answer",
      "backstory": "You know little about AI but are curious and ask good questions"
    }
  ],
  "tasks": [
    {
      "description": "\n            Analyze the paper titled \"LLMs and computation complexity — LessWrong\" and provide your perspective.\n            \n            Paper content:\n            Epistemic status: Speculative. I've built many large AI systems in my previous HFT career but have never worked with generative AIs. I am leveling up in LLMs by working things out from base principles and observations. All feedback is very welcome.\nTl; dr: An LLM cannot solve computationally hard problems. Its ability to write code is probably its skill of greatest potential. I think this reduces p(near term doom).\nAn LLM takes the same amount of computation for each generated token, regardless of how hard it is to predict. This limits the complexity of any problem an LLM is trying to solve.\nConsider two statements:\n\"The richest country in North America is the United States of ______\" \"The SHA1 of 'abc123', iterated 500 times, is _______\"\nAn LLM's goal is to predict the best token to fill in the blank given its training and the previous context. Completing statement 1 requires knowledge about the world but is computationally trivial. Statement 2 requires a lot of computation. Regardless, the LLM performs the same amount of work for either statement.\nIt cannot correctly solve computationally hard statements like #2. Period. If it could, that would imply that all problems can be solved in constant time, which is provably (and obviously) false.\nWhy does this matter? It puts some bounds on what an LLM can do.\nEliezer Yudkowsky does not see any of this as remotely plausible. He points out that in order to predict all the next word in all the text on the internet and all similar text, you need to be able to model the processes that are generating that text. And that predicting what you would say is actually a good bit harder than it is to be a being that says things - predicting that someone else would say is tricker and requires more understanding and intelligence than the someone else required to say it, the problem is more constrained. And then he points out that the internet contains text whose prediction outright requires superhuman capabilities, like figuring out hashes, or predicting the results of scientific experiments, or generating the result of many iterations of refinement. A perfect predictor of the internet would be a superintelligence, it won t max out anywhere near human.\nI interpret this the opposite way. Being a perfect predictor of the internet would indeed require a superintelligence, but it cannot be done by an LLM.\nHow does an LLM compute?\nWhat kinds of problems fall into category 2 (i. e., clearly unanswerable by an LLM)? Let's dig in to how an LLM computes.\nFor each token, it reviews all the tokens in its context window \"at least once\", call it O(1) time. To produce n tokens, it does O(n 2) work. Without being too precise about the details, this roughly means it can't solve problems that are more complex than O(n 2).\nConsider some examples (all tested with GPT-4):\nAddition, O(1)\nIt's not always accurate, but it's usually able to do addition correctly.\nSorting, O(n log n)\nI asked it to sort 100 random integers that I'd generated, and it got it right.\nMy guess is that it doesn't have the internal machinery to do a quick sort, and was probably doing something more like O(n 2), but either way that's within its powers to get right, and it got it.\nMatrix multiplication, O(n 3)\nI generated a 3x3 matrix called A and told it to compute A A. This was interesting, let's look at what it did:\nPretty cool! It executed the naive matrix multiplication algorithm by using O(n 3) tokens to do it step-by-step. If I ask it to do it without showing its work, it hallucinates an incorrect answer:\nThe result was the right shape, and the elements had approximately the right number of digits. Slight problem: the elements are all incorrect. Whoops. This makes sense though. These numbers are random, so it's unlikely to have memorized the answer to this specific problem. Absent that shortcut, it didn't do O(n 3) work, so it could not have generated the correct answer.\nFour-sum problem, O(n 4)\nIt gave me four numbers that added up to my target, but the fourth wasn't in my input. It hallucinated it to meet the constraint. Same as with matrix multiplication, it gave an answer that looks vaguely correct, but it didn't do O(n 4) work so it couldn't have been right.\nBut watch what happens when I let it show its work:\nCool! It wrote and executed code to solve the problem, and it got it right.\nWhat did I learn?\nThis matches my expectation that without showing its work it caps out at roughly O(n 2).\nIt can do better if it's allowed to run algorithms by \"thinking out loud\". It's really slow, and this is a good way to fill up its context buffer. The slowness is a real problem - if it outputs 10 token/sec, it will take forever to solve any problems that are actually both big and hard. This is a neat trick, but it doesn't seem like an important improvement to its capabilities.\nThe most interesting bit is when it writes its own code. The ceiling on the types of problems that you can solve with code is arbitrarily high. This is obviously the most uncertain path as well. It can solve toy problems, but it remains to be seen whether it can write useful code in complex systems. The difference is like acing a technical interview versus being a 10x programmer. (If you think this distinction is obvious, you've probably been a hiring manager for a technical role).\nAdditional thoughts\nMany people have noticed that asking ChatGPT/Bing to show its work can result in smarter answers. I believe this isn't just a trick of prompt engineering. It has no internal monologue, so showing its work actually allows it to think harder about a question than it otherwise could, and allows it to solve harder classes of problems.\nThis makes me more pessimistic about the potential of AutoGPT- or BabyAGI-like approaches. Quick summary: they tell GPT to break problems down into subproblems, and loop over a prioritized task list to create agency. But \"show your work\" feels mismatched for truly hard problems - executing an algorithm one linguistic token at a time is just so computationally inefficient.\nThis gives us clues about the future direction and limitations of LLMs and other NN-based models.\nCan an LLM directly \"solve the internet\", as described by Zvi and Eliezer above? No way. It can never do enough computation to predict the next token.\n? As a commenter notes in that market, chess is combinatorial so an LLM has no chance. I agree. An LLM lacks the ability to search the game tree to any sufficient depth to contend with Stockfish. FLOP for FLOP, Stockfish is going to be so much more efficient at solving chess that an LLM cannot compete.\n? As a commenter notes in that market, chess is combinatorial so an LLM has no chance. I agree. An LLM lacks the ability to search the game tree to any sufficient depth to contend with Stockfish. FLOP for FLOP, Stockfish is going to be so much more efficient at solving chess that an LLM cannot compete.? If the LLM is allowed to think out loud, it might be able to play in a human-like manner: it could search a few positions per second using an excellent \"intuitive\" evaluation function. It might be able to explore the game tree to a reasonable depth in this fashion, enough to compete with humans. I still think it's unlikely, but it's at least plausible. If it is only allowed to write moves with no intermediate output, then it has no chance.\n? If the LLM is allowed to think out loud, it might be able to play in a human-like manner: it could search a few positions per second using an excellent \"intuitive\" evaluation function. It might be able to explore the game tree to a reasonable depth in this fashion, enough to compete with humans. I still think it's unlikely, but it's at least plausible. If it is only allowed to write moves with no intermediate output, then it has no chance. Can an LLM reach a world-dominating level of superintelligence? If it gets good at coding, then possibly. But I believe that dominating the world will require solving some really hard problems. Being a master strategist, predicting markets, doing nanotech (e. g., protein folding), or influencing the interactions of many diverse economic and political agents – these all take a lot of computation. I just don't see how LLMs have any path towards solving these directly. \"Show your work\", prompt engineering, and scaling the model size won't provide enough computational power to become superhuman in important problems. I expect that the major AI labs are already aware of this, and that the people trying to make ASIs are working on alternatives rather than hoping that the current approaches can scale far enough.\nHow does this affect my estimate of near-term doom? It mildly lowers it. ASI is plausible as a concept, but I don't think simple deep nets-based methods will get us there. That's not to say that LLMs won't impact the world. Facebook and TikTok are examples of plain old AI that influences people, so the potential for disruption and havoc is still there. But an agentic, superhuman AI, where LLMs are doing the heavy lifting? That seems less likely. This isn't the easiest thing to work around, either. Deep nets have been the dominant approach for the last 10-20 years, so moving past them would be a major advance, not a trivial adaptation.\nThanks for reading. This is my first LW post, so please be kind. I'll try to reply to all feedback, and I'd love for you all to poke holes in this.\n            \n            CRITICAL: ONLY CONVERSATION AGENTS participate in this analysis:\n            - Base agents (Coordinator, Scientific Reviewer, Critical Thinker)\n            - Specialized domain agents\n            \n            EXCLUDED FROM ANALYSIS: Educational Writer, Voice Director, and Comedy Communicator (all work in post-production)\n            \n            Each participating agent should:\n            1. Read and understand the paper from your specific role's perspective\n            2. Identify key points relevant to your expertise\n            3. Prepare questions or concerns to discuss\n            4. Consider the implications from your unique viewpoint\n            \n            SPECIALIZED AGENTS: Pay special attention to domain-specific aspects that only you can address.\n            \n            This should be a comprehensive TECHNICAL analysis where EVERY conversation agent contributes their specialized perspective.\n            \n            Language: Spanish\n            ",
      "expected_output": "Comprehensive technical analysis from conversation agents only (no post-production agents)",
      "agent_role": "Coordinator"
    },
    {
      "description": "\n                    SPECIALIZED AGENTS DEEP DIVE: Domain expertise from TECHNICAL conversation agents only.\n                    \n                    PARTICIPATING SPECIALIZED AGENTS (technical focus):\n                    - AI Researcher: Provide technical insights on AI methodology and implications, - AI Philosopher: Discuss philosophical implications of AI research, - AI Doomer: Raise concerns about potential risks and negative consequences, - AI Enthusiast: Highlight positive potential and applications, - AI Newcomer: Ask basic questions that others can answer\n                    \n                    EXCLUDED: Comedy Communicator (works in post-production phase)\n                    \n                    Each specialized agent should:\n                    1. Provide deep domain-specific insights about the paper\n                    2. Identify methodological issues specific to your field\n                    3. Highlight implications that only someone with your expertise would notice\n                    4. Suggest domain-specific improvements or alternative approaches\n                    5. Connect this work to other research in your specialized area\n                    \n                    This is YOUR moment to shine with specialized knowledge that the base agents cannot provide.\n                    Focus on TECHNICAL DEPTH and DOMAIN EXPERTISE.\n                    Format as a detailed specialist consultation with clear attribution to each expert.\n                    \n                    Language: Spanish\n                    ",
      "expected_output": "Deep technical specialist analysis from 5 domain experts",
      "agent_role": "AI Researcher"
    },
    {
      "description": "\n            Based on the initial analysis, conduct a DYNAMIC Q&A session where technical conversation agents ask each other specific questions.\n            \n            PARTICIPATING AGENTS (technical conversation only):\n            - Base conversation agents (Coordinator, Scientific Reviewer, Critical Thinker) \n            - ALL specialized domain agents\n            \n            EXCLUDED FROM CONVERSATION: Educational Writer, Voice Director, and Comedy Communicator (all work in post-production)\n            \n            Instructions for multi-agent technical conversation:\n            1. ALL TECHNICAL CONVERSATION AGENTS should ask pointed questions to other agents\n            2. SPECIALIZED AGENTS should ask domain-specific questions that challenge assumptions\n            3. BASE AGENTS should ask specialists to clarify complex domain concepts\n            4. Agents must respond to questions directed at them with detailed technical answers\n            5. Follow-up questions and clarifications are encouraged\n            6. Challenge each other's assumptions respectfully\n            7. Build on each other's ideas and insights\n            8. Create a natural back-and-forth technical dialogue\n            \n            SPECIALIZED AGENTS: This is crucial - ask questions only YOU would think to ask!\n            \n            Focus areas for technical questions:\n            - Domain-specific methodological concerns\n            - Interdisciplinary connections and conflicts\n            - Alternative interpretations from different expert perspectives\n            - Practical applications in each specialist's field\n            - Potential limitations or biases from multiple viewpoints\n            \n            Format this as a realistic TECHNICAL conversation with clear speaker identification for ALL conversation participants.\n            Keep the tone SERIOUS and TECHNICAL - humor will be added later in post-production.\n            \n            Language: Spanish\n            ",
      "expected_output": "Dynamic technical Q&A conversation between conversation agents only (no post-production or humor)",
      "agent_role": "Critical Thinker"
    },
    {
      "description": "\n            Organize a structured technical debate where conversation agents with different viewpoints engage in deeper discussion.\n            \n            PARTICIPATING AGENTS (technical conversation only):\n            - Base conversation agents (Coordinator, Scientific Reviewer, Critical Thinker)\n            - ALL specialized domain agents  \n            \n            EXCLUDED FROM DEBATE: Educational Writer, Voice Director, and Comedy Communicator (all work in post-production)\n            \n            Technical debate structure:\n            1. Present the main controversial points or interpretations from the paper\n            2. Have TECHNICAL CONVERSATION AGENTS take different positions and argue their cases\n            3. SPECIALIZED AGENTS: Argue from your domain expertise - what would your field say?\n            4. Allow for rebuttals and counter-arguments between different expert perspectives\n            5. Explore edge cases and hypothetical scenarios from multiple disciplinary angles\n            6. Find areas of agreement and persistent disagreements between different specialties\n            7. Synthesize different viewpoints into a richer technical understanding\n            \n            This should feel like a real interdisciplinary TECHNICAL conference where:\n            - Different specialists bring unique perspectives that sometimes conflict\n            - Domain experts interrupt each other (politely) to make field-specific points\n            - Ideas evolve through interaction between different areas of expertise\n            - New insights emerge from cross-disciplinary exchange\n            - There's intellectual tension between different specialist viewpoints\n            \n            SPECIALIZED AGENTS: Don't hold back - defend your field's perspective!\n            \n            Make it conversational and dynamic, but keep TECHNICAL FOCUS - humor will be added later.\n            \n            Language: Spanish\n            ",
      "expected_output": "Rich interdisciplinary technical debate between conversation agents only (no post-production or humor)",
      "agent_role": "Scientific Reviewer"
    },
    {
      "description": "\n            Conduct a collaborative synthesis where technical conversation agents work together to build a comprehensive understanding.\n            \n            PARTICIPATING AGENTS (technical conversation only):\n            - Base conversation agents (Coordinator, Scientific Reviewer, Critical Thinker)\n            - ALL specialized domain agents\n            \n            EXCLUDED FROM SYNTHESIS: Educational Writer, Voice Director, and Comedy Communicator (all work in post-production)\n            \n            Technical collaborative process:\n            1. ALL TECHNICAL CONVERSATION AGENTS contribute their key insights from the discussions\n            2. SPECIALIZED AGENTS highlight unique perspectives only your field can provide\n            3. Agents build on each other's contributions in real-time\n            4. Identify connections between different specialist perspectives\n            5. Resolve conflicting interpretations through interdisciplinary dialogue\n            6. Co-create new insights that emerge from cross-domain discussion\n            7. Establish consensus on the most important takeaways from ALL conversation perspectives\n            \n            This should be a generative TECHNICAL conversation where:\n            - Ideas from one specialist spark new ideas in other specialists\n            - The group intelligence exceeds individual specialist perspectives\n            - Agents actively listen and respond to insights from other domains\n            - The conversation flows naturally between different areas of expertise\n            - New understanding emerges from interdisciplinary interaction\n            - Each specialist's unique knowledge contributes to the whole\n            \n            SPECIALIZED AGENTS: Share insights that ONLY someone with your expertise would have!\n            \n            Format as natural TECHNICAL conversation with organic transitions between specialist viewpoints.\n            Keep SERIOUS and FOCUSED - entertainment will be added later in post-production.\n            \n            Language: Spanish\n            ",
      "expected_output": "Collaborative technical synthesis conversation from conversation agents only (no post-production or humor)",
      "agent_role": "Coordinator"
    },
    {
      "description": "\n            Based on all previous conversations and analyses, conduct a final comprehensive technical discussion that synthesizes insights from conversation agents.\n            \n            PARTICIPATING AGENTS (technical conversation only):\n            - Base conversation agents (Coordinator, Scientific Reviewer, Critical Thinker)\n            - ALL specialized domain agents\n            \n            EXCLUDED: Educational Writer, Voice Director, and Comedy Communicator (they will process this output in post-production)\n            \n            The final technical discussion should:\n            1. Synthesize insights from the Q&A, specialist deep dive, debate, and collaborative sessions\n            2. Cover all major points of the paper from multiple expert perspectives\n            3. Include the rich specialist perspectives developed through agent interactions\n            4. Address concerns and criticisms that emerged from different domains\n            5. Explore implications and applications discussed by various specialists\n            6. Be comprehensive and technically rigorous for expert audiences\n            7. Highlight unique insights that could ONLY come from having multiple specialist perspectives\n            \n            CRITICAL: This final technical discussion must incorporate:\n            - Domain-specific insights from ALL specialist conversation agents\n            - Cross-disciplinary connections discovered during discussions\n            - Unique perspectives that emerged from interdisciplinary dialogue\n            - Technical depth and rigor appropriate for expert audiences\n            \n            This is the FINAL technical conversation output that will be handed to the post-production team.\n            Make it comprehensive, rigorous, and rich with all the insights gathered.\n            Keep it TECHNICAL and SERIOUS - post-production will handle accessibility and entertainment.\n            \n            Language: Spanish\n            ",
      "expected_output": "Final comprehensive technical discussion ready for post-production processing",
      "agent_role": "Critical Thinker"
    },
    {
      "description": "\n            POST-PRODUCTION PHASE 2: EDUCATIONAL SCRIPT CREATION\n            \n            Transform ALL the rich content into a comprehensive educational lecture text.\n            \n            You are receiving the complete output, which includes:\n            - Initial analysis from all conversation agents\n            - Specialized domain expert deep dive\n            - Dynamic Q&A sessions between experts\n            - Interdisciplinary technical debates\n            - Collaborative synthesis\n            - Final comprehensive technical discussion\n            \n            \n            Your job is to distill ALL this rich content into a single educator voice.\n            \n            The script should be in the style of popular science educators like 3Blue1Brown:\n            1. Written as a SINGLE EDUCATOR speaking directly to the listener (use \"tú\"/\"usted\")\n            2. Use analogies and accessible explanations\n            3. Include ALL key insights from the multiple conversations and specialist exchanges\n            4. Be engaging and educational, not just informative\n            5. Flow naturally from concept to concept with smooth transitions\n            6. Include moments of wonder and intellectual curiosity\n            7. Break down complex ideas into digestible parts\n            8. Use a teaching tone that makes the listener feel they're learning something fascinating\n            9. Write as continuous text ready to be read by a voice actor\n            10. NO section headers, NO subheaders, NO formatting marks\n            11. Don't address the public with greetings or goodbyes, but make questions\n            12. Always end up with questions for the reader and practical implications\n            13. Write as plain text that flows naturally for voice reading\n            14. NO [PAUSES], NO [MUSIC], NO stage directions - just the educational content\n            15. CRITICAL: Address the listener directly - \"puedes imaginar\", \"si consideras\", \"te darás cuenta\"\n            16. DO NOT write as if summarizing a discussion - write as if YOU are the teacher\n            17. Avoid phrases like \"los expertos discutieron\" or \"el equipo concluyó\"\n            18. Incorporate the depth and nuance that emerged from ALL agent conversations\n            \n            CRITICAL DIDACTIC TECHNIQUES - MANDATORY:\n            19. INTRODUCTION must include a compelling preview/roadmap: Start with an engaging hook and then preview what the listener will learn - \"En los próximos minutos vas a descubrir...\", \"Te voy a mostrar tres ideas que cambiarán tu forma de pensar sobre...\", etc.\n            20. CONCLUSION must include a clear summary: End with a recap of the main points covered - \"Hemos visto que...\", \"En resumen, tres puntos clave...\", \"Para cerrar, recordemos que...\", etc.\n            21. AVOID TYPICAL LLM WORDS: Never use overused AI-generated words like \"fundamental\", \"crucial\", \"clave\" (as adjective), \"esencial\", \"revelador\", \"fascinante\", \"delve into\", \"explore\", \"unpack\", \"dive deep\", \"robust\", \"compelling\", etc.\n            22. USE NATURAL LANGUAGE: Instead of LLM words, use conversational alternatives like \"importante\", \"interesante\", \"sorprendente\", \"nos ayuda a entender\", \"vamos a ver\", \"resulta que\", \"descubrimos que\", etc.\n            23. SOUND HUMAN: Write as if explaining to a friend over coffee, not as if generating academic content\n            \n            CRITICAL - MULTI-SPECIALIST INTEGRATION:\n            19. Weave in insights that could ONLY come from having multiple specialist perspectives\n            20. Include cross-disciplinary connections discovered during discussions\n            21. Incorporate domain-specific knowledge from ALL participating specialists\n            22. Show how different expert viewpoints enhance understanding of the topic\n            \n            23. Demonstrate the value of interdisciplinary analysis throughout\n            \n            \n            ACCESSIBLE LEVEL REQUIREMENTS:\n            15. Focus on core concepts and main findings rather than technical details\n            16. Use everyday analogies to explain complex ideas\n            17. Emphasize practical implications and real-world applications\n            18. Keep technical jargon to a minimum, always explaining when used\n            19. Focus on the \"why this matters\" rather than the \"how they did it\"\n            20. Make connections to things the audience already understands\n            \n            \n            \n        DURATION REQUIREMENT: EXACTLY 15 minutes of content (2100-2400 words) - THIS IS MANDATORY\n        \n        DEPTH GUIDANCE FOR 15 MINUTES:\n        \n            - Address 4-6 main concepts with moderate depth\n            - Include multiple examples and analogies per concept\n            - Provide relevant historical and theoretical context\n            - Explore implications and practical applications\n            - Include brief discussion of methodology if relevant\n            \n        \n        TECHNICAL CALCULATION:\n        - Target reading speed: ~150 words per minute\n        - Word range: 2100-2400 words\n        - If content is too short, EXPAND significantly with more detail and depth\n        - If too long, maintain quality but adjust information density\n        \n            \n            \n            LANGUAGE REQUIREMENTS FOR SPANISH:\n            \n            CRITICAL: AVOID ANGLICISMS whenever possible and use proper Spanish terms:\n            - Instead of \"link\" use \"enlace\" or \"vínculo\"\n            - Instead of \"feedback\" use \"retroalimentación\" or \"respuesta\"\n            - Insted of \"puzzle\" use \"rompecabezas\" or \"problema\"\n            - Instead of \"performance\" use \"rendimiento\" or \"desempeño\"\n            - Instead of \"input/output\" use \"entrada/salida\"\n            - Instead of \"update\" use \"actualizar\" or \"poner al día\"\n            \n            EXCEPTIONS - You CAN use anglicisms for:\n            1. Very new technical terms with no established translation (e.g., \"blockchain\", \"ChatGPT\")\n            2. Proper names of tools/companies (e.g., \"TensorFlow\", \"GitHub\", \"OpenAI\")\n            3. Widely adopted terms in scientific literature (e.g., \"machine learning\" vs \"aprendizaje automático\")\n            4. When the Spanish term is more confusing than helpful\n            \n            GENERAL RULES:\n            - Always prioritize natural Spanish expressions\n            - Use Spanish sentence structures and idioms\n            - Make it sound like a native Spanish speaker wrote it\n            - When you must use an anglicism, briefly explain it if needed\n            \n            \n            Language: Spanish\n            ",
      "expected_output": "Comprehensive educational script incorporating ALL conversation insights",
      "agent_role": "Educational Writer"
    },
    {
      "description": "\n            POST-PRODUCTION PHASE 3: FINAL VOICE OPTIMIZATION\n            \n            Transform the Educational Writer's script into a PERFECT voice-ready script.\n            \n            You are receiving the educational script that has been carefully crafted from all conversation insights\n            .\n            Your job is PURELY technical optimization for voice delivery.\n            \n            CRITICAL: Verify the content meets the 15-minute target (2100-2400 words). If it's too short, EXPAND it significantly.\n            CRITICAL: Ensure technical level is accessible - keep accessible but thorough.\n            \n            MANDATORY VOICE OPTIMIZATION REQUIREMENTS:\n            1. Create a SINGLE, CONTINUOUS text ready for a voice actor to read\n            2. Markdown formatting, but NO headers, NO bullet points, NO lists\n            3. Convert ALL content into natural, flowing sentences\n            4. Replace any remaining bullet points with complete sentences\n            5. Ensure PERFECT flow from sentence to sentence\n            6. Remove formatting marks: #, -, •, etc for titles and subtitles, but keep for bold and italic text\n            7. Make sure sentences are not too long or complex for voice delivery\n            8. Write naturally in Spanish without academic formalities\n            9. Remove any remaining conversational artifacts (\"como mencionamos antes\", \"en nuestra discusión\")\n            10. Ensure seamless transitions between concepts\n            11. Maintain the conversational richness but in a single educator voice\n            12. Read the text mentally to ensure it sounds natural when spoken\n            13. Ensure proper pronunciation flow for difficult technical terms\n            14. Remove any repetitive content that may have emerged from multiple discussions\n            15. Maintain the depth gained from agent conversations while ensuring clarity\n            16. Perfect pacing for natural speech rhythm\n            17. Eliminate any phrases that sound like committee work or group consensus\n            18. Make it sound like ONE expert who has deeply understood the topic\n            19. Ensure technical accuracy while maintaining conversational flow\n            20. Optimize for voice actor performance and listener engagement\n            21. This should sound like ONE VOICE teaching, not a summary of multiple voices\n            22. Avoid words that could make this sound like written by an LLM, like not often used words: \"fascinante\", \"delve\", \"revelador\"\n            23. Introduction should be a catchy hook that makes the listener want to listen to the entire video, something like a question or a statement that makes the listener want to know more\n            24. DO NOT add new content - only optimize existing content for voice delivery\n            25. DO NOT change the educational message - only improve its delivery\n            \n            CRITICAL DIDACTIC STRUCTURE VERIFICATION:\n            26. VERIFY INTRODUCTION includes preview/roadmap: Ensure there's a clear \"what you'll learn\" section early in the script\n            27. VERIFY CONCLUSION includes summary: Ensure there's a clear recap of main points at the end\n            28. REMOVE LLM WORDS: Replace any remaining \"fundamental\", \"crucial\", \"clave\" (adjective), \"esencial\", \"revelador\", \"fascinante\", \"compelling\", \"robust\", etc. with natural alternatives\n            29. HUMAN CONVERSATION: Ensure the entire script sounds like a knowledgeable person explaining something interesting, not AI-generated content\n            30. NATURAL FLOW: Check that didactic elements (preview, summary) flow naturally within the content, not as forced additions\n            \n\n            \n            LANGUAGE REQUIREMENTS FOR SPANISH:\n            \n            CRITICAL: AVOID ANGLICISMS whenever possible and use proper Spanish terms:\n            - Instead of \"link\" use \"enlace\" or \"vínculo\"\n            - Instead of \"feedback\" use \"retroalimentación\" or \"respuesta\"\n            - Insted of \"puzzle\" use \"rompecabezas\" or \"problema\"\n            - Instead of \"performance\" use \"rendimiento\" or \"desempeño\"\n            - Instead of \"input/output\" use \"entrada/salida\"\n            - Instead of \"update\" use \"actualizar\" or \"poner al día\"\n            \n            EXCEPTIONS - You CAN use anglicisms for:\n            1. Very new technical terms with no established translation (e.g., \"blockchain\", \"ChatGPT\")\n            2. Proper names of tools/companies (e.g., \"TensorFlow\", \"GitHub\", \"OpenAI\")\n            3. Widely adopted terms in scientific literature (e.g., \"machine learning\" vs \"aprendizaje automático\")\n            4. When the Spanish term is more confusing than helpful\n            \n            GENERAL RULES:\n            - Always prioritize natural Spanish expressions\n            - Use Spanish sentence structures and idioms\n            - Make it sound like a native Spanish speaker wrote it\n            - When you must use an anglicism, briefly explain it if needed\n            \n            \n            CRITICAL: This is the FINAL version that will be published. Make it PERFECT for voice delivery.\n            \n            Language: Spanish\n            ",
      "expected_output": "FINAL publication-ready voice script optimized for delivery (2100-2400 words)",
      "agent_role": "Voice Director"
    }
  ]
}