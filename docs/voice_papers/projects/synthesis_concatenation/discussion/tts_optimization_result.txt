TLDR: <break time="1.0s" />  
• Main finding/concept: The chapter introduces the evolution and scaling of AI from language models to foundation models, and the emergence of AI engineering as a discipline built on these advances. <break time="1.0s" />  
• Key supporting points: <break time="0.5s" />  
 – The scaling up of AI models has enabled powerful applications like ChatGPT and Midjourney while also lowering the barrier to building AI applications via model-as-a-service. <break time="0.5s" />  
 – Key technical foundations include language models, tokenization, self-supervision, autoregressive versus masked modeling, and the extension to multimodal (foundation) models. <break time="0.5s" />  
 – The rise of AI engineering is underpinned by general-purpose AI, increased investments, and a low entrance barrier thanks to accessible AI models and APIs. <break time="0.5s" />  
• Primary conclusion: The evolution from traditional ML to AI engineering has shifted the focus from model training to model adaptation, application development, and evaluation, setting the stage for a rapidly growing field with broad use cases and new engineering challenges.  

<break time="1.5s" />  
────────────────────────────────────────  
I. Introduction and Context <break time="1.0s" />  
──────────────────────────────────────── <break time="1.0s" />  
CHAPTER <break time="0.5s" />  
Introduction to Building AI Applications with Foundation Models <break time="1.0s" />  
If I could use only one word to describe AI post‑2020, it’d be scale. <break time="0.5s" />  
The AI models behind applications like ChatGPT, Google’s Gemini, and Midjourney are at such a scale that they’re consuming a nontrivial portion of the world’s electricity, and we’re at risk of running out of publicly available internet data to train them. <break time="1.0s" />  
The scaling up of AI models has two major consequences. <break time="0.5s" />  
First, AI models are becoming more powerful and capable of more tasks, enabling more applications. <break time="0.5s" />  
More people and teams leverage AI to increase productivity, create economic value, and improve quality of life. <break time="1.0s" />  
Second, training large language models (LLMs) requires data, compute resources, and specialized talent that only a few organizations can afford. <break time="0.5s" />  
This has led to the emergence of model as a service: models developed by these few organizations are made available for others to use as a service. <break time="0.5s" />  
Anyone who wishes to leverage AI to build applications can now use these models to do so without having to invest up front in building a model. <break time="1.0s" />  
In short, the demand for AI applications has increased while the barrier to entry for building AI applications has decreased. <break time="0.5s" />  
This has turned AI engineering—the process of building applications on top of readily available models—into one of the fastest‑growing engineering disciplines. <break time="1.0s" />  
Building applications on top of machine learning (ML) models isn’t new. <break time="0.5s" />  
Long before LLMs became prominent, AI was already powering many applications, including product recommendations, fraud detection, and churn prediction. <break time="0.5s" />  
While many principles of productionizing AI applications remain the same, the new generation of large‑scale, readily available models brings about new possibilities and new challenges, which are the focus of this book. <break time="1.0s" />  
This chapter begins with an overview of foundation models, the key catalyst behind the explosion of AI engineering. <break time="0.5s" />  
I’ll then discuss a range of successful AI use cases, each illustrating what AI is good and not yet good at. <break time="0.5s" />  
As AI’s capabilities expand daily, predicting its future possibilities becomes increasingly challenging. <break time="0.5s" />  
However, existing application patterns can help uncover opportunities today and offer clues about how AI may continue to be used in the future. <break time="1.0s" />  
To close out the chapter, I’ll provide an overview of the new AI stack, including what has changed with foundation models, what remains the same, and how the role of an AI engineer today differs from that of a traditional ML engineer.  

<break time="1.5s" />  
────────────────────────────────────────  
II. The Rise of AI Engineering <break time="1.0s" />  
──────────────────────────────────────── <break time="1.0s" />  
Foundation models emerged from large language models, which, in turn, originated as just language models. <break time="0.5s" />  
While applications like ChatGPT and GitHub’s Copilot may seem to have come out of nowhere, they are the culmination of decades of technology advancements, with the first language models emerging in the 1950s. <break time="1.0s" />  
This section traces the key breakthroughs that enabled the evolution from language models to AI engineering.  

<break time="1.5s" />  
────────────────────────────────────────  
III. From Language Models to Large Language Models <break time="1.0s" />  
──────────────────────────────────────── <break time="1.0s" />  
While language models have been around for a while, they’ve only been able to grow to the scale they are today with self‑supervision. <break time="0.5s" />  
This section gives a quick overview of what language model and self‑supervision mean. <break time="0.5s" />  
If you’re already familiar with those, feel free to skip this section. <break time="1.0s" />  

A. Language Models <break time="0.5s" />  
A language model encodes statistical information about one or more languages. <break time="0.5s" />  
Intuitively, this information tells us how likely a word is to appear in a given context. <break time="0.5s" />  
For example, given the context “My favorite color is __”, a language model that encodes English should predict “blue” more often than “car.” <break time="1.0s" />  
For non‑English languages, a single Unicode character can sometimes be represented as multiple tokens. <break time="1.0s" />  
The statistical nature of languages was discovered centuries ago. <break time="0.5s" />  
In the 1905 story “The Adventure of the Dancing Men,” Sherlock Holmes leveraged simple statistical information of English to decode sequences of mysterious stick figures. <break time="0.5s" />  
Since the most common letter in English is E, Holmes deduced that the most common stick figure must stand for E. <break time="1.0s" />  
Later on, Claude Shannon used more sophisticated statistics to decipher enemy messages during the Second World War. <break time="0.5s" />  
His work on how to model English was published in his 1951 landmark paper “Prediction and Entropy of Printed English.” <break time="0.5s" />  
Many concepts introduced in this paper, including entropy, are still used for language modeling today. <break time="1.0s" />  
In the early days, a language model involved one language. <break time="0.5s" />  
However, today, a language model can involve multiple languages. <break time="1.0s" />  
The basic unit of a language model is token. <break time="0.5s" />  
A token can be a character, a word, or a part of a word (like “-tion”), depending on the model. <break time="0.5s" />  
For example, GPT‑4, a model behind ChatGPT, breaks the phrase “I can’t wait to build AI applications” into nine tokens, as shown in Figure‑1. <break time="0.5s" />  
Note that in this example, the word “can’t” is broken into two tokens, “can” and “t.” <break time="0.5s" />  
You can see how different OpenAI models tokenize text on the OpenAI website. <break time="1.0s" />  
Figure‑1. An example of how GPT‑4 tokenizes a phrase. <break time="1.0s" />  
The process of breaking the original text into tokens is called tokenization. <break time="0.5s" />  
For GPT‑4, an average token is approximately ¾ the length of a word. <break time="0.5s" />  
So, 100 tokens are approximately 75 words. <break time="1.0s" />  
The set of all tokens a model can work with is the model’s vocabulary. <break time="0.5s" />  
You can use a small number of tokens to construct a large number of distinct words, similar to how you can use a few letters in the alphabet to construct many words. <break time="0.5s" />  
The Mixtral 8x7B model has a vocabulary size of 32,000. <break time="0.5s" />  
GPT‑4’s vocabulary size is 100,256. <break time="0.5s" />  
The tokenization method and vocabulary size are decided by model developers. <break time="1.0s" />  

B. Why Tokens? <break time="0.5s" />  
Why do language models use token as their unit instead of word or character? <break time="0.5s" />  
There are three main reasons: <break time="1.0s" />  
1. Compared to characters, tokens allow the model to break words into meaningful components. <break time="0.5s" />  
For example, “cooking” can be broken into “cook” and “ing,” with both components carrying some meaning of the original word. <break time="1.0s" />  
2. Because there are fewer unique tokens than unique words, this reduces the model’s vocabulary size, making the model more efficient (as discussed in Chapter 2). <break time="1.0s" />  
3. Tokens also help the model process unknown words. <break time="0.5s" />  
For instance, a made‑up word like “chatgpting” could be split into “chatgpt” and “ing,” helping the model understand its structure. <break time="0.5s" />  
Tokens balance having fewer units than words while retaining more meaning than individual characters.  

<break time="1.5s" />  
C. Types of Language Models <break time="0.5s" />  
There are two main types of language models: masked language models and autoregressive language models. <break time="0.5s" />  
They differ based on what information they can use to predict a token: <break time="1.0s" />  
– Masked language model: A masked language model is trained to predict missing tokens anywhere in a sequence, using the context from both before and after the missing tokens. <break time="0.5s" />  
In essence, a masked language model is trained to be able to fill in the blank. <break time="0.5s" />  
For example, given the context “My favorite __ is blue,” a masked language model should predict that the blank is likely “color.” <break time="0.5s" />  
A well‑known example of a masked language model is bidirectional encoder representations from transformers, or BERT. <break time="0.5s" />  
As of writing, masked language models are commonly used for non‑generative tasks such as sentiment analysis and text classification. <break time="0.5s" />  
They are also useful for tasks requiring an understanding of the overall context, such as code debugging, where a model needs to understand both the preceding and following code to identify errors. <break time="1.0s" />  
– Autoregressive language model: An autoregressive language model is trained to predict the next token in a sequence, using only the preceding tokens. <break time="0.5s" />  
It predicts what comes next in “My favorite color is __.” <break time="0.5s" />  
An autoregressive model can continually generate one token after another. <break time="0.5s" />  
Today, autoregressive language models are the models of Chapter 1: Introduction to Building AI Applications with Foundation Models. <break time="0.5s" />  
Technically, a masked language model like BERT can also be used for text generation if you try really hard, but autoregressive models are the choice for text generation, and for this reason, they are much more popular than masked language models. <break time="1.0s" />  
Figure‑2 shows these two types of language models. <break time="0.5s" />  
Figure‑2. Autoregressive language model and masked language model. <break time="1.0s" />  
In this book, unless explicitly stated, “language model” will refer to an autoregressive model. <break time="1.0s" />  
The outputs of language models are open‑ended. <break time="0.5s" />  
A language model can use its fixed, finite vocabulary to construct infinite possible outputs. <break time="0.5s" />  
A model that can generate open‑ended outputs is called generative, hence the term generative AI. <break time="1.0s" />  
You can think of a language model as a completion machine: given a text (prompt), it tries to complete that text. <break time="0.5s" />  
Here’s an example: <break time="0.5s" />  
 Prompt (from user): To be or not to be <break time="0.5s" />  
 Completion (from language model): , that is the question. <break time="1.0s" />  
It’s important to note that completions are predictions, based on probabilities, and not guaranteed to be correct. <break time="0.5s" />  
This probabilistic nature of language models makes them both so exciting and frustrating to use. <break time="1.0s" />  
We explore this further in Chapter 2.  

<break time="1.5s" />  
D. The Power of Completion <break time="0.5s" />  
As simple as it sounds, completion is incredibly powerful. <break time="0.5s" />  
Many tasks, including translation, summarization, coding, and solving math problems, can be framed as completion tasks. <break time="0.5s" />  
For example, given the prompt: “How are you in French is …”, a language model might be able to complete it with: “Comment ça va”, effectively translating from one language to another. <break time="1.0s" />  
As another example, given the prompt: <break time="0.5s" />  
 Question: Is this email likely spam? Here’s the email: [email content] <break time="0.5s" />  
 Answer: <break time="0.5s" />  
A language model might be able to complete it with: “Likely spam”, which turns this language model into a spam classifier. <break time="1.0s" />  
While completion is powerful, completion isn’t the same as engaging in a conversation. <break time="0.5s" />  
For example, if you ask a completion machine a question, it can complete what you said by adding another question instead of answering the question. <break time="0.5s" />  
Post‑Training on page 78 discusses how to make a model respond appropriately to a user’s request.  

<break time="1.5s" />  
────────────────────────────────────────  
IV. Self‑Supervision <break time="1.0s" />  
──────────────────────────────────────── <break time="1.0s" />  
Language modeling is just one of many ML algorithms. <break time="0.5s" />  
There are also models for object detection, topic modeling, recommender systems, weather forecasting, stock price prediction, etc. <break time="0.5s" />  
What’s special about language models that made them the center of the scaling approach that caused the ChatGPT moment? <break time="1.0s" />  
The answer is that language models can be trained using self‑supervision, while many other models require supervision. <break time="0.5s" />  
Supervision refers to the process of training ML algorithms using labeled data, which can be expensive and slow to obtain. <break time="0.5s" />  
Self‑supervision helps overcome this data labeling bottleneck to create larger datasets for models to learn from, effectively allowing models to scale up. <break time="1.0s" />  
Here’s how.  

A. Supervision vs. Self‑Supervision <break time="0.5s" />  
With supervision, you label examples to show the behaviors you want the model to learn, and then train the model on these examples. <break time="0.5s" />  
Once trained, the model can be applied to new data. <break time="0.5s" />  
For example, to train a fraud detection model, you use examples of transactions, each labeled with “fraud” or “not fraud.” <break time="0.5s" />  
Once the model learns from these examples, you can use this model to predict whether a transaction is fraudulent. <break time="1.0s" />  
The success of AI models in the 2010s lay in supervision. <break time="0.5s" />  
The model that started the deep learning revolution, AlexNet, was supervised. <break time="0.5s" />  
It was trained to learn how to classify over 1 million images in the dataset ImageNet. <break time="0.5s" />  
It classified each image into one of 1,000 categories such as car, balloon, or monkey. <break time="1.0s" />  
The actual data labeling cost varies depending on several factors, including the task’s complexity, the scale (larger datasets typically result in lower per‑sample costs), and the labeling service provider. <break time="0.5s" />  
For example, as of September 2024, Amazon SageMaker Ground Truth charges 8 cents per image for labeling fewer than 50,000 images, but only 2 cents per image for labeling more than 1 million images. <break time="1.0s" />  
A drawback of supervision is that data labeling is expensive and time‑consuming. <break time="0.5s" />  
If it costs 5 cents for one person to label one image, it’d cost $50,000 to label a million images for ImageNet. <break time="0.5s" />  
If you want two different people to label each image—so that you could cross‑check label quality—it’d cost twice as much. <break time="0.5s" />  
Because the world contains vastly more than 1,000 objects, to expand models’ capabilities to work with more objects, you’d need to add labels of more categories. <break time="0.5s" />  
To scale up to 1 million categories, the labeling cost alone would increase to $50 million. <break time="1.0s" />  
Labeling everyday objects is something that most people can do without prior training. <break time="0.5s" />  
Hence, it can be done relatively cheaply. <break time="0.5s" />  
However, not all labeling tasks are that simple. <break time="0.5s" />  
Generating Latin translations for an English‑to‑Latin model is more expensive. <break time="0.5s" />  
Labeling whether a CT scan shows signs of cancer would be astronomical. <break time="1.0s" />  

B. How Self‑Supervision Works <break time="0.5s" />  
Self‑supervision helps overcome the data labeling bottleneck. <break time="0.5s" />  
In self‑supervision, instead of requiring explicit labels, the model can infer labels from the input data. <break time="0.5s" />  
Language modeling is self‑supervised because each input sequence provides both the labels (tokens to be predicted) and the contexts the model can use to predict these labels. <break time="0.5s" />  
For example, the sentence “I love street food.” gives six training samples, as shown in Table‑1. <break time="1.0s" />  
Table‑1. Training samples from the sentence “I love street food.” for language modeling. <break time="0.5s" />  
 Input (context)    Output (next token) <break time="0.5s" />  
 BOS <break time="0.5s" />  
 BOS, I <break time="0.5s" />  
 love <break time="0.5s" />  
 BOS, I, love <break time="0.5s" />  
 street <break time="0.5s" />  
 BOS, I, love, street <break time="0.5s" />  
 food <break time="0.5s" />  
 BOS, I, love, street, food <break time="0.5s" />  
 BOS, I, love, street, food, . <break time="0.5s" />  
 EOS <break time="1.0s" />  
In Table‑1, BOS and EOS mark the beginning and the end of a sequence. <break time="0.5s" />  
These markers are necessary for a language model to work with multiple sequences. <break time="0.5s" />  
Each marker is typically treated as one special token by the model. <break time="0.5s" />  
The end‑of‑sequence marker is especially important as it helps language models know when to end their responses. <break time="1.0s" />  
It might seem counterintuitive that larger models require more training data. <break time="0.5s" />  
If a model is more powerful, shouldn’t it require fewer examples to learn from? <break time="0.5s" />  
However, we’re not trying to get a large model to match the performance of a small model using the same data; <break time="0.5s" />  
we’re trying to maximize model performance. <break time="0.5s" />  
Larger models have more capacity to learn and therefore need more training data. <break time="1.0s" />  
Self‑supervision differs from unsupervision. <break time="0.5s" />  
In self‑supervised learning, labels are inferred from the input data. <break time="0.5s" />  
In unsupervised learning, you don’t need labels at all. <break time="0.5s" />  
Self‑supervised learning means that language models can learn from text sequences without requiring any labeling. <break time="0.5s" />  
Because text sequences are everywhere—in books, blog posts, articles, and Reddit comments—it’s possible to construct a massive amount of training data, allowing language models to scale up to become LLMs. <break time="1.0s" />  
LLM, however, is hardly a scientific term. <break time="0.5s" />  
How large does a language model have to be to be considered large? <break time="0.5s" />  
What is large today might be considered tiny tomorrow. <break time="0.5s" />  
A model’s size is typically measured by its number of parameters. <break time="0.5s" />  
A parameter is a variable within an ML model that is updated through the training process. <break time="0.5s" />  
In general, though this is not always true, the more parameters a model has, the greater its capacity to learn desired behaviors. <break time="1.0s" />  
When OpenAI’s first generative pre‑trained transformer (GPT) model came out in June 2018, it had 117 million parameters, and that was considered large. <break time="0.5s" />  
In February 2019, when OpenAI introduced GPT‑2 with 1.5 billion parameters, 117 million was downgraded to be considered small. <break time="0.5s" />  
As of the writing of this book, a model with billion parameters is considered large. <break time="0.5s" />  
Perhaps one day, this size will be considered small. <break time="1.0s" />  
Before we move on to the next section, I want to touch on a question that is usually taken for granted: <break time="0.5s" />  
Why do larger models need more data? <break time="0.5s" />  
Larger models have more capacity to learn, and therefore would need more training data to maximize their performance. <break time="0.5s" />  
You can train a large model on a small dataset too, but it’d be a waste of compute. <break time="0.5s" />  
You could have achieved similar or better results on this dataset with smaller models.  

<break time="1.5s" />  
────────────────────────────────────────  
V. From Large Language Models to Foundation Models <break time="1.0s" />  
──────────────────────────────────────── <break time="1.0s" />  
While language models are capable of incredible tasks, they are limited to text. <break time="0.5s" />  
As humans, we perceive the world not just via language but also through vision, hearing, touch, and more. <break time="0.5s" />  
Being able to process data beyond text is essential for AI to operate in the real world. <break time="1.0s" />  
For this reason, language models are being extended to incorporate more data modalities. <break time="0.5s" />  
GPT‑4V and Claude 3 can understand images and texts. <break time="0.5s" />  
Some models even understand videos, 3D assets, protein structures, and so on. <break time="0.5s" />  
Incorporating more data modalities into language models makes them even more powerful. <break time="0.5s" />  
OpenAI noted in their GPT‑4V system card in 2023 that incorporating additional modalities (such as image inputs) into LLMs is viewed by some as a key frontier in AI research and development. <break time="1.0s" />  
While many people still call Gemini and GPT‑4V LLMs, they’re better characterized as foundation models. <break time="0.5s" />  
The word "foundation" signifies both the importance of these models in AI applications and the fact that they can be built upon for different needs. <break time="0.5s" />  
Foundation models mark a breakthrough from the traditional structure of AI research. <break time="1.0s" />  
For a long time, AI research was divided by data modalities. <break time="0.5s" />  
Natural language processing (NLP) deals only with text. <break time="0.5s" />  
Computer vision deals only with vision. <break time="0.5s" />  
Text‑only models can be used for tasks such as translation and spam detection. <break time="0.5s" />  
Image‑only models can be used for object detection and image classification. <break time="0.5s" />  
Audio‑only models can handle speech recognition (speech‑to‑text, or TTS) and speech synthesis (text‑to‑speech, or TTS). <break time="1.0s" />  
A model that can work with more than one data modality is also called a multimodal model. <break time="0.5s" />  
A generative multimodal model is also called a large multimodal model (LMM). <break time="0.5s" />  
If a language model generates the next token conditioned on text‑only tokens, a multimodal model generates the next token conditioned on both text and image tokens, or whichever modalities that the model supports, as shown in Figure‑3. <break time="1.0s" />  
Figure‑3. A multimodal model can generate the next token using information from both text and visual tokens. <break time="1.0s" />  
Just like language models, multimodal models need data to scale up. <break time="0.5s" />  
Self‑supervision works for multimodal models too. <break time="0.5s" />  
For example, OpenAI used a variant of self‑supervision called natural language supervision to train their language‑image model CLIP (OpenAI, 2021). <break time="0.5s" />  
Instead of manually generating labels for each image, they found (image, text) pairs that co‑occurred on the internet. <break time="0.5s" />  
They were able to generate a dataset of 400 million (image, text) pairs, which was 400 times larger than ImageNet, without manual labeling cost. <break time="0.5s" />  
This dataset enabled CLIP to become the first model that could generalize to multiple image classification tasks without requiring additional training. <break time="1.0s" />  
This book uses the term foundation models to refer to both large language models and large multimodal models. <break time="1.0s" />  
Note that CLIP isn’t a generative model—it wasn’t trained to generate open‑ended outputs. <break time="0.5s" />  
CLIP is an embedding model, trained to produce joint embeddings of both texts and images. <break time="0.5s" />  
Introduction to Embedding on page 134 discusses embeddings in detail. <break time="0.5s" />  
For now, you can think of embeddings as vectors that aim to capture the meanings of the original data. <break time="0.5s" />  
Multimodal embedding models like CLIP are the backbones of generative multimodal models, such as Flamingo, LLaVA, and Gemini (previously Bard). <break time="1.0s" />  
Foundation models also mark the transition from task‑specific models to general‑purpose models. <break time="0.5s" />  
Previously, models were often developed for specific tasks, such as sentiment analysis or translation. <break time="0.5s" />  
A model trained for sentiment analysis wouldn’t be able to do translation, and vice versa. <break time="0.5s" />  
Foundation models, thanks to their scale and the way they are trained, are capable of a wide range of tasks. <break time="0.5s" />  
Out‑of‑the‑box, general‑purpose models can work relatively well for many tasks. <break time="0.5s" />  
An LLM can do both sentiment analysis and translation. <break time="0.5s" />  
However, you can often tweak a general‑purpose model to maximize its performance on a specific task. <break time="1.0s" />  
Figure‑4 shows the tasks used by the Super‑NaturalInstructions benchmark to evaluate foundation models, providing an idea of the types of tasks a foundation model can perform. <break time="1.0s" />  
Imagine you’re working with a retailer to build an application to generate product descriptions for their website. <break time="0.5s" />  
An out‑of‑the‑box model might be able to generate accurate descriptions but might fail to capture the brand’s voice or highlight the brand’s messaging. <break time="0.5s" />  
The generated descriptions might even be full of marketing speech and cliches. <break time="1.0s" />  
There are multiple techniques you can use to get the model to generate what you want. <break time="0.5s" />  
For example, you can craft detailed instructions with examples of the desirable product descriptions. <break time="0.5s" />  
This approach is prompt engineering. <break time="0.5s" />  
You can connect the model to a database of customer reviews that the model can leverage to generate better descriptions. <break time="0.5s" />  
Using a database to supplement the instructions is called retrieval‑augmented generation (RAG). <break time="0.5s" />  
You can also finetune—further train—the model on a dataset of high‑quality product descriptions. <break time="1.0s" />  
Prompt engineering, RAG, and finetuning are three very common AI engineering techniques that you can use to adapt a model to your needs. <break time="0.5s" />  
The rest of the book will discuss all of them in detail. <break time="1.0s" />  
Adapting an existing powerful model to your task is generally a lot easier than building a model for your task from scratch—for example, ten examples and one weekend versus 1 million examples and six months. <break time="0.5s" />  
Foundation models make it cheaper to develop AI applications and reduce time to market. <break time="0.5s" />  
Exactly how much data is needed to adapt a model depends on what technique you use. <break time="0.5s" />  
This book will also touch on this question when discussing each technique. <break time="0.5s" />  
However, there are still many benefits to task‑specific models, for example, they might be a lot smaller, making them faster and cheaper to use. <break time="1.0s" />  
Whether to build your own model or leverage an existing one is a classic buy‑or‑build question that teams will have to answer for themselves. <break time="0.5s" />  
Discussions throughout the book can help with that decision.  

<break time="1.5s" />  
────────────────────────────────────────  
VI. From Foundation Models to AI Engineering <break time="1.0s" />  
──────────────────────────────────────── <break time="1.0s" />  
AI engineering refers to the process of building applications on top of foundation models. <break time="0.5s" />  
People have been building AI applications for over a decade—a process often known as ML engineering or MLOps (short for ML operations). <break time="0.5s" />  
Why do we talk about AI engineering now? <break time="1.0s" />  
If traditional ML engineering involves developing ML models, AI engineering leverages existing ones. <break time="0.5s" />  
The availability and accessibility of powerful foundation models lead to three factors that, together, create ideal conditions for the rapid growth of AI engineering as a discipline: <break time="1.0s" />  

A. Factor 1: General‑Purpose AI Capabilities <break time="0.5s" />  
Foundation models are powerful not just because they can do existing tasks better. <break time="0.5s" />  
They are also powerful because they can do more tasks. <break time="0.5s" />  
Applications previously thought impossible are now possible, and applications not thought of before are emerging. <break time="0.5s" />  
Even applications not thought possible today might be possible tomorrow. <break time="0.5s" />  
This makes AI more useful for more aspects of life, vastly increasing both the user base and the demand for AI applications. <break time="1.0s" />  
For example, since AI can now write as well as humans, sometimes even better, AI can automate or partially automate every task that requires communication—which is pretty much everything. <break time="0.5s" />  
AI is used to write emails, respond to customer requests, and explain complex contracts. <break time="0.5s" />  
Anyone with a computer has access to tools that can instantly generate customized, high‑quality images and videos to help create marketing materials, edit professional headshots, visualize art concepts, illustrate books, and so on. <break time="0.5s" />  
AI can even be used to synthesize training data, develop algorithms, and write code, all of which will help train even more powerful models in the future. <break time="1.0s" />  
For comparison, the entire US expenditures for public elementary and secondary schools are around $900 billion, only nine times the investments in AI in the US.  

<break time="1.5s" />  
B. Factor 2: Increased AI Investments <break time="0.5s" />  
The success of ChatGPT prompted a sharp increase in investments in AI, both from venture capitalists and enterprises. <break time="0.5s" />  
As AI applications become cheaper to build and faster to go to market, returns on investment for AI become more attractive. <break time="0.5s" />  
Companies rush to incorporate AI into their products and processes. <break time="1.0s" />  
Matt Ross, a senior manager of applied research at Scribd, told me that the estimated AI cost for his use cases has gone down two orders of magnitude from April 2022 to April 2023. <break time="1.0s" />  
Goldman Sachs Research estimated that AI investment could approach $100 billion in the US and $200 billion globally by 2025. <break time="0.5s" />  
AI is often mentioned as a competitive advantage. <break time="0.5s" />  
FactSet found that one in three S&P 500 companies mentioned AI in their earnings calls for the second quarter of 2023, three times more than did so the year earlier. <break time="1.0s" />  
Figure‑5 shows the number of S&P 500 companies that mentioned AI in their earning calls from 2018 to 2023. <break time="0.5s" />  
Figure‑5. The number of S&P 500 companies that mention AI in their earnings calls reached a record high in 2023. Data from FactSet. <break time="1.0s" />  
According to WallStreetZen, companies that mentioned AI in their earning calls saw their stock price increase more than those that didn’t: an average of a 4.6% increase compared to 2.4%. <break time="0.5s" />  
It’s unclear whether it’s causation (AI makes these companies more successful) or correlation (companies are successful because they are quick to adapt to new technologies).  

<break time="1.5s" />  
C. Factor 3: Low Entrance Barrier to Building AI Applications <break time="0.5s" />  
The model‑as‑a‑service approach popularized by OpenAI and other model providers makes it easier to leverage AI to build applications. <break time="0.5s" />  
In this approach, models are exposed via APIs that receive user queries and return model outputs. <break time="0.5s" />  
Not only that, AI also makes it possible to build applications with minimal coding. <break time="0.5s" />  
First, AI can write code for you, allowing people without a software engineering background to quickly turn their ideas into code and put them in front of their users. <break time="0.5s" />  
Second, you can work with these models in plain English instead of having to use a programming language. <break time="0.5s" />  
Anyone, and I mean anyone, can now develop AI applications. <break time="1.0s" />  
Because of the resources it takes to develop foundation models, this process is possible only for big corporations (Google, Meta, Microsoft, Baidu, Tencent), governments (Japan, the UAE), and ambitious, well‑funded startups (OpenAI, Anthropic, Mistral). <break time="0.5s" />  
In a September 2022 interview, Sam Altman, CEO of OpenAI, said that the biggest opportunity for the vast majority of people will be to adapt these models for specific applications. <break time="1.0s" />  
The world is quick to embrace this opportunity. <break time="0.5s" />  
AI engineering has rapidly emerged as one of the fastest, and quite possibly the fastest‑growing, engineering disciplines. <break time="1.0s" />  
Tools for AI engineering are gaining traction faster than any previous software engineering tools. <break time="0.5s" />  
Within just two years, four open source AI engineering tools (AutoGPT, Stable Diffusion eb UI, LangChain, Ollama) have already garnered more stars on GitHub than Bitcoin. <break time="0.5s" />  
They are on track to surpass even the most popular web development frameworks, including React and Vue, in star count. <break time="1.0s" />  
Figure‑6 shows the GitHub star growth of AI engineering tools compared to Bitcoin, Vue, and React. <break time="0.5s" />  
A LinkedIn survey from August 2023 shows that the number of professionals adding terms like Generative AI, ChatGPT, Prompt Engineering, and Prompt Crafting to their profile increased on average 75% each month. <break time="0.5s" />  
ComputerWorld declared that teaching AI to behave is the fastest‑growing career skill. <break time="0.5s" />  
Figure‑6. Open source AI engineering tools are growing faster than any other software engineering tools, according to their GitHub star counts. <break time="1.0s" />  

D. Why the Term AI Engineering? <break time="0.5s" />  
Many terms are being used to describe the process of building applications on top of foundation models, including ML engineering, MLOps, AIOps, LLMOps, etc. <break time="0.5s" />  
I didn’t go with the term ML engineering because, as discussed in AI Engineering Versus ML Engineering on page 39, working with foundation models differs from working with traditional ML models in several important aspects. <break time="0.5s" />  
The term ML engineering won’t be sufficient to capture this differentiation. <break time="0.5s" />  
However, ML engineering is a great term to encompass both processes. <break time="0.5s" />  
I didn’t go with all the terms that end with “Ops” because, while there are operational components of the process, the focus is more on tweaking (engineering) foundation models to do what you want. <break time="0.5s" />  
Finally, I surveyed 20 people who were developing applications on top of foundation models about what term they would use to describe what they were doing. <break time="0.5s" />  
Most people preferred “AI engineering.” <break time="0.5s" />  
I decided to go with the people. <break time="0.5s" />  
Fun fact: as of September 16, 2024, the website theresanaiforthat.com lists 16,814 AIs for 14,688 tasks and 4,803 jobs. <break time="1.0s" />  
The rapidly expanding community of AI engineers has demonstrated remarkable creativity with an incredible range of exciting applications. <break time="0.5s" />  
The next section will explore some of the most common application patterns.  

<break time="1.5s" />  
────────────────────────────────────────  
VII. Foundation Model Use Cases <break time="1.0s" />  
──────────────────────────────────────── <break time="1.0s" />  
If you’re not already building AI applications, I hope the previous section has convinced you that now is a great time to do so. <break time="0.5s" />  
If you have an application in mind, you might want to jump to Planning AI Applications on page 28. <break time="0.5s" />  
If you’re looking for inspiration, this section covers a wide range of industry‑proven and promising use cases. <break time="1.0s" />  
The number of potential applications that you could build with foundation models seems endless. <break time="0.5s" />  
Whatever use case you think of, there’s probably an AI for that. <break time="0.5s" />  
It’s impossible to list all potential use cases for AI. <break time="1.0s" />  
Even attempting to categorize these use cases is challenging, as different surveys use different categorizations. <break time="0.5s" />  
For example, Amazon Web Services (AWS) has categorized enterprise generative AI use cases into three buckets: customer experience, employee productivity, and process optimization. <break time="0.5s" />  
A 2024 O’Reilly survey categorized the use cases into eight categories: programming, data analysis, customer support, marketing copy, other copy, research, web design, and art. <break time="0.5s" />  
Some organizations, like Deloitte, have categorized use cases by value capture, such as cost reduction, process efficiency, growth, and accelerating innovation. <break time="0.5s" />  
For value capture, Gartner has a category for business continuity, meaning an organization might go out of business if it doesn’t adopt generative AI. <break time="0.5s" />  
Of the 2,500 executives Gartner surveyed in 2023, 7% cited business continuity as the motivation for embracing generative AI. <break time="1.0s" />  
Eloundou et al. has excellent research on how exposed different occupations are to AI. <break time="0.5s" />  
They defined a task as “exposed” if AI and AI‑powered software can reduce the time needed to complete this task by at least 50%. <break time="0.5s" />  
An occupation with 80% exposure means that 80% of the occupation’s tasks are exposed. <break time="0.5s" />  
According to the study, occupations with 100% or close to 100% exposure include interpreters and translators, tax preparers, web designers, and writers. <break time="0.5s" />  
Some of them are shown in Table‑2. <break time="1.0s" />  
Not unsurprisingly, occupations with no exposure to AI include cooks, stonemasons, and athletes. <break time="0.5s" />  
This study gives a good idea of what use cases AI is good for. <break time="1.0s" />  
Table‑2. Occupations with the highest exposure to AI as annotated by humans. <break time="0.5s" />  
α refers to exposure to AI models directly, whereas β and ζ refer to exposures to AI‑powered software. <break time="0.5s" />  
 Group                 Occupations with highest exposure         % Exposure <break time="0.5s" />  
 Human α          Interpreters and translators, Survey researchers, Poets, lyricists, and creative writers, Animal scientists, Public relations specialists        76.5, 75.0, 68.8, 66.7, 66.7 <break time="0.5s" />  
 Human β          Survey researchers, Writers and authors, Interpreters and translators, Public relations specialists, Animal scientists        84.4, 82.5, 82.4, 80.6, 77.8 <break time="0.5s" />  
 Human ζ          Tax preparers, Financial quantitative analysts, Writers and authors, Web and digital interface designers        100.0, 100.0, 100.0, 100.0, 100.0 <break time="1.0s" />  
Exploring different AI applications is perhaps one of my favorite things about writing this book. <break time="0.5s" />  
It’s a lot of fun seeing what people are building. <break time="0.5s" />  
You can find the list of open source AI applications that I track. <break time="0.5s" />  
The list is updated every 12 hours. <break time="1.0s" />  

To understand enterprise use cases, I interviewed 50 companies on their AI strategies and read over 100 case studies. <break time="0.5s" />  
To understand consumer applications, I examined open source AI applications with at least 500 stars on GitHub. <break time="0.5s" />  
I categorized applications into eight groups, as shown in Table‑3. <break time="0.5s" />  
The limited list here serves best as a reference. <break time="0.5s" />  
As you learn more about how to build foundation models in Chapter [x] and how to evaluate them in Chapter 3, you’ll also be able to form a better picture of what use cases foundation models can and should be used for. <break time="1.0s" />  
Table‑3. Common generative AI use cases across consumer and enterprise applications. <break time="0.5s" />  
 Category      Examples of consumer use cases      Examples of enterprise use cases <break time="0.5s" />  
 Coding      Coding      Coding <break time="0.5s" />  
 Image and video   Photo and video editing     Design      Ad generation <break time="0.5s" />  
 Writing      Email, Social media and blog posts  Copywriting, search engine optimization (SEO), Reports, memos, design docs <break time="0.5s" />  
 Education      Tutoring, Essay grading, Employee onboarding, Employee upskill training  — <break time="0.5s" />  
 Conversational bots    General chatbot, AI companion    Customer support, Product copilots <break time="0.5s" />  
 Information aggregation    Talk‑to‑your‑docs, Market research    Data organization, Image search, Memex, Knowledge management, Document processing <break time="0.5s" />  
 Travel planning      Event planning, Data extraction, entry, and annotation  — <break time="0.5s" />  
 Lead generation      — <break time="1.0s" />  
Because foundation models are general, applications built on top of them can solve many problems. <break time="0.5s" />  
This means that an application can belong to more than one category. <break time="0.5s" />  
For example, a bot can provide companionship and aggregate information. <break time="0.5s" />  
An application can help you extract structured data from a PDF and answer questions about that PDF. <break time="1.0s" />  
Figure‑7 shows the distribution of these use cases among the 205 open source applications. <break time="0.5s" />  
Note that the small percentage of education, data organization, and writing use cases doesn’t mean that these use cases aren’t popular. <break time="0.5s" />  
It just means that these applications aren’t open source. <break time="0.5s" />  
Builders of these applications might find them more suitable for enterprise use cases. <break time="1.0s" />  
Figure‑7. Distribution of use cases in the 205 open source repositories on GitHub. <break time="1.0s" />  
The enterprise world generally prefers applications with lower risks. <break time="0.5s" />  
For example, a a16z Growth report showed that companies are faster to deploy internal‑facing applications (internal knowledge management) than external‑facing applications (customer support chatbots), as shown in Figure‑8. <break time="0.5s" />  
Internal applications help companies develop their AI engineering expertise while minimizing the risks associated with data privacy, compliance, and potential catastrophic failures. <break time="0.5s" />  
Similarly, while foundation models are open‑ended and can be used for any task, many applications built on top of them are still close‑ended, such as classification. <break time="0.5s" />  
Classification tasks are easier to evaluate, which makes their risks easier to estimate. <break time="1.0s" />  
Figure‑8. Companies are more willing to deploy internal‑facing applications <break time="1.0s" />  
Even after seeing hundreds of AI applications, I still find new applications that surprise me every week. <break time="0.5s" />  
In the early days of the internet, few people foresaw that the dominating use case on the internet one day would be social media. <break time="0.5s" />  
As we learn to make the most out of AI, the use case that will eventually dominate might surprise us. <break time="0.5s" />  
With luck, the surprise will be a good one.  

<break time="1.5s" />  
A. Coding <break time="0.5s" />  
In multiple generative AI surveys, coding is hands down the most popular use case. <break time="0.5s" />  
AI coding tools are popular both because AI is good at coding and because early AI engineers are coders who are more exposed to coding challenges. <break time="1.0s" />  
One of the earliest successes of foundation models in production is the code completion tool GitHub Copilot, whose annual recurring revenue crossed $100 million only two years after its launch. <break time="0.5s" />  
As of this writing, AI‑powered coding startups have raised hundreds of millions of dollars, with Magic raising $320 million and Anysphere raising $60 million, both in August 2024. <break time="0.5s" />  
Open source coding tools like gpt‑engineer and screenshot‑to‑code both got 50,000 stars on GitHub within a year, and many more are being rapidly introduced. <break time="1.0s" />  
Other than tools that help with general coding, many tools specialize in certain coding tasks. <break time="0.5s" />  
Here are examples of these tasks: <break time="0.5s" />  
 • Extracting structured data from web pages and PDFs (AgentGPT) <break time="0.5s" />  
 • Converting English to code (DB‑GPT, SQL Chat, PandasAI) <break time="0.5s" />  
 • Given a design or a screenshot, generating code that will render into a website that looks like the given image (screenshot‑to‑code, draw‑a‑ui) <break time="0.5s" />  
 • Translating from one programming language or framework to another (GPTMigrate, AI Code Translator) <break time="0.5s" />  
 • Writing documentation (Autodoc) <break time="0.5s" />  
 • Creating tests (PentestGPT) <break time="0.5s" />  
 • Generating commit messages (AI Commits) <break time="1.0s" />  
It’s clear that AI can do many software engineering tasks. <break time="0.5s" />  
The question is whether AI can automate software engineering altogether. <break time="0.5s" />  
At one end of the spectrum, Jensen Huang, CEO of NVIDIA, predicts that AI will replace human software engineers and that we should stop saying kids should learn to code. <break time="0.5s" />  
In a leaked recording, AWS CEO Matt Garman shared that in the near future, most developers will stop coding. <break time="0.5s" />  
He doesn’t mean it as the end of software developers; it’s just that their jobs will change. <break time="1.0s" />  
At the other end are many software engineers who are convinced that they will never be replaced by AI, both for technical and emotional reasons (people don’t like admitting that they can be replaced). <break time="1.0s" />  
Software engineering consists of many tasks. <break time="0.5s" />  
AI is better at some than others. <break time="0.5s" />  
McKinsey researchers found that AI can help developers be twice as productive for documentation, and 25‑50% more productive for code generation and code refactoring. <break time="0.5s" />  
Minimal productivity improvement was observed for highly complex tasks, as shown in Figure‑9. <break time="0.5s" />  
In my conversations with developers of AI coding tools, many told me that they’ve noticed that AI is much better at frontend development than backend development. <break time="1.0s" />  
Figure‑9. AI can help developers be significantly more productive, especially for simple tasks, but this applies less for highly complex tasks. Data by McKinsey. <break time="1.0s" />  
Because enterprises usually spend a lot of money on ads and marketing, automation there can lead to huge savings. <break time="0.5s" />  
On average, 11% of a company’s budget is spent on marketing. <break time="1.0s" />  
Regardless of whether AI will replace software engineers, AI can certainly make them more productive. <break time="0.5s" />  
This means that companies can now accomplish more with fewer engineers. <break time="0.5s" />  
AI can also disrupt the outsourcing industry, as outsourced tasks tend to be simpler ones outside of a company’s core business. <break time="1.0s" />  

<break time="1.5s" />  
B. Image and Video Production <break time="0.5s" />  
Thanks to its probabilistic nature, AI is great for creative tasks. <break time="0.5s" />  
Some of the most successful AI startups are creative applications, such as Midjourney for image generation, Adobe Firefly for photo editing, and Runway, Pika Labs, and Sora for video generation. <break time="0.5s" />  
In late 2023, at one and a half years old, Midjourney had already generated $200 million in annual recurring revenue. <break time="0.5s" />  
As of December 2023, among the top free apps for Graphics & Design on the Apple App Store, half have AI in their names. <break time="0.5s" />  
I suspect that soon, graphics and design apps will incorporate AI by default, and they’ll no longer need the word AI in their names. <break time="1.0s" />  
Chapter 2 discusses the probabilistic nature of AI in more detail. <break time="1.0s" />  
It’s now common to use AI to generate profile pictures for social media, from LinkedIn to TikTok. <break time="0.5s" />  
Many candidates believe that AI‑generated headshots can help them put their best foot forward and increase their chances of landing a job. <break time="1.0s" />  
The perception of AI‑generated profile pictures has changed significantly. <break time="0.5s" />  
In 2019, Facebook banned accounts using AI‑generated profile photos for safety reasons. <break time="0.5s" />  
In 2023, many social media apps provide tools that let users use AI to generate profile photos. <break time="1.0s" />  

<break time="1.5s" />  
C. Writing <break time="0.5s" />  
AI has long been used to aid writing. <break time="0.5s" />  
If you use a smartphone, you’re probably familiar with autocorrect and auto‑completion, both powered by AI. <break time="0.5s" />  
Writing is an ideal application for AI because we do it a lot, it can be quite tedious, and we have a high tolerance for mistakes. <break time="0.5s" />  
If a model suggests something that you don’t like, you can just ignore it. <break time="0.5s" />  
I have found AI very helpful in the process of writing this book, and I can see that AI will be able to automate many parts of the writing process. <break time="0.5s" />  
When writing fiction, I often ask AI to brainstorm ideas on what it thinks will happen next or how a character might react to a situation. <break time="0.5s" />  
I’m still evaluating what kind of writing can be automated and what kind of writing can’t be. <break time="1.0s" />  
It’s not a surprise that LLMs are good at writing, given that they are trained for text completion. <break time="0.5s" />  
To study the impact of ChatGPT on writing, an MIT study (Noy and Zhang, 2023) assigned occupation‑specific writing tasks to 453 college‑educated professionals and randomly exposed half of them to ChatGPT. <break time="0.5s" />  
Their results show that among those exposed to ChatGPT, the average time taken decreased by 40% and output quality rose by 18%. <break time="0.5s" />  
ChatGPT helps close the gap in output quality between workers, which means that it’s more helpful to those with less inclination for writing. <break time="0.5s" />  
Workers exposed to ChatGPT during the experiment were 2 times as likely to report using it in their real job two weeks after the experiment and 1.6 times as likely two months after that. <break time="1.0s" />  
For consumers, the use cases are obvious. <break time="0.5s" />  
Many use AI to help them communicate better. <break time="0.5s" />  
You can be angry in an email and ask AI to make it pleasant. <break time="0.5s" />  
You can give it bullet points and get back complete paragraphs. <break time="0.5s" />  
Several people claimed they no longer send an important email without asking AI to improve it first. <break time="1.0s" />  

<break time="1.5s" />  
D. Education <break time="0.5s" />  
Whenever ChatGPT is down, OpenAI’s Discord server is flooded with students complaining about being unable to complete their homework. <break time="0.5s" />  
Several education boards, including the New York City Public Schools and the Los Angeles Unified School District, were quick to ban ChatGPT for fear of students using it for cheating, but reversed their decisions just a few months later. <break time="1.0s" />  
Instead of banning AI, schools could incorporate it to help students learn faster. <break time="0.5s" />  
AI can summarize textbooks and generate personalized lecture plans for each student. <break time="0.5s" />  
I find it strange that ads are personalized because we know everyone is different, but education is not. <break time="0.5s" />  
AI can help adapt the materials to the format best suited for each student. <break time="0.5s" />  
Auditory learners can ask AI to read the materials out loud. <break time="0.5s" />  
Students who love animals can use AI to adapt visualizations to feature more animals. <break time="0.5s" />  
Those who find it easier to read code than math equations can ask AI to translate math equations into code. <break time="1.0s" />  
AI is especially helpful for language learning, as you can ask AI to roleplay different practice scenarios. <break time="0.5s" />  
Pajak and Bicknell (Duolingo, 2022) found that out of four stages of course creation, lesson personalization is the stage that can benefit the most from AI, as shown in Figure‑10. <break time="1.0s" />  
Figure‑10. AI can be used throughout all four stages of course creation at Duolingo, but it’s the most helpful in the personalization stage. Image from Pajak and Bicknell (Duolingo, 2022). <break time="1.0s" />  
AI can generate quizzes, both multiple‑choice and open‑ended, and evaluate the answers. <break time="0.5s" />  
AI can become a debate partner as it’s much better at presenting different views on the same topic than the average human. <break time="0.5s" />  
For example, Khan Academy offers AI‑powered teaching assistants to students and course assistants to teachers. <break time="0.5s" />  
An innovative teaching method I’ve seen is that teachers assign AI‑generated essays for students to find and correct mistakes. <break time="1.0s" />  
While many education companies embrace AI to build better products, many find their lunches taken by AI. <break time="0.5s" />  
For example, Chegg, a company that helps students with their homework, saw its share price plummet from $28 when ChatGPT launched in November 2022 to $2 in September 2024, as students have been turning to AI for help. <break time="1.0s" />  

<break time="1.5s" />  
E. Conversational Bots <break time="0.5s" />  
Conversational bots are versatile. <break time="0.5s" />  
They can help us find information, explain concepts, and brainstorm ideas. <break time="0.5s" />  
AI can be your companion and therapist. <break time="0.5s" />  
It can emulate personalities, letting you talk to a digital copy of anyone you like. <break time="0.5s" />  
Digital girlfriends and boyfriends have become weirdly popular in an incredibly short amount of time. <break time="1.0s" />  
Many are already spending more time talking to bots than to humans. <break time="0.5s" />  
Some are worried that AI will ruin dating. <break time="1.0s" />  
In research, people have also found that they can use a group of conversational bots to simulate a society, enabling them to conduct studies on social dynamics (Park et al., 2023). <break time="1.0s" />  
For enterprises, the most popular bots are customer support bots. <break time="0.5s" />  
They can help companies save costs while improving customer experience because they can respond to users sooner than human agents. <break time="0.5s" />  
AI can also be product copilots that guide customers through painful and confusing tasks such as filing insurance claims, doing taxes, or looking up corporate policies. <break time="1.0s" />  

<break time="1.5s" />  
F. Information Aggregation <break time="0.5s" />  
Many people believe that our success depends on our ability to filter and digest useful information. <break time="0.5s" />  
However, keeping up with emails, Slack messages, and news can sometimes be overwhelming. <break time="0.5s" />  
Luckily, AI came to the rescue. <break time="0.5s" />  
AI has proven to be capable of aggregating information and summarizing it. <break time="0.5s" />  
According to Salesforce’s Generative AI Snapshot Research, 74% of generative AI users use it to distill complex ideas and summarize information. <break time="1.0s" />  
I currently have over 40,000 photos and videos in my Google Photos. <break time="0.5s" />  
Without AI, it’d be near impossible for me to search for the photos I want, when I want them. <break time="1.0s" />  
For consumers, many applications can process your documents—contracts, disclosures, papers—and let you retrieve information in a conversational manner. <break time="0.5s" />  
This use case is also called talk‑to‑your‑docs. <break time="0.5s" />  
AI can help you summarize websites, research, and create reports on the topics of your choice. <break time="0.5s" />  
During the process of writing this book, I found AI helpful for summarizing and comparing papers. <break time="1.0s" />  
Information aggregation and distillation are essential for enterprise operations. <break time="0.5s" />  
More efficient information aggregation and dissimilation can help an organization become leaner, as it reduces the burden on middle management. <break time="1.0s" />  
When Instacart launched an internal prompt marketplace, it discovered that one of the most popular prompt templates is “Fast Breakdown.” <break time="0.5s" />  
This template asks AI to summarize meeting notes, emails, and Slack conversations with facts, open questions, and action items. <break time="0.5s" />  
These action items can then be automatically inserted into a project tracking tool and assigned to the right owners. <break time="1.0s" />  
AI can help you surface the critical information about your potential customers and run analyses on your competitors. <break time="0.5s" />  
The more information you gather, the more important it is to organize it. <break time="1.0s" />  

<break time="1.5s" />  
G. Data Organization <break time="0.5s" />  
One thing certain about the future is that we’ll continue producing more and more data. <break time="0.5s" />  
Smartphone users will continue taking photos and videos. <break time="0.5s" />  
Companies will continue to log everything about their products, employees, and customers. <break time="0.5s" />  
Billions of contracts are being created each year. <break time="0.5s" />  
Photos, videos, logs, and PDFs are all unstructured or semistructured data. <break time="0.5s" />  
It’s essential to organize all this data in a way that can be searched later. <break time="1.0s" />  
AI can help with exactly that. <break time="0.5s" />  
AI can automatically generate text descriptions about images and videos, or help match text queries with visuals that match those queries. <break time="1.0s" />  
Services like Google Photos are already using AI to surface images that match search queries. <break time="0.5s" />  
Google Image Search goes a step further: if there’s no existing image matching users’ needs, it can generate some. <break time="1.0s" />  
Personally, I also find AI good at explaining data and graphs. <break time="0.5s" />  
When encountering a confusing graph with too much information, I ask ChatGPT to break it down for me. <break time="1.0s" />  
AI is very good with data analysis. <break time="0.5s" />  
It can write programs to generate data visualization, identify outliers, and make predictions like revenue forecasts. <break time="0.5s" />  
Enterprises can use AI to extract structured information from unstructured data, which can be used to organize data and help search it. <break time="0.5s" />  
Simple use cases include automatically extracting information from credit cards, driver’s licenses, receipts, tickets, contact information from email footers, and so on. <break time="0.5s" />  
More complex use cases include extracting data from contracts, reports, charts, and more. <break time="1.0s" />  
It’s estimated that the IDP (intelligent data processing) industry will reach $12.81 billion by 2030, growing 32.9% each year.  

<break time="1.5s" />  
H. Workflow Automation <break time="0.5s" />  
Ultimately, AI should automate as much as possible. <break time="0.5s" />  
For end users, automation can help with boring daily tasks like booking restaurants, requesting refunds, planning trips, and filling out forms. <break time="0.5s" />  
For enterprises, AI can automate repetitive tasks such as lead management, invoicing, reimbursements, managing customer requests, data entry, and so on. <break time="0.5s" />  
One especially exciting use case is using AI models to synthesize data, which can then be used to improve the models themselves. <break time="0.5s" />  
You can use AI to create labels for your data—looping in humans to improve the labels. <break time="0.5s" />  
We discuss data synthesis in Chapter 8. <break time="0.5s" />  
Access to external tools is required to accomplish many tasks. <break time="0.5s" />  
To book a restaurant, an application might need permission to open a search engine to look up the restaurant’s number, use your phone to make calls, and add appointments to your calendar. <break time="1.0s" />  
AIs that can plan and use tools are called agents. <break time="0.5s" />  
The level of interest around agents borders on obsession, but it’s not entirely unwarranted. <break time="0.5s" />  
AI agents have the potential to make every person vastly more productive and generate vastly more economic value. <break time="1.0s" />  
Agents are a central topic in Chapter 6. <break time="1.0s" />  
It’s been a lot of fun looking into different AI applications. <break time="0.5s" />  
One of my favorite things to daydream about is the different applications I can build. <break time="0.5s" />  
However, not all applications should be built. <break time="0.5s" />  
The next section discusses what we should consider before building an AI application.  

<break time="1.5s" />  
────────────────────────────────────────  
VIII. Planning AI Applications <break time="1.0s" />  
──────────────────────────────────────── <break time="1.0s" />  
Given the seemingly limitless potential of AI, it’s tempting to jump into building applications. <break time="0.5s" />  
If you just want to learn and have fun, jump right in. <break time="0.5s" />  
Building is one of the best ways to learn. <break time="0.5s" />  
In the early days of foundation models, several heads of AI startups, however, might have to prioritize product focus and can’t afford to have even one person look around. <break time="1.0s" />  
I was told that they encouraged their teams to experiment with AI applications to upskill themselves. <break time="1.0s" />  
However, if you’re doing this for a living, it might be worthwhile to take a step back and consider why you’re building this and how you should go about it. <break time="0.5s" />  
It’s easy to build a cool demo with foundation models. <break time="0.5s" />  
It’s hard to create a profitable product. <break time="1.0s" />  

A. Use Case Evaluation <break time="0.5s" />  
The first question to ask is why you want to build this application. <break time="0.5s" />  
Like many business decisions, building an AI application is often a response to risks and opportunities. <break time="0.5s" />  
Here are a few examples of different levels of risks, ordered from high to low: <break time="1.0s" />  
 1. If you don’t do this, competitors with AI can make you obsolete. <break time="0.5s" />  
If AI poses a major existential threat to your business, incorporating AI must have the highest priority. <break time="0.5s" />  
In the 2023 Gartner study, 7% cited business continuity as their reason for embracing AI. <break time="0.5s" />  
This is more common for businesses involving document processing and information aggregation, such as financial analysis, insurance, and data processing, as well as for creative work such as advertising, web design, and image production. <break time="1.0s" />  
 2. If you don’t do this, you’ll miss opportunities to boost profits and productivity. <break time="0.5s" />  
Most companies embrace AI for the opportunities it brings. <break time="0.5s" />  
AI can help in most, if not all, business operations. <break time="0.5s" />  
AI can make user acquisition cheaper by crafting more effective copywrites, product descriptions, and promotional visual content. <break time="0.5s" />  
AI can increase user retention by improving customer support and customizing user experience. <break time="0.5s" />  
AI can also help with sales lead generation, internal communication, market research, and competitor tracking. <break time="1.0s" />  
 3. You’re unsure where AI will fit into your business yet, but you don’t want to be left behind. <break time="0.5s" />  
While a company shouldn’t chase every hype train, many have failed by waiting too long to take the leap (cue Kodak, Blockbuster, and BlackBerry). <break time="1.0s" />  
Investing resources into understanding how a new, transformational technology can impact your business isn’t a bad idea if you can afford it. <break time="0.5s" />  
At bigger companies, this can be part of the R&D department. <break time="1.0s" />  
Once you’ve found a good reason to develop this use case, you might consider whether you have to build it yourself. <break time="0.5s" />  
If AI poses an existential threat to your business, you might want to do AI in‑house instead of outsourcing it to a competitor. <break time="0.5s" />  
However, if you’re using AI to boost profits and productivity, you might have plenty of buy options that can save you time and money while giving you better performance. <break time="1.0s" />  

B. The Role of AI and Humans in the Application <break time="0.5s" />  
What role AI plays in the AI product influences the application’s development and its requirements. <break time="0.5s" />  
Apple has a great document explaining different ways AI can be used in a product. <break time="0.5s" />  
Here are three key points relevant to the current discussion: <break time="1.0s" />  
 – Critical or complementary: <break time="0.5s" />  
If an app can still work without AI, AI is complementary to the app. <break time="0.5s" />  
For example, Face ID wouldn’t work without AI‑powered facial recognition, whereas Gmail would still work without Smart Compose. <break time="0.5s" />  
  • The more critical AI is to the application, the more accurate and reliable the AI part has to be. <break time="1.0s" />  
 – Reactive or proactive: <break time="0.5s" />  
A reactive feature shows its responses in reaction to users’ requests or specific actions, whereas a proactive feature shows its responses when there’s an opportunity for it. <break time="0.5s" />  
For example, a chatbot is reactive, whereas traffic alerts on Google Maps are proactive. <break time="0.5s" />  
  • Because reactive features are generated in response to events, they usually, but not always, need to happen fast. <break time="0.5s" />  
On the other hand, proactive features can be precomputed and shown opportunistically, so latency is less important. <break time="0.5s" />  
  • Because users don’t ask for proactive features, they can view them as intrusive or annoying if the quality is low. <break time="0.5s" />  
Therefore, proactive predictions and generations typically have a higher quality bar. <break time="1.0s" />  
 – Dynamic or static: <break time="0.5s" />  
Dynamic features are updated continually with user feedback, whereas static features are updated periodically. <break time="0.5s" />  
For example, Face ID needs to be updated as people’s faces change over time. <break time="0.5s" />  
However, object detection in Google Photos is likely updated only when Google Photos is upgraded. <break time="1.0s" />  
In the case of AI, dynamic features might mean that each user has their own model, continually finetuned on their data, or other mechanisms for personalization such as ChatGPT’s memory feature, which allows ChatGPT to remember each user’s preferences. <break time="0.5s" />  
However, static features might have one model for a group of users updated only when the shared model is updated. <break time="1.0s" />  
It’s also important to clarify the role of humans in the application. <break time="0.5s" />  
Will AI provide background support to humans, make decisions directly, or both? <break time="0.5s" />  
For example, for a customer support chatbot, AI responses can be used in different ways: <break time="0.5s" />  
  • AI shows several responses that human agents can reference to write faster responses. <break time="0.5s" />  
  • AI responds only to simple requests and routes more complex requests to humans. <break time="0.5s" />  
  • AI responds to all requests directly, without human involvement. <break time="1.0s" />  
Involving humans in AI’s decision‑making processes is called human‑in‑the‑loop. <break time="1.0s" />  

C. AI Product Defensibility <break time="0.5s" />  
If you’re selling AI applications as standalone products, it’s important to consider their defensibility. <break time="0.5s" />  
The low entry barrier is both a blessing and a curse. <break time="0.5s" />  
If something is easy for you to build, it’s also easy for your competitors. <break time="0.5s" />  
What moats do you have to defend your product? <break time="0.5s" />  
In a way, building applications on top of foundation models means providing a layer on top of these models. <break time="0.5s" />  
This also means that if the underlying models expand in capabilities, the layer you provide might be subsumed by the models, rendering your application obsolete. <break time="0.5s" />  
Imagine building a PDF‑parsing application on top of ChatGPT based on the assumption that ChatGPT can’t parse PDFs well or can’t do so at scale. <break time="0.5s" />  
Your ability to compete will weaken if this assumption is no longer true. <break time="0.5s" />  
However, even in this case, a PDF‑parsing application might still make sense if it’s built on top of open source models, gearing your solution toward users who want to host models in‑house. <break time="1.0s" />  
One general partner at a major VC firm told me that she’s seen many startups whose entire products could’ve been a feature for Google Docs or Microsoft Office. <break time="0.5s" />  
If their products take off, what would stop Google or Microsoft from allocating three engineers to replicate these products in two weeks? <break time="1.0s" />  
In AI, there are generally three types of competitive advantages: technology, data, and distribution—the ability to bring your product in front of users. <break time="0.5s" />  
With foundation models, the core technologies of most companies will be similar. <break time="0.5s" />  
The distribution advantage likely belongs to big companies. <break time="0.5s" />  
The data advantage is more nuanced. <break time="0.5s" />  
Big companies likely have more existing data. <break time="0.5s" />  
However, if a startup can get to market first and gather sufficient usage data to continue improving their products, data will be their moat. <break time="0.5s" />  
Even for the scenarios where user data can’t be used to train models directly, usage information can give invaluable insights into user behaviors and product shortcomings, which can be used to guide the data collection and training process. <break time="1.0s" />  
There have been many successful companies whose original products could’ve been features of larger products. <break time="0.5s" />  
Calendly could’ve been a feature of Google Calendar. <break time="0.5s" />  
Mailchimp could’ve been a feature of Gmail. <break time="0.5s" />  
Photoroom could’ve been a feature of Google Photos. <break time="1.0s" />  
Many startups eventually overtake bigger competitors, starting by building a feature that these bigger competitors overlooked. <break time="0.5s" />  
Perhaps yours can be the next one. <break time="1.0s" />  

D. Setting Expectations and Milestone Planning <break time="0.5s" />  
Once you’ve decided that you need to build this amazing AI application by yourself, the next step is to figure out what success looks like: how will you measure success? <break time="0.5s" />  
The most important metric is how this will impact your business. <break time="0.5s" />  
For example, if it’s a customer support chatbot, the business metrics can include the following: <break time="0.5s" />  
 • What percentage of customer messages do you want the chatbot to automate? <break time="0.5s" />  
 • How many more messages should the chatbot allow you to process? <break time="0.5s" />  
 • How much quicker can you respond using the chatbot? <break time="0.5s" />  
 • How much human labor can the chatbot save you? <break time="1.0s" />  
A chatbot can answer more messages, but that doesn’t mean it’ll make users happy, so it’s important to track customer satisfaction and customer feedback in general. <break time="0.5s" />  
User Feedback on page 474 discusses how to design a feedback system. <break time="1.0s" />  
To ensure a product isn’t put in front of customers before it’s ready, have clear expectations on its usefulness threshold: how good it has to be for it to be useful. <break time="0.5s" />  
Usefulness thresholds might include the following metric groups: <break time="0.5s" />  
 – Quality metrics to measure the quality of the chatbot’s responses. <break time="0.5s" />  
 – Latency metrics including TTFT (time to first token), TPOT (time per output token), and total latency. <break time="0.5s" />  
 – Cost metrics: how much it costs per inference request. <break time="0.5s" />  
 – Other metrics such as interpretability and fairness. <break time="1.0s" />  
If you’re not yet sure what metrics you want to use, don’t worry. <break time="0.5s" />  
The rest of the book will cover many of these metrics. <break time="0.5s" />  
Once you’ve set measurable goals, you need a plan to achieve these goals. <break time="0.5s" />  
How to get to the goals depends on where you start. <break time="0.5s" />  
Evaluate existing models to understand their capabilities. <break time="0.5s" />  
The stronger the off‑the‑shelf models, the less work you’ll have to do. <break time="0.5s" />  
For example, if your goal is to automate 60% of customer support tickets and the off‑the‑shelf model you want to use can already automate 30% of the tickets, the effort you need to put in might be less than if it can automate no tickets at all. <break time="1.0s" />  
It’s likely that your goals will change after evaluation. <break time="0.5s" />  
For example, after evaluation, you may realize that the resources needed to get the app to the usefulness threshold will be more than its potential return, and, therefore, you no longer want to pursue it. <break time="1.0s" />  

────────────────────────────────────────  
IX. The AI Engineering Stack <break time="1.0s" />  
──────────────────────────────────────── <break time="1.0s" />  
AI engineering’s rapid growth also induced an incredible amount of hype and FOMO (fear of missing out). <break time="0.5s" />  
The number of new tools, techniques, models, and applications introduced every day can be overwhelming. <break time="0.5s" />  
Instead of trying to keep up with the constantly shifting sand, let’s look into the fundamental building blocks of AI engineering. <break time="0.5s" />  
To understand AI engineering, it’s important to recognize that AI engineering evolved out of ML engineering. <break time="0.5s" />  
When a company starts experimenting with foundation models, it’s natural that its existing ML team should lead the effort. <break time="0.5s" />  
Some companies treat AI engineering the same as ML engineering, as shown in Figure‑12. <break time="1.0s" />  
Figure‑12. Many companies put AI engineering and ML engineering under the same umbrella, as shown in the job headlines on LinkedIn from December 17, 2023. <break time="1.0s" />  
Some companies have separate job descriptions for AI engineering, as shown in Figure‑13. <break time="1.0s" />  
Regardless of where organizations position AI engineers and ML engineers, their roles have significant overlap. <break time="0.5s" />  
Existing ML engineers can add AI engineering to their lists of skills to expand their job prospects. <break time="0.5s" />  
However, there are also AI engineers with no previous ML experience. <break time="1.0s" />  
To best understand AI engineering and how it differs from traditional ML engineering, the following section breaks down different layers of the AI application building process and looks at the role each layer plays in AI engineering and ML engineering. <break time="1.0s" />  

A. Three Layers of the AI Stack <break time="0.5s" />  
There are three layers to any AI application stack: application development, model development, and infrastructure. <break time="0.5s" />  
When developing an AI application, you’ll likely start from the top layer and move down as needed: <break time="0.5s" />  
 1. Application development: With models readily available, anyone can use them to develop applications. <break time="0.5s" />  
This is the layer that has seen the most action in the last two years, and it is still rapidly evolving. <break time="0.5s" />  
Application development involves providing a model with good prompts and necessary context. <break time="0.5s" />  
This layer requires rigorous evaluation. <break time="0.5s" />  
Good applications also demand good interfaces. <break time="1.0s" />  
 2. Model development: This layer provides tooling for developing models, including frameworks for modeling, training, finetuning, and inference optimization. <break time="0.5s" />  
Because data is central to model development, this layer also contains dataset engineering. <break time="0.5s" />  
Model development also requires rigorous evaluation. <break time="1.0s" />  
 3. Infrastructure: At the bottom of the stack is infrastructure, which includes tooling for model serving, managing data and compute, and monitoring. <break time="1.0s" />  
Figure‑14 shows these three layers of the AI engineering stack with examples of responsibilities for each layer. <break time="0.5s" />  
Figure‑14. Three layers of the AI engineering stack. <break time="1.0s" />  
To get a sense of how the landscape has evolved with foundation models, in March 2024, I searched GitHub for all AI‑related repositories with at least 500 stars. <break time="0.5s" />  
Given the prevalence of GitHub, I believe this data is a good proxy for understanding the ecosystem. <break time="0.5s" />  
In my analysis, I also included repositories for applications and models, which are the products of the application development and model development layers, respectively. <break time="0.5s" />  
I found a total of 920 repositories. <break time="0.5s" />  
Figure‑15 shows the cumulative number of repositories in each category month‑over‑month. <break time="1.0s" />  
Figure‑15. Cumulative count of repositories by category over time. <break time="1.0s" />  
The data shows a big jump in the number of AI toolings in 2023, after the introduction of Stable Diffusion and ChatGPT. <break time="0.5s" />  
In 2023, the categories that saw the highest increases were applications and application development. <break time="0.5s" />  
The infrastructure layers saw some growth, but it was much less than the growth seen in other layers. <break time="0.5s" />  
This is expected. <break time="0.5s" />  
Even though models and applications have changed, the core infrastructural needs—resource management, serving, monitoring, etc.—remain the same. <break time="1.0s" />  
While the level of excitement and creativity around foundation models is unprecedented, many principles of building AI applications remain the same. <break time="0.5s" />  
For enterprise use cases, AI applications still need to solve business problems, and, therefore, it’s still essential to map from business metrics to ML metrics and vice versa. <break time="0.5s" />  
You still need to do systematic experimentation. <break time="0.5s" />  
With classical ML engineering, you experiment with different hyperparameters. <break time="0.5s" />  
With foundation models, you experiment with different models, prompts, retrieval algorithms, sampling variables, and more. <break time="0.5s" />  
(Sampling variables are discussed in Chapter 2.) <break time="0.5s" />  
We still want to make models run faster and cheaper. <break time="0.5s" />  
It’s still important to set up a feedback loop so that we can iteratively improve our applications with production data. <break time="1.0s" />  

────────────────────────────────────────  
X. AI Engineering Versus ML Engineering <break time="1.0s" />  
──────────────────────────────────────── <break time="1.0s" />  
While the unchanging principles of deploying AI applications are reassuring, it’s also important to understand how things have changed. <break time="0.5s" />  
This is helpful for teams that want to adapt their existing platforms for new AI use cases and developers who are interested in which skills to learn to stay competitive in a new market. <break time="1.0s" />  
At a high level, building applications using foundation models today differs from traditional ML engineering in three major ways: <break time="0.5s" />  
 1. Without foundation models, you have to train your own models for your applications. <break time="0.5s" />  
With AI engineering, you use a model someone else has trained for you. <break time="0.5s" />  
This means that AI engineering focuses less on modeling and training, and more on model adaptation. <break time="1.0s" />  
 2. AI engineering works with models that are bigger, consume more compute resources, and incur higher latency than traditional ML engineering. <break time="0.5s" />  
This means that there’s more pressure for efficient training and inference optimization. <break time="0.5s" />  
A corollary of compute‑intensive models is that many companies now need more GPUs and work with bigger compute clusters than they previously did. <break time="0.5s" />  
This means there’s more need for engineers who know how to work with GPUs and big clusters. <break time="1.0s" />  
 3. AI engineering works with models that can produce open‑ended outputs. <break time="0.5s" />  
Open‑ended outputs give models the flexibility to be used for more tasks, but they are also harder to evaluate. <break time="0.5s" />  
This makes evaluation a much bigger problem in AI engineering. <break time="1.0s" />  
In short, AI engineering differs from ML engineering in that it’s less about model development and more about adapting and evaluating models. <break time="0.5s" />  
I’ve mentioned model adaptation several times in this chapter, so before we move on, I want to make sure that we’re on the same page about what model adaptation means. <break time="0.5s" />  
In general, model adaptation techniques can be divided into two categories, depending on whether they require updating model weights. <break time="1.0s" />  
 • Prompt‑based techniques, which include prompt engineering, adapt a model without updating the model weights. <break time="0.5s" />  
You adapt a model by giving it instructions and context instead of changing the model itself. <break time="0.5s" />  
Prompt engineering is easier to get started and requires less data. <break time="0.5s" />  
Many successful applications have been built with just prompt engineering. <break time="0.5s" />  
Its ease of use allows you to experiment with more models, which increases your chance of finding a model that is unexpectedly good for your applications. <break time="1.0s" />  
 • Finetuning, on the other hand, requires updating model weights. <break time="0.5s" />  
You adapt a model by making changes to the model itself. <break time="0.5s" />  
In general, finetuning techniques are more complicated and require more data, but they can improve your model’s quality, latency, and cost significantly. <break time="0.5s" />  
Many things aren’t possible without changing model weights, such as adapting the model to a new task it wasn’t exposed to during training. <break time="1.0s" />  
Now, let’s zoom into the application development and model development layers to see how each has changed with AI engineering, starting with what existing ML engineers are more familiar with. <break time="0.5s" />  
This section gives an overview of different processes involved in developing an AI application. <break time="0.5s" />  
How these processes work will be discussed throughout this book. <break time="1.0s" />  

────────────────────────────────────────  
XI. Model Development <break time="1.0s" />  
──────────────────────────────────────── <break time="1.0s" />  
Model development is the layer most commonly associated with traditional ML engineering. <break time="0.5s" />  
It has three main responsibilities: <break time="0.5s" />  
 • Modeling and training, <break time="0.5s" />  
 • Dataset engineering, and <break time="0.5s" />  
 • Inference optimization. <break time="1.0s" />  
Evaluation is also required, but because most people will come across it first in the application development layer, I’ll discuss evaluation in the next section. <break time="1.0s" />  

A. Modeling and Training <break time="0.5s" />  
Modeling and training refers to the process of coming up with a model architecture, training it, and finetuning it. <break time="0.5s" />  
Examples of tools in this category are Google’s TensorFlow, Hugging Face’s Transformers, and Meta’s PyTorch. <break time="1.0s" />  
Developing ML models requires specialized ML knowledge. <break time="0.5s" />  
It requires knowing different types of ML algorithms (such as clustering, logistic regression, decision trees, and collaborative filtering) and neural network architectures (such as feedforward, recurrent, convolutional, and transformer). <break time="0.5s" />  
It also requires understanding how a model learns, including concepts such as gradient descent, loss function, regularization, etc. <break time="1.0s" />  
With the availability of foundation models, ML knowledge is no longer a must‑have for building AI applications. <break time="0.5s" />  
I’ve met many wonderful and successful AI application builders who aren’t at all interested in learning about gradient descent. <break time="0.5s" />  
However, ML knowledge is still extremely valuable, as it expands the set of tools that you can use and helps troubleshooting when a model doesn’t work as expected. <break time="1.0s" />  

On the Differences Among Training, Pre‑Training, Finetuning, and Post‑Training <break time="0.5s" />  
Training always involves changing model weights, but not all changes to model weights constitute training. <break time="0.5s" />  
For example, quantization, the process of reducing the precision of model weights, technically changes the model’s weight values but isn’t considered training. <break time="1.0s" />  
The term “training” can often be used in place of pre‑training, finetuning, and post‑training, which refer to different training phases: <break time="1.0s" />  

 • Pre‑training: <break time="0.5s" />  
  Pre‑training refers to training a model from scratch—the model weights are randomly initialized. <break time="0.5s" />  
For LLMs, pre‑training often involves training a model for text completion. <break time="0.5s" />  
Out of all training steps, pre‑training is often the most resource‑intensive by a long shot. <break time="0.5s" />  
For the InstructGPT model, pre‑training takes up to 98% of the overall compute and data resources. <break time="0.5s" />  
Pre‑training also takes a long time to do. <break time="0.5s" />  
A small mistake during pre‑training can incur a significant financial loss and set back the project significantly. <break time="0.5s" />  
Due to the resource‑intensive nature of pre‑training, this has become an art that only a few practice. <break time="0.5s" />  
Those with expertise in pre‑training large models, however, are heavily sought after. <break time="1.0s" />  

 • Finetuning: <break time="0.5s" />  
  Finetuning means continuing to train a previously trained model—the model weights are obtained from the previous training process. <break time="0.5s" />  
Because the model already has certain knowledge from pre‑training, finetuning typically requires fewer resources (e.g., data and compute) than pre‑training. <break time="1.0s" />  

 • Post‑training: <break time="0.5s" />  
  Many people use “post‑training” to refer to the process of training a model after the pre‑training phase. <break time="0.5s" />  
Conceptually, post‑training and finetuning are the same and can be used interchangeably. <break time="0.5s" />  
However, sometimes, people might use them differently to signify the different goals. <break time="0.5s" />  
It’s usually “post‑training” when it’s done by model developers. <break time="0.5s" />  
For example, OpenAI might post‑train a model to make it better at following instructions before releasing it. <break time="0.5s" />  
It’s “finetuning” when it’s done by application developers. <break time="0.5s" />  
For example, you might finetune an OpenAI model (which might have been post‑trained itself) to adapt it to your needs. <break time="1.0s" />  
Pre‑training and post‑training make up a spectrum. <break time="0.5s" />  
Their processes and toolings are very similar. <break time="0.5s" />  
Their differences are explored further in Chapters 2 and 7. <break time="1.0s" />  
Some people use the term “training” to refer to prompt engineering, which isn’t correct. <break time="0.5s" />  
I read a Business Insider article where the author said she trained ChatGPT to mimic her younger self. <break time="0.5s" />  
She did so by feeding her childhood journal entries into ChatGPT. <break time="0.5s" />  
Colloquially, the author’s usage of the word “training” is correct, as she’s teaching the model to do something. <break time="0.5s" />  
But technically, if you teach a model what to do via the context input into the model, you’re doing prompt engineering. <break time="0.5s" />  
Similarly, I’ve seen people using the term “finetuning” when what they do is prompt engineering.  

<break time="1.5s" />  
B. Dataset Engineering <break time="0.5s" />  
Dataset engineering refers to curating, generating, and annotating the data needed for training and adapting AI models. <break time="0.5s" />  
In traditional ML engineering, most use cases are close‑ended—a model’s output can only be among predefined values. <break time="0.5s" />  
For example, spam classification with only two possible outputs (“spam” and “not spam”) is close‑ended. <break time="0.5s" />  
Foundation models, however, are open‑ended. <break time="0.5s" />  
Annotating open‑ended queries is much harder than annotating close‑ended queries—it’s easier to determine whether an email is spam than to write an essay. <break time="0.5s" />  
So data annotation is a much bigger challenge for AI engineering. <break time="0.5s" />  
Another difference is that traditional ML engineering works more with tabular data, whereas foundation models work with unstructured data. <break time="0.5s" />  
In AI engineering, data manipulation is more about deduplication, tokenization, context retrieval, and quality control, including removing sensitive information and toxic data. <break time="1.0s" />  
Dataset engineering is the focus of Chapter 8. <break time="1.0s" />  

C. Inference Optimization <break time="0.5s" />  
Inference optimization means making models faster and cheaper. <break time="0.5s" />  
Inference optimization has always been important for ML engineering. <break time="0.5s" />  
Users never say no to faster models, and companies can always benefit from cheaper inference. <break time="0.5s" />  
However, as foundation models scale up to incur even higher inference cost and latency, inference optimization has become even more important. <break time="0.5s" />  
One challenge with foundation models is that they are often autoregressive—tokens are generated sequentially. <break time="0.5s" />  
If it takes 10 ms for a model to generate a token, it’ll take a second to generate an output of 100 tokens, and even more for longer outputs. <break time="0.5s" />  
As users are getting notoriously impatient, getting AI applications’ latency down to the ms latency expected for a typical internet application is a huge challenge. <break time="0.5s" />  
Inference optimization has become an active subfield in both industry and academia. <break time="1.0s" />  
A summary of how the importance of different categories of model development change with AI engineering is shown in Table‑4. <break time="1.0s" />  
Table‑4. How different responsibilities of model development have changed with foundation models. <break time="0.5s" />  
 Category       Building with traditional ML      Building with foundation models <break time="0.5s" />  
 Modeling and training  ML knowledge is required for training a model from scratch  ML knowledge is a nice‑to‑have, not a must‑have <break time="0.5s" />  
 Dataset engineering  More about feature engineering, especially with tabular data  Less about feature engineering and more about data deduplication, tokenization, context retrieval, and quality control <break time="0.5s" />  
 Inference optimization  Important  Even more important  

<break time="1.5s" />  
────────────────────────────────────────  
XII. Application Development <break time="1.0s" />  
──────────────────────────────────────── <break time="1.0s" />  
With traditional ML engineering, where teams build applications using their proprietary models, the model quality is a differentiation. <break time="0.5s" />  
With foundation models, where many teams use the same model, differentiation must be gained through the application development process. <break time="0.5s" />  
The application development layer consists of these responsibilities: <break time="0.5s" />  
 • Evaluation, <break time="0.5s" />  
 • Prompt engineering, and <break time="0.5s" />  
 • AI interface. <break time="1.0s" />  

A. Evaluation <break time="0.5s" />  
Evaluation is about mitigating risks and uncovering opportunities. <break time="0.5s" />  
Evaluation is necessary throughout the whole model adaptation process. <break time="0.5s" />  
It is needed to select models, benchmark progress, determine whether an application is ready for deployment, and detect issues and opportunities for improvement in production. <break time="0.5s" />  
While evaluation has always been important in ML engineering, it’s even more important with foundation models, for many reasons. <break time="0.5s" />  
The challenges of evaluating foundation models are discussed in Chapter 3. <break time="0.5s" />  
In summary, these challenges chiefly arise from foundation models’ open‑ended nature and expanded capabilities. <break time="1.0s" />  
For example, in close‑ended ML tasks like fraud detection, there are usually expected ground truths that you can compare your model’s outputs against. <break time="0.5s" />  
If a model’s output differs from the expected output, you know the model is wrong. <break time="0.5s" />  
For a task like chatbots, however, there are so many possible responses to each prompt that it is impossible to curate an exhaustive list of ground truths to compare a model’s response to. <break time="1.0s" />  

B. Prompt Engineering and Context Construction <break time="0.5s" />  
Prompt engineering is about getting AI models to express the desirable behaviors from the input alone, without changing the model weights. <break time="0.5s" />  
The Gemini evaluation story highlights the impact of prompt engineering on model performance. <break time="0.5s" />  
By using a different prompt engineering technique, Gemini Ultra’s performance on MMLU went from 83.7% to 90.04%. <break time="0.5s" />  
It’s possible to get a model to do amazing things with just prompts. <break time="0.5s" />  
The right instructions can get a model to perform the task you want, in the format of your choice. <break time="1.0s" />  

C. AI Interface <break time="0.5s" />  
AI interface means creating an interface for end users to interact with your AI applications. <break time="0.5s" />  
Before foundation models, only organizations with sufficient resources to develop AI models could develop AI applications. <break time="0.5s" />  
These applications were often embedded into the organization’s existing products. <break time="0.5s" />  
For example, fraud detection was embedded into Stripe, Venmo, and PayPal. <break time="0.5s" />  
Recommender systems were part of social networks and media apps like Netflix, TikTok, and Spotify. <break time="0.5s" />  
With foundation models, anyone can build AI applications. <break time="0.5s" />  
You can serve your AI applications as standalone products or embed them into other products, including products developed by other people. <break time="0.5s" />  
For example, ChatGPT and Perplexity are standalone products, whereas GitHub’s Copilot is commonly used as a plug‑in in VSCode, and Grammarly is commonly used as a browser extension for Google Docs. <break time="0.5s" />  
Midjourney can either be used via its standalone web app or via its integration in Discord. <break time="1.0s" />  
Streamlit, Gradio, and Plotly Dash are common tools for building AI web apps. <break time="0.5s" />  
Anton Bacaj told me that AI engineering is just software engineering with AI models thrown in the stack. <break time="1.0s" />  
There need to be tools that provide interfaces for standalone AI applications or make it easy to integrate AI into existing products. <break time="0.5s" />  
Here are just some of the interfaces that are gaining popularity for AI applications: <break time="0.5s" />  
 • Standalone web, desktop, and mobile apps. <break time="0.5s" />  
 • Browser extensions that let users quickly query AI models while browsing. <break time="0.5s" />  
 • Chatbots integrated into chat apps like Slack, Discord, WeChat, and WhatsApp. <break time="0.5s" />  
 • Many products, including VSCode, Shopify, and Microsoft 365, provide APIs that let developers integrate AI into their products as plug‑ins and add‑ons. <break time="0.5s" />  
These APIs can also be used by AI agents to interact with the world, as discussed in Chapter 6. <break time="1.0s" />  
While the chat interface is the most commonly used, AI interfaces can also be voice‑based (such as with voice assistants) or embodied (such as in augmented and virtual reality). <break time="0.5s" />  
These new AI interfaces also mean new ways to collect and extract user feedback. <break time="0.5s" />  
The conversation interface makes it so much easier for users to give feedback in natural language, but this feedback is harder to extract. <break time="0.5s" />  
User feedback design is discussed in Chapter 10. <break time="1.0s" />  
A summary of how the importance of different categories in app development changes with AI engineering is shown in Table‑6. <break time="1.0s" />  
Table‑6. The importance of different categories in app development for AI engineering and ML engineering. <break time="0.5s" />  
 Category       Building with traditional ML      Building with foundation models <break time="0.5s" />  
 AI interface     Less important      Important <break time="0.5s" />  
 Prompt engineering   Not applicable     Important <break time="0.5s" />  
 Evaluation      More important <break time="1.0s" />  

D. AI Engineering Versus Full‑Stack Engineering <break time="0.5s" />  
The increased emphasis on application development, especially on interfaces, brings AI engineering closer to full‑stack development. <break time="0.5s" />  
The rising importance of interfaces leads to a shift in the design of AI toolings to attract more frontend engineers. <break time="0.5s" />  
Traditionally, ML engineering is Python‑centric. <break time="0.5s" />  
Before foundation models, the most popular ML frameworks supported mostly Python APIs. <break time="0.5s" />  
Today, Python is still popular, but there is also increasing support for JavaScript APIs, with LangChain.js, Transformers.js, OpenAI’s Node library, and Vercel’s AI SDK. <break time="0.5s" />  
While many AI engineers come from traditional ML backgrounds, more are increasingly coming from web development or full‑stack backgrounds. <break time="0.5s" />  
An advantage that full‑stack engineers have over traditional ML engineers is their ability to quickly turn ideas into demos, get feedback, and iterate. <break time="1.0s" />  
With traditional ML engineering, you usually start with gathering data and training a model. <break time="0.5s" />  
Building the product comes last. <break time="0.5s" />  
However, with AI models readily available today, it’s possible to start with building the product first, and only invest in data and models once the product shows promise, as visualized in Figure‑16. <break time="1.0s" />  
Figure‑16. The new AI engineering workflow rewards those who can iterate fast. <break time="0.5s" />  
Image recreated from “The Rise of the AI Engineer” (Shawn Wang, 2023). <break time="1.0s" />  
In traditional ML engineering, model development and product development are often disjointed processes, with ML engineers rarely involved in product decisions at many organizations. <break time="0.5s" />  
However, with foundation models, AI engineers tend to be much more involved in building the product. <break time="1.0s" />  

────────────────────────────────────────  
XIII. Summary <break time="1.0s" />  
──────────────────────────────────────── <break time="1.0s" />  
I meant this chapter to serve two purposes. <break time="0.5s" />  
One is to explain the emergence of AI engineering as a discipline, thanks to the availability of foundation models. <break time="0.5s" />  
Two is to give an overview of the process needed to build applications on top of these models. <break time="0.5s" />  
I hope that this chapter achieved this goal. <break time="0.5s" />  
As an overview chapter, it only lightly touched on many concepts. <break time="0.5s" />  
These concepts will be explored further in the rest of the book. <break time="1.0s" />  
The chapter discussed the rapid evolution of AI in recent years. <break time="0.5s" />  
It walked through some of the most notable transformations, starting with the transition from language models to large language models, thanks to a training approach called self‑supervision. <break time="0.5s" />  
It then traced how language models incorporated other data modalities to become foundation models, and how foundation models gave rise to AI engineering. <break time="1.0s" />  
The rapid growth of AI engineering is motivated by the many applications enabled by the emerging capabilities of foundation models. <break time="0.5s" />  
This chapter discussed some of the most successful application patterns, both for consumers and enterprises. <break time="0.5s" />  
Despite the incredible number of AI applications already in production, we’re still in the early stages of AI engineering, with countless more innovations yet to be built. <break time="1.0s" />  
Before building an application, an important yet often overlooked question is whether you should build it. <break time="0.5s" />  
This chapter discussed this question together with major considerations for building AI applications. <break time="1.0s" />  
While AI engineering is a new term, it evolved out of ML engineering, which is the overarching discipline involved with building applications with all ML models. <break time="0.5s" />  
Many principles from ML engineering are still applicable to AI engineering. <break time="0.5s" />  
However, AI engineering also brings with it new challenges and solutions. <break time="0.5s" />  
The last section of the chapter discusses the AI engineering stack, including how it has changed from ML engineering. <break time="1.0s" />  
One aspect of AI engineering that is especially challenging to capture in writing is the incredible amount of collective energy, creativity, and engineering talent that the community brings. <break time="0.5s" />  
This collective enthusiasm can often be overwhelming, as it’s impossible to keep up‑to‑date with new techniques, discoveries, and engineering feats that seem to happen constantly. <break time="1.0s" />  
One consolation is that since AI is great at information aggregation, it can help us aggregate and summarize all these new updates. <break time="0.5s" />  
But tools can help only to a certain extent. <break time="0.5s" />  
The more overwhelming a space is, the more important it is to have a framework to help us navigate it. <break time="0.5s" />  
This book aims to provide such a framework. <break time="1.0s" />  
The rest of the book will explore this framework step‑by‑step, starting with the fundamental building block of AI engineering: the foundation models that make so many amazing applications possible. <break time="1.0s" />  
Chapter 1: Introduction to Building AI Applications with Foundation Models