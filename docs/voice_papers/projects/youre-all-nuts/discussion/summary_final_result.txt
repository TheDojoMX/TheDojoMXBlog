¿Alguna vez te has encontrado con esa sensación de ver un paisaje tan surrealista y vibrante que pareciera sacado de un sueño psicodélico? Imagínate que, justo en medio de la techosfera, ves una imagen como “A psychedelic landscape” de Annie Ruygt, y ahí te das cuenta de que algo realmente raro está pasando en el mundo del desarrollo de software. Yo estaba hablando con unos amigos, esos que no se conforman con lo convencional y que siempre tienen una opinión fuerte sobre la inteligencia artificial. Y fue en esa conversación, entre risas y anécdotas, donde surgió la frase: “Mis amigos escépticos de la IA son todos unos locos”. Parece exagerado, ¿verdad? Pero la verdad es que, en el presente, mientras ejecutivos tecnológicos insisten en implantar modelos de lenguaje a gran escala (LLMs) como si fueran el futuro ineludible, parece que algunos aún se empeñan en ver la IA como una moda pasajera —una especie de manía similar a la fiebre de los NFT.

Ahora bien, ¿cómo es posible que en este mundo del código, donde desde los 90 se ha vivido de compilar, refactorizar y pulir líneas de C, C++ y Python, unos visionarios se lancen a explorar los límites de la generación automática de código? Te voy a contar una historia: imagina a un programador que comenzó con un código empaquetado y sellado, evolucionando poco a poco con la influencia de mentes como Alexandrescu, y que pasó por Ruby y Rust. Este mismo programador comenzó a ver, hace apenas dos años —con la llegada de herramientas como Copilot— que usar un LLM para escribir código se estaba transformando en algo muy distinto de lo que era considerado “trabajo serio” hasta hace poco. Hace tan solo seis meses, la manera en que algunos codificadores se aprovechaban de esta asistencia automática resultaba casi irreconocible en comparación a lo que hoy practican.

Pero, ¿y sabes qué es lo más interesante? Resulta que hay ejemplos tan concretos que te hacen replantear todo lo que conocíamos acerca de la programación. Tomemos, por ejemplo, el caso de un usuario que asignó 13 tareas a un LLM: tres Pull Requests (PRs) que fueron descartadas y reintentadas, cinco con retroalimentación del tipo “esto parece trabajo de un desarrollador junior”, y finalmente otras cinco que se integraron sin mayores problemas. Es como si el LLM se comportara de forma meticulosa, intentando, equivocándose y luego arreglando el rumbo. Algo similar a cuando colaboras con un colega que, aunque a veces se “despista” o tiene ideas poco pulidas, sabe volver a encaminarse si se le apunta el error. ¡Y todo esto ocurre en cuestión de segundos! Mientras tanto, un interno puede costar unos $20 al mes, y esa oferta supera incluso a herramientas especializadas como Cursor.ai. La diferencia se siente casi como comparar una bicicleta con un coche de carreras.

Ahora, vamos a sumergirnos un poco más en el meollo de la cuestión. Muchos de ustedes probablemente han experimentado la frustración de tener que buscar en Google mil soluciones para un problema de codificación que consume horas de tu tiempo. Pero imagina un agente programado, que no solo explora el código de forma autónoma, sino que además escribe archivos, ejecuta compilaciones y hasta realiza pruebas. Todo esto gracias a la magia de los LLMs. Y no estamos hablando de un ente incapaz de cansarse; estos modelos realizan búsquedas internas de información sin sufrir los temidos efectos de la fatiga. En términos simples, lo que sucede es que el agente se comporta casi como un makefile viviente: coordina una cadena de herramientas (o toolchain) que interactúa con Git, utiliza linters, formatea y compila, y si algo falla, reitera el proceso con retroalimentación automatizada.

Pero espera, hay más. En mi opinión, lo más interesante es cómo estas herramientas han evolucionado hasta poder realizar tareas en paralelo. Imagina alimentar 40 transcripciones de log y, en cuestión de segundos, detectar problemas de corrupción de metadatos en un LVM. Es como tener un equipo de detectives digitales que trabajan sin descanso, sin cometer esos errores humanos que a veces nos hacen perder la cabeza. Esa capacidad, que antes hubiera requerido una larga cadena de razonamientos y búsquedas, ahora se resuelve con simples interacciones de LLM y agentes inteligentes, abriendo la puerta a una productividad sin precedentes.

Claro, no podemos olvidar que, pese a todas estas mejoras y ventilaciones de procesos automatizados, cada desarrollador sigue siendo el responsable final del código que se integra en la rama principal. Es decir, el juicio humano sigue siendo indispensable. Así como en una buena receta, donde la tecnología te ayuda con las medidas exactas y el tiempo preciso de cocción, pero al final, el chef debe probar, ajustar y decidir el resultado final, nuestras herramientas de IA tienen su “cadena de pensamiento” (el famoso chain of thought log) que, aunque a veces muestra errores o “alucinaciones”, es útil para entender el proceso interno del agente. ¿Te ha pasado que, al final del día, revisas y corriges algo que parecía perfecto a primera vista? Pues aquí no es diferente, y es justamente esa colaboración entre hombre y máquina la que marca la diferencia.

Algunos expertos han criticado que “los LLMs no pueden programar”, señalando casos en los que estos modelos no logran capturar la complejidad de lenguajes como Rust. Y es cierto que, según se comenta, los desarrolladores de este lenguaje deberían esforzarse en mejorar la compatibilidad de sus herramientas con las nuevas técnicas de generación automatizada. Pero lo realmente provocativo es otra: estamos en el umbral de un cambio donde los LLMs no solo pueden escribir código tedioso, sino que, en el futuro cercano, se espera que la mayor parte del código Bash —y quizás hasta otras partes del código de sistema— sea generado por estas inteligencias artificiales. Es un cambio de paradigma, donde lo que antes era trabajo repetitivo y monótono, se transforma en una tarea en la que la creatividad, el juicio y la supervisión humana se vuelven los protagonistas.

Y aquí es donde se conecta con el lado práctico. Imagina a un equipo trabajando con un agente como el que muestran en Zed, que te notifica al finalizar una tarea sin necesidad de que estés pegado a la pantalla todo el tiempo. Eso no solo libera tiempo, sino que permite que te concentres en tareas que realmente requieren tu expertise, dejando que la IA se encargue de lo que ya se ha vuelto rutinario. A este punto, no es exagerado decir que quienes no adopten este cambio podrían quedarse rezagados en una carrera en la que el combustible ya es “rocket fuel”. Esa presión de la competencia hace que la integración de estos agentes inteligentes no sea una opción, sino una necesidad para seguir siendo relevante en el campo.

Detrás de toda esta automatización se esconde un entramado técnico impresionante. Los agentes de coding operan utilizando una cadena de herramientas que se entrelazan de manera muy sofisticada. Exploración del código, escritura de archivos, ejecución de pruebas, todo se fortalece mediante procesos de construcción, linting y evaluaciones que determinan el rendimiento final del agente. En esencia, su éxito depende más de cómo se organizan estos procesos que de la sofisticación por sí sola de las herramientas. Esto quiere decir que, en manos expertas, es posible construir un agente de codificación efectivo en un fin de semana, siempre y cuando se tenga muy claro cómo montar esta cadena de responsabilidades.

Pero, ¿qué pasa con estos fragmentos de código que a veces parecen provenir de repositorios públicos de GitHub? Al generar salidas, es inevitable que aparezcan fragmentos que han sido previamente escritos por otros. Este fenómeno plantea una cuestión intrigante sobre la propiedad intelectual y el respeto hacia lo que, en cierto modo, consideramos patrimonio colectivo. Los desarrolladores han mostrado históricamente una actitud un tanto indiferente hacia la propiedad intelectual en el ámbito del software; sin embargo, esta tendencia, en el contexto de la generación automatizada, se vuelve tema de debate en serio.

De otro lado, hay quienes sostienen que la “hype cycle” de la IA, alimentada tanto por inversores libertarios como por una nueva ola de entusiastas, podría estar generando un exceso de expectativas. Es decir, aunque el funcionamiento subyacente de la tecnología no cambia drásticamente, el entorno de inversión y la presión mediática lo convierten en un espectáculo que a veces estira la realidad. Y aun si todo este entusiasmo se desinfla repentinamente, el impacto que tiene en la carrera del desarrollo de software ya es innegable. En mi opinión, la segunda gran contribución de esta revolución, después de su impacto en los smartphones o el internet, se centra en precisamente esta transformación: desde automatizar el código tedioso hasta elevar el “piso” mínimo de calidad que se exige en los proyectos.

Entonces, ¿qué significa esto para ti, que quizás eres programador, estudiante o simplemente alguien curioso por las nuevas tecnologías? Significa que la integración de LLMs y agentes programáticos está abriendo la puerta a una nueva forma de trabajar que, en lugar de reemplazar el trabajo humano, lo complementa. Esto implica que el rol del desarrollador se transforma: ya no solo se trata de escribir cada línea de código a mano, sino de curar, orientar y dirigir la generación automatizada. Seguimos siendo responsables de lo que se integra en “main”, y esa responsabilidad es lo que mantiene el estándar de calidad y la dirección del proyecto.

Para terminar, déjame dejarte con una imagen mental: imagina un taller de ebanistería japonesa, donde la técnica del “sashimono joinery” era la que garantizaba que cada pieza encajara a la perfección sin usar clavos. Así, en el mundo de la programación, los desarrolladores serios actúan como esos maestros ebanistas, asegurándose de que, pese a la ayuda descomunal de los LLMs, cada componente del código esté cuidadosamente revisado, validado y, sobre todo, tenga un propósito claro. Las máquinas pueden generar mucho, pero ellas no tienen la intuición, la experiencia y, sobre todo, la responsabilidad humana de garantizar que el “producto final” sea algo en lo que realmente se pueda confiar.

En resumen, la revolución que trae la programación asistida por IA no es un simple truco moderno, sino una transformación en la forma de abordar los problemas del código cotidiano. Y aunque algunos de mis amigos escépticos sigan dudando, yo creo que este cambio —que combina conocimientos empíricos de décadas con las nuevas capacidades automatizadas— es, sin duda, un paso emocionante hacia un futuro donde la tecnología y el ingenio humano se reafirman en conjunto. 

Así que, la próxima vez que te encuentres con un error de compilación o una línea tediosa que te saca canas, recuerda: tal vez ya hay un agente asistido por IA dispuesto a hacer ese trabajo, dejándote a ti el placer de explorar nuevas ideas, innovar y, sobre todo, seguir creando. Porque, al final del día, lo que realmente importa es aprender a trabajar en equipo con estas herramientas, permitiendo que cada uno aporte lo mejor de sí en este taller digital.

Y doy por concluida esta charla con la convicción de que, en el mundo del desarrollo, el futuro se construye día a día entre líneas de código, procesos automatizados y, por sobre todo, el inapelable juicio humano que sigue siendo el alma de cada proyecto. ¡Muchas gracias por acompañarme en este viaje y nos vemos en la siguiente aventura digital!