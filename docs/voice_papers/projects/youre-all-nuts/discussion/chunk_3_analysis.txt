Section: Section 3
Characters: 200
==================================================
• Título: “My AI Skeptic Friends Are All Nuts.”  
• Imagen incluida: “A psychedelic landscape.”  
  – URL: “/blog/youre-all-nuts/assets/whoah.png”  
• Crédito de imagen: Annie Ruygt (enlace: https://annieruygtillustration.com/)  
• Declaración: Se trata de una provocación sincera sobre la programación asistida por IA.  
• Hecho: Ejecutivos tecnológicos están ordenando la adopción de modelos de lenguaje a gran escala (LLMs).  
• Afirmación: Algunos de los programadores y expertos de primera línea creen que la IA es una moda pasajera, comparable a la “manía” de los NFT.  
• Afirmación: Personas talentosas están realizando tareas que los LLMs ya hacen de forma superior, motivadas por deseos no constructivos.  
• Afirmación: Todo el progreso en los LLMs podría detenerse en cualquier momento y, aun así, los LLMs serían la segunda cosa más importante que ha ocurrido en la carrera del autor.  
• Especificación: El análisis se centra exclusivamente en las implicaciones de los LLMs para el desarrollo de software (no para el arte, la música o la escritura).  
• Datos biográficos del autor:  
  – Publica software desde mediados de los años 90.  
  – Comenzó trabajando con código en C empaquetado y sellado.  
  – Pasó por una fase de C++ influenciada por Alexandrescu.  
  – Ha trabajado con herramientas en Ruby y Python.  
  – Ha realizado trabajo a nivel de kernel.  
  – Ha desarrollado en C (servidor), Go y Rust.  
• Nota temporal: “O, Dios no lo quiera, hace 2 años con Copilot.”  
• Comparación temporal: Hace 6 meses, usar un LLM para código sin agentes no es lo mismo que lo que hacen los codificadores serios hoy en día.  
• Funciones de un agente en programación asistida por LLMs:  
  – Explorar el código de forma autónoma.  
  – Escribir archivos directamente.  
  – Ejecutar herramientas.  
  – Compilar código, ejecutar pruebas y realizar iteraciones basadas en los resultados.  
  – Incorporar código arbitrario de la estructura de archivos local o de otras fuentes en línea en su “ventana de contexto.”  
  – Utilizar herramientas Unix estándar para navegar por el árbol de archivos y extraer información.  
  – Interactuar con Git.  
  – Usar herramientas existentes (linters, formateadores y comprobadores de modelos).  
  – Realizar llamadas arbitrarias a herramientas configuradas a través de MCP.  
• Declaración técnica: El código que ejecuta los agentes para “hacer cosas” es código de sistemas sencillo, comparable en su dependencia a un Makefile.  
• Afirmación: Es posible escribir un agente de codificación efectivo en un fin de semana.  
• Comparación: El rendimiento del agente depende más de la forma en que se estructuran los procesos de construcción, linting y pruebas, que del nivel de sofisticación de herramientas especializadas (e.g., o3 o Sonnet).  
• Advertencia: Ejecutar solicitudes en una página de ChatGPT y luego copiar el código resultante (posiblemente roto) a un editor no es lo que hacen los usuarios avanzados de LLM.  
• Declaración funcional: Los LLMs pueden escribir una gran fracción del código tedioso en proyectos típicos.  
• Afirmación: La mayoría del código en la mayoría de los proyectos es tedioso.  
• Afirmación: Los LLMs reducen drásticamente la necesidad de buscar soluciones en Google.  
• Hecho: Los LLMs realizan búsquedas internamente.  
• Hecho: Los LLMs no se cansan y no sufren inercia.  
• Ejemplo de uso: Un LLM puede ser instruido para resolver tareas de inicio en proyectos pospuestos, proporcionando de inmediato un punto de entrada para comenzar a ajustar el código.  
• Declaración psicológica: La sensación de mejora inmediata (dopaína) producida al ver el código funcionar es una razón por la que el autor programa.  
• Descripción de un posible inconveniente: Tareas complejas o “sucias”, como refactorizar pruebas unitarias, requieren trabajo que en ocasiones se evita.  
• Ejemplo: Un agente puede pasar horas en una máquina virtual refactorizando pruebas unitarias y luego generar una solicitud de extracción (PR).  
• Afirmación: Cada desarrollador es responsable del código que integra en la rama “main.”  
• Instrucción: Si se construye algo con un LLM en el que dependen otros, se debe leer y revisar el código.  
• Observación: Los LLMs están empezando a adaptarse a la idiosincrasia local, aunque aún no han alcanzado un alto grado de personalización.  
• Aclaración: El código generado por un LLM no es inherentemente “probabilístico”; si se mantienen las salvaguardas, es legible y comprensible.  
• Afirmación: Leer y entender el código de otros es parte del trabajo del desarrollador.  
• Nota: La traza de pensamiento (“chain of thought log”) que genera un agente puede mostrar errores (“alucinaciones”), pero se sugiere no visualizarla.  
• Ejemplo de herramienta: El modo agente de Zed (https://zed.dev/agentic) muestra una notificación de escritorio al finalizar el trabajo en lugar de requerir supervisión constante.  
• Afirmación técnica: Los agentes “lint” (analizan) el código, compilan y ejecutan pruebas; si el LLM crea una firma de función inventada, el error es detectado, se retroalimenta al LLM y este reintenta.  
• Comparación de costos: Costo de un interno – $20/mes – versus el costo de Cursor.ai.  
• Declaración: Uno de los roles del desarrollador senior es hacer que programadores con menor habilidad sean productivos, ya sean humanos o “algebraicos.”  
• Descripción de habilidad: Manejar agentes efectivamente requiere habilidad y constituye un proyecto de ingeniería basado en técnicas de instrucciones (prompts), índices y herramientas.  
• Afirmación: Los LLMs solo generan código de mala calidad si se permiten errores en su uso.  
• Notación: “100% de todo el código Bash que deberías escribir a partir de ahora” será generado por LLMs.  
• Descripción de tareas realizadas por los LLMs: tipeo, búsquedas (“Googling”), generación de casos de prueba y ciclos de edición-compilación-prueba-depuración.  
• Afirmación: Los desarrolladores serios mantienen la responsabilidad de la curación, el juicio, la orientación y la dirección.  
• Comentario: Las primeras versiones de código hechas por humanos no son necesariamente superiores.  
• Ejemplo humorístico: Dificultad de establecer una buena cadena de herramientas (“toolchain”) para el lenguaje Brainfuck.  
• Afirmación: La crítica “LLMs no pueden programar” puede referirse a “LLMs no pueden escribir Rust.”  
• Observación: La elección de lenguajes de programación se basa en parte en qué tan bien funcionan los LLMs con ellos; se sugiere que los desarrolladores de Rust deben mejorar esta compatibilidad.  
• Declaración: El autor trabaja principalmente en Go.  
• Afirmaciones sobre Go:  
  – Los diseñadores de Go no pretendieron crear el lenguaje más legible para LLMs, pero lo lograron en cierta medida.  
  – Go ofrece seguridad en los tipos, una extensa biblioteca estándar y una cultura que valora patrones idiomáticos (a menudo repetitivos).  
  – Los LLMs tienen buen rendimiento generando código en Go.  
• Declaración: El autor también programa en Rust y lo encuentra aceptable; si los LLMs no funcionan bien con Rust para algún usuario, ese problema es distinto.  
• Comparación: Analogía con la ebanistería japonesa, el uso de herramientas manuales y la técnica de “sashimono joinery.”  
• Detalle personal: El autor dispone de un taller básico de carpintería en su sótano.  
• Elección práctica: Aunque el autor podría fabricar una mesa o un banco de trabajo, prefiere comprar una mesa para que se sienten personas en su oficina.  
• Declaración sobre el rol profesional: Los desarrolladores de software profesionales resuelven problemas prácticos mediante código y no actúan como artesanos.  
• Cita implícita: “Steve Jobs estaba equivocado” respecto a la necesidad de perfeccionar detalles estéticos internos (“carve the unseen feet”) en el diseño.  
• Afirmación: La solidez de un producto de software no depende de la belleza del código.  
• Advertencia: Dedicarse en exceso a refinar funciones en expresiones funcionales muy pulidas puede constituir “yak-shaving” (realizar tareas accesorias en lugar del trabajo principal) y usarse para auto tranquilizarse en lugar de construir el producto.  
• Declaración final sobre la función de los LLMs: Eliminan el “trabajo tedioso” (“schlep”) y facilitan que los desarrolladores se enfoquen en tareas donde el juicio y los valores personales son decisivos.  
• Declaración del autor con experiencia de mediana a avanzada carrera: Se valora la mediocridad, pues la mayoría del código escrito es mediocre.  
• Afirmación: No todo el código tiene la misma importancia; dedicar un esfuerzo máximo en, por ejemplo, una prueba unitaria arbitraria, es incorrecto.  
• Instrucción final: El líder del equipo debe corregir cuando se dedique demasiado esfuerzo en partes menos críticas del código.  

(Información adicional sobre el contexto del uso de LLMs en la programación)  
• Consideración sobre la calidad del código: No se requiere que todo el código tenga la misma importancia; es aceptable que parte del código sea mediocre.  
• No es necesario invertir el máximo esfuerzo en pruebas unitarias aleatorias; en esos casos, el líder del equipo debe intervenir.  
• Afirmación: Los LLMs pueden “bajar el techo” de calidad y, al mismo tiempo, “elevar el piso” mínimo de lo producido.  
• Afirmación: Gemini (un LLM) tiene un “piso” de calidad superior al del código del autor; su código personal se describe como visualmente “bonito” pero menos exhaustivo.  
• Afirmación: El código generado por LLM suele ser repetitivo, mientras que el código humano puede incluir “contorsiones” innecesarias al aplicar el principio DRY.  
• Conjunto de “trucos” algorítmicos en LLMs:  
  – Radix tries  
  – Topological sorts  
  – Graph reductions  
  – LDPC codes  
• Mención: El paquete rsync es referido en relación con el artículo de Andrew Tridgell.  
• Afirmación: Aunque el código producido por LLMs pueda ser mediocre, esto reduce la cantidad de código mediocre que deben escribir los humanos.  
• Comentario: La “hype cycle” de AI/VC afecta a los practicantes inteligentes, pero el funcionamiento subyacente permanece inalterado, independientemente de opiniones de figuras como Jensen Huang.  
• Hecho: En el pasado se pagaba “buena plata” por bases de datos; la industria tecnológica se basa en automatizar puestos de trabajo, lo que ha reducido la cantidad de trabajadores en roles tales como:  
  – Agentes de viajes  
  – Corredores de bolsa en planta  
  – Dependientes en tiendas de discos  
  – Técnicos de laboratorio fotográfico (darkroom tech)  
• Términos utilizados por algunos inversionistas libertarios: “lamplighters”, “creative destruction” y “new kinds of work.”  
• Afirmación: Existe la posibilidad de que los LLMs desplacen a numerosos desarrolladores de software.  
• Impacto en las artes visuales:  
  – Los LLMs afectan a artistas que producen ilustraciones y composiciones competentes para portadas de revistas, exhibiciones en museos, motion graphics y activos para videojuegos.  
  – Los LLMs pueden generar facsímiles “suficientes” del trabajo creativo humano, cumpliendo estándares de la industria.  
• Observación: Fragmentos de código de repositorios públicos en GitHub pueden aparecer en salidas generadas, lo que genera preocupación sobre licenciamiento.  
• Afirmación: En general, los desarrolladores muestran poco respeto por la propiedad intelectual, evidenciado por ejemplos como:  
  – La visión del “median dev” de Star Wars y Daft Punk como bienes comunes.  
  – La oposición cultural a medidas que dificulten el funcionamiento de sitios de compartición de medios monetizables.  
  – La existencia y apoyo a redes de piratería a escala global y la burla hacia esfuerzos por preservar ventanas de estreno para series de TV.  
• Mención: Dificultad para hacer streaming de “The Expanse” en LibreWolf (implicación en discusiones sobre IPR).  
• Hecho: Los LLMs procesan y “digieren” el código de manera más profunda que un humano.  
• “Level set” del estado del arte en programación asistida por LLMs:  
  – Las tomas (outputs) de los LLMs evolucionan rápidamente (comparado con la vida útil de un bluefish filet).  
  – Usuarios jóvenes utilizan agentes y agentes asíncronos que realizan múltiples tareas en paralelo.  
  – Ejemplo cuantitativo: Un usuario puede asignar 13 tareas a su LLM, de las cuales:  
   • 3 Pull Requests (PRs) son descartadas y re-promptadas.  
   • 5 reciben retroalimentación similar a la que daría un desarrollador junior.  
   • 5 son finalmente integradas (merged).  
  – Comentario de un colaborador: “está tomando rocket fuel” (implicando que quienes no adopten la IA quedarán rezagados).  
• Hecho: Los LLMs no tienen acceso a entornos de producción (“prod”).  
  – Ejemplo: El autor alimentó 40 transcripciones de log a un agente LLM, y en segundos éste detectó problemas de corrupción de metadatos LVM en un host con problemas persistentes.  
• Declaración política y técnica del autor: Se identifica como “statist” y escribe en Go y Python, descartando actitudes radicales o futuristas.  
• En la front page de Hacker News se encuentra abundante contenido relacionado con LLMs, incluyendo:  
  – Actualizaciones incrementales de modelos.  
  – Startups trabajando con LLMs.  
  – Tutoriales de LLMs.  
  – Críticas extensas contra los LLMs.  
• Comparación: La atención actual hacia la inteligencia artificial es comparable a la que recibieron los smartphones en 2008 y, en menor medida, a la que tuvo Internet en sus inicios.  
• Términos críticos utilizados: “stochastic parrots” y “vibe coding,” con la predicción de que tales críticas no resistirán el contacto con la realidad.  
• Afirmación final: Eventualmente, los agentes de codificación serán mucho más efectivos que lo que son hoy.  
• (Sección breve adicional:)  
  – Texto: “arking about these people, but I meant what I said: they’re smarter than me. And when they get over this affectation, they’re going to make coding agents profoundly more effective than they are today.”  
   • Afirmación: Las personas mencionadas son más inteligentes que el autor.  
   • Predicción: Una vez que superen su “afectación,” harán que los agentes de codificación sean profunda y significativamente más efectivos que en la actualidad.