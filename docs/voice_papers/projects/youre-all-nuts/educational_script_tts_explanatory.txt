¿Alguna vez te has encontrado con esa sensación de ver un paisaje tan surrealista y vibrante que pareciera sacado de un sueño psicodélico?<break time="1.0s"/> Imagínate que, justo en medio de la techosfera, ves una imagen como “A psychedelic landscape” de Annie Ruygt, y ahí te das cuenta de que algo realmente raro está pasando en el mundo del desarrollo de software.<break time="1.0s"/> Yo estaba hablando con unos amigos, esos que no se conforman con lo convencional y que siempre tienen una opinión fuerte sobre la INTELIGENCIA ARTIFICIAL.<break time="1.0s"/> Y fue en esa conversación, entre risas y anécdotas, donde surgió la frase: “Mis amigos escépticos de la IA son todos unos locos”.<break time="1.0s"/> Parece exagerado, ¿verdad?<break time="1.0s"/> Pero la verdad es que, en el presente, mientras ejecutivos tecnológicos insisten en implantar modelos de lenguaje a gran escala (LLMs) como si fueran el futuro ineludible, parece que algunos aún se empeñan en ver la IA como una moda pasajera —una especie de manía similar a la fiebre de los NFT.<break time="1.5s"/>

Ahora bien, ¿cómo es posible que en este mundo del código, donde desde los 90 se ha vivido de compilar, refactorizar y pulir líneas de C, C++ y Python, unos visionarios se lancen a explorar los límites de la generación automática de código?<break time="1.0s"/> Te voy a contar una historia: imagina a un programador que comenzó con un código empaquetado y sellado, evolucionando poco a poco con la influencia de mentes como Alexandrescu, y que pasó por Ruby y Rust.<break time="1.0s"/> Este mismo programador comenzó a ver, hace apenas dos años —con la llegada de herramientas como Copilot— que usar un LLM para escribir código se estaba transformando en algo muy distinto de lo que era considerado “trabajo serio” hasta hace poco.<break time="1.0s"/> Hace tan solo seis meses, la manera en que algunos codificadores se aprovechaban de esta asistencia automática resultaba casi irreconocible en comparación a lo que hoy practican.<break time="1.5s"/>

Pero, ¿y sabes qué es lo más interesante?<break time="1.0s"/> Resulta que hay ejemplos tan concretos que te hacen replantear todo lo que conocíamos acerca de la programación.<break time="1.0s"/> Tomemos, por ejemplo, el caso de un usuario que asignó 13 tareas a un LLM: tres Pull Requests (PRs) que fueron descartadas y reintentadas, cinco con retroalimentación del tipo “esto parece trabajo de un desarrollador junior”, y finalmente otras cinco que se integraron sin mayores problemas.<break time="1.0s"/> Es como si el LLM se comportara de forma meticulosa, intentando, equivocándose y luego arreglando el rumbo.<break time="1.0s"/> Algo similar a cuando colaboras con un colega que, aunque a veces se “despista” o tiene ideas poco pulidas, sabe volver a encaminarse si se le apunta el error.<break time="1.0s"/> ¡Y todo esto ocurre en cuestión de segundos!<break time="1.0s"/> Mientras tanto, un interno puede costar unos $20 al mes, y esa oferta supera incluso a herramientas especializadas como Cursor.ai.<break time="1.0s"/> La diferencia se siente casi como comparar una bicicleta con un coche de carreras.<break time="1.5s"/>

Ahora, vamos a sumergirnos un poco más en el meollo de la cuestión.<break time="1.0s"/> Muchos de ustedes probablemente han experimentado la frustración de tener que buscar en Google mil soluciones para un problema de codificación que consume horas de tu tiempo.<break time="1.0s"/> Pero imagina un agente programado, que no solo explora el código de forma autónoma, sino que además escribe archivos, ejecuta compilaciones y hasta realiza pruebas.<break time="1.0s"/> Todo esto gracias a la magia de los LLMs.<break time="1.0s"/> Y no estamos hablando de un ente incapaz de cansarse; estos modelos realizan búsquedas internas de información sin sufrir los temidos efectos de la fatiga.<break time="1.0s"/> En términos simples, lo que sucede es que el agente se comporta casi como un makefile viviente: coordina una cadena de herramientas (o toolchain) que interactúa con Git, utiliza linters, formatea y compila, y si algo falla, reitera el proceso con retroalimentación automatizada.<break time="1.5s"/>

Pero espera, hay más.<break time="1.0s"/> En mi opinión, lo más interesante es cómo estas herramientas han evolucionado hasta poder realizar tareas en paralelo.<break time="1.0s"/> Imagina alimentar 40 transcripciones de log y, en cuestión de segundos, detectar problemas de corrupción de metadatos en un LVM.<break time="1.0s"/> Es como tener un equipo de detectives digitales que trabajan sin descanso, sin cometer esos errores humanos que a veces nos hacen perder la cabeza.<break time="1.0s"/> Esa capacidad, que antes hubiera requerido una larga cadena de razonamientos y búsquedas, ahora se resuelve con simples interacciones de LLM y agentes inteligentes, abriendo la puerta a una productividad sin precedentes.<break time="1.5s"/>

Claro, no podemos olvidar que, pese a todas estas mejoras y ventilaciones de procesos automatizados, cada desarrollador sigue siendo el responsable final del código que se integra en la rama principal.<break time="1.0s"/> Es decir, el juicio humano sigue siendo indispensable.<break time="1.0s"/> Así como en una buena receta, donde la tecnología te ayuda con las medidas exactas y el tiempo preciso de cocción, pero al final, el chef debe probar, ajustar y decidir el resultado final, nuestras herramientas de IA tienen su “cadena de pensamiento” (el famoso chain of thought log) que, aunque a veces muestra errores o “alucinaciones”, es útil para entender el proceso interno del agente.<break time="1.0s"/> ¿Te ha pasado que, al final del día, revisas y corriges algo que parecía perfecto a primera vista?<break time="1.0s"/> Pues aquí no es diferente, y es justamente esa colaboración entre hombre y máquina la que marca la diferencia.<break time="1.5s"/>

Algunos expertos han criticado que “los LLMs no pueden programar”, señalando casos en los que estos modelos no logran capturar la complejidad de lenguajes como Rust.<break time="1.0s"/> Y es cierto que, según se comenta, los desarrolladores de este lenguaje deberían esforzarse en mejorar la compatibilidad de sus herramientas con las nuevas técnicas de generación automatizada.<break time="1.0s"/> Pero lo realmente provocativo es otra: estamos en el umbral de un cambio donde los LLMs no solo pueden escribir código tedioso, sino que, en el futuro cercano, se espera que la mayor parte del código Bash —y quizás hasta otras partes del código de sistema— sea generado por estas inteligencias artificiales.<break time="1.0s"/> Es un cambio de paradigma, donde lo que antes era trabajo repetitivo y monótono, se transforma en una tarea en la que la creatividad, el juicio y la supervisión humana se vuelven los protagonistas.<break time="1.5s"/>

Y aquí es donde se conecta con el lado práctico.<break time="1.0s"/> Imagina a un equipo trabajando con un agente como el que muestran en Zed, que te notifica al finalizar una tarea sin necesidad de que estés pegado a la pantalla todo el tiempo.<break time="1.0s"/> Eso no solo libera tiempo, sino que permite que te concentres en tareas que realmente requieren tu EXPERTISE, dejando que la IA se encargue de lo que ya se ha vuelto rutinario.<break time="1.0s"/> A este punto, no es exagerado decir que quienes no adopten este cambio podrían quedarse rezagados en una carrera en la que el combustible ya es “ROCKET FUEL”.<break time="1.0s"/> Esa presión de la competencia hace que la integración de estos agentes inteligentes no sea una opción, sino una necesidad para seguir siendo relevante en el campo.<break time="1.5s"/>

Detrás de toda esta automatización se esconde un entramado técnico impresionante.<break time="1.0s"/> Los agentes de coding operan utilizando una cadena de herramientas que se entrelazan de manera muy sofisticada.<break time="1.0s"/> Exploración del código, escritura de archivos, ejecución de pruebas, todo se fortalece mediante procesos de construcción, linting y evaluaciones que determinan el rendimiento final del agente.<break time="1.0s"/> En esencia, su éxito depende más de cómo se organizan estos procesos que de la sofisticación por sí sola de las herramientas.<break time="1.0s"/> Esto quiere decir que, en manos expertas, es posible construir un agente de codificación efectivo en un fin de semana, siempre y cuando se tenga muy claro cómo montar esta cadena de responsabilidades.<break time="1.5s"/>

Pero, ¿qué pasa con estos fragmentos de código que a veces parecen provenir de repositorios públicos de GitHub?<break time="1.0s"/> Al generar salidas, es inevitable que aparezcan fragmentos que han sido previamente escritos por otros.<break time="1.0s"/> Este fenómeno plantea una cuestión intrigante sobre la propiedad intelectual y el respeto hacia lo que, en cierto modo, consideramos patrimonio colectivo.<break time="1.0s"/> Los desarrolladores han mostrado históricamente una actitud un tanto indiferente hacia la propiedad intelectual en el ámbito del software; sin embargo, esta tendencia, en el contexto de la generación automatizada, se vuelve tema de debate en serio.<break time="1.5s"/>

De otro lado, hay quienes sostienen que la “hype cycle” de la IA, alimentada tanto por inversores libertarios como por una nueva ola de entusiastas, podría estar generando un exceso de expectativas.<break time="1.0s"/> Es decir, aunque el funcionamiento subyacente de la tecnología no cambia drásticamente, el entorno de inversión y la presión mediática lo convierten en un espectáculo que a veces estira la realidad.<break time="1.0s"/> Y aun si todo este entusiasmo se desinfla repentinamente, el impacto que tiene en la carrera del desarrollo de software ya es innegable.<break time="1.0s"/> En mi opinión, la segunda gran contribución de esta revolución, después de su impacto en los smartphones o el internet, se centra en precisamente esta transformación: desde automatizar el código tedioso hasta elevar el “piso” mínimo de calidad que se exige en los proyectos.<break time="1.5s"/>

Entonces, ¿qué significa esto para ti, que quizás eres programador, estudiante o simplemente alguien curioso por las nuevas tecnologías?<break time="1.0s"/> Significa que la integración de LLMs y agentes programáticos está abriendo la puerta a una nueva forma de trabajar que, en lugar de reemplazar el trabajo humano, lo complementa.<break time="1.0s"/> Esto implica que el rol del desarrollador se transforma: ya no solo se trata de escribir cada línea de código a mano, sino de curar, orientar y dirigir la generación automatizada.<break time="1.0s"/> Seguimos siendo responsables de lo que se integra en “main”, y esa responsabilidad es lo que mantiene el estándar de calidad y la dirección del proyecto.<break time="1.5s"/>

Para terminar, déjame dejarte con una imagen mental: imagina un taller de ebanistería japonesa, donde la técnica del “sashimono joinery” era la que garantizaba que cada pieza encajara a la perfección sin usar clavos.<break time="1.0s"/> Así, en el mundo de la programación, los desarrolladores serios actúan como esos maestros ebanistas, asegurándose de que, pese a la ayuda descomunal de los LLMs, cada componente del código esté cuidadosamente revisado, validado y, sobre todo, tenga un propósito claro.<break time="1.0s"/> Las máquinas pueden generar mucho, pero ellas no tienen la intuición, la experiencia y, sobre todo, la responsabilidad humana de garantizar que el “producto final” sea algo en lo que realmente se pueda confiar.<break time="1.5s"/>

En resumen, la revolución que trae la programación asistida por IA no es un simple truco moderno, sino una transformación en la forma de abordar los problemas del código cotidiano.<break time="1.0s"/> Y aunque algunos de mis amigos escépticos sigan dudando, yo creo que este cambio —que combina conocimientos empíricos de décadas con las nuevas capacidades automatizadas— es, sin duda, un paso emocionante hacia un futuro donde la tecnología y el ingenio humano se reafirman en conjunto.<break time="1.5s"/>

Así que, la próxima vez que te encuentres con un error de compilación o una línea tediosa que te saca canas, recuerda: tal vez ya hay un agente asistido por IA dispuesto a hacer ese trabajo, dejándote a ti el placer de explorar nuevas ideas, innovar y, sobre todo, seguir creando.<break time="1.0s"/> Porque, al final del día, lo que realmente importa es aprender a trabajar en equipo con estas herramientas, permitiendo que cada uno aporte lo mejor de sí en este taller digital.<break time="1.5s"/>

Y doy por concluida esta charla con la convicción de que, en el mundo del desarrollo, el futuro se construye día a día entre líneas de código, procesos automatizados y, por sobre todo, el inapelable juicio humano que sigue siendo el alma de cada proyecto.<break time="1.0s"/> ¡Muchas gracias por acompañarme en este viaje y nos vemos en la siguiente aventura digital!