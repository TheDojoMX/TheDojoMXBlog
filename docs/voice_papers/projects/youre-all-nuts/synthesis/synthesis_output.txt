My AI Skeptic Friends Are All Nuts

Key facts and data points:
• Imagen incluida: “A psychedelic landscape.”, URL “/blog/youre-all-nuts/assets/whoah.png”.
• Crédito de imagen: Annie Ruygt (enlace: https://annieruygtillustration.com/).
• Ejecutivos tecnológicos están ordenando la adopción de modelos de lenguaje a gran escala (LLMs).
• Nota temporal: “o, Dios no lo quiera, hace 2 años con Copilot.”
• Datos biográficos del autor: publica software desde mediados de los años 90; comenzó con código en C empaquetado y sellado; pasó por C++ influenciado por Alexandrescu; ha trabajado con Ruby, Python, código a nivel de kernel, C (servidor), Go y Rust.
• Comparación temporal: Hace 6 meses, usar un LLM para código sin agentes no es lo mismo que lo que practican codificadores serios hoy.
• Ejemplo cuantitativo en programación asistida por LLMs: un usuario asigna 13 tareas a un LLM (3 PRs descartadas y re-promptadas, 5 con retroalimentación similar a la de un desarrollador junior, 5 finalmente integradas).
• Costo comparativo: un interno a $20/mes versus el costo de Cursor.ai.
• Ejemplo de uso: Alimentación de 40 transcripciones de log a un agente LLM que, en segundos, detectó problemas de corrupción de metadatos LVM.

Conceptos y definiciones:
• Modelos de lenguaje a gran escala (LLMs): algoritmos que generan código, realizan búsquedas internas, y no se fatigan.
• Agentes en programación asistida por LLMs: software que explora código, escribe archivos, ejecuta herramientas, compila, ejecuta pruebas, incorpora código de diversas fuentes en su “ventana de contexto”, utiliza herramientas Unix para navegar por el árbol de archivos, interactúa con Git y usa herramientas existentes (linters, formateadores, comprobadores de modelos) así como llamadas configuradas vía MCP.
• Código “de sistemas” de los agentes: se asemeja a un Makefile en función y dependencia de conceptos básicos de programación.
• “Chain of thought log”: traza de pensamiento generada por un agente, la cual puede mostrar errores (“alucinaciones”).
• “Stochastic parrots” y “vibe coding”: términos críticos utilizados en debates sobre la generación de código por LLMs.
• “Yak-shaving”: dedicarse en exceso a refinar funciones accesorias en detrimento del trabajo principal.
• “Sashimono joinery”: técnica de ebanistería japonesa que se utiliza como analogía en el texto.
• “Toolchain”: cadena de herramientas, ejemplificada con la dificultad para Brainfuck.
• “Lamplighters”, “creative destruction” y “new kinds of work”: términos utilizados por algunos inversionistas libertarios en el contexto de la automatización y cambios en la fuerza laboral.

Statements and claims made:
• Se trata de una provocación sincera sobre la programación asistida por IA.
• Algunos programadores y expertos de primera línea creen que la IA es una moda pasajera, comparable a la “manía” de los NFT.
• Personas talentosas están realizando tareas que los LLMs ya hacen de forma superior, motivadas por deseos no constructivos.
• Todo el progreso en los LLMs podría detenerse en cualquier momento y, aun así, representar la segunda contribución más importante en la carrera del autor.
• Los LLMs pueden escribir gran parte del código tedioso, reduciendo la necesidad de búsquedas en Google.
• Los LLMs realizan búsquedas internamente, no se cansan y no sufren inercia.
• Cada desarrollador es responsable del código integrado en la rama “main”, por lo que debe revisar el código generado.
• La traza de pensamiento “chain of thought log” puede mostrar errores (“alucinaciones”), pero se sugiere no visualizarla.
• Los agentes “lint” el código, compilan, ejecutan pruebas y, en caso de error, el sistema retroalimenta al LLM para reintentar.
• Es posible escribir un agente de codificación efectivo en un fin de semana.
• El rendimiento del agente depende más de la estructura de los procesos de construcción, linting y pruebas que del nivel de sofisticación de herramientas especializadas.
• Los usuarios avanzados de LLM evitan copiar ciegamente el código resultante de una interfaz como ChatGPT sin revisarlo.
• Los desarrolladores serios mantienen la responsabilidad de la curación, el juicio, la orientación y la dirección.
• La crítica “LLMs no pueden programar” puede ser una alusión a que “LLMs no pueden escribir Rust.”
• La elección de lenguajes de programación se basa en parte en qué tan bien funcionan los LLMs con ellos; se sugiere que los desarrolladores de Rust deben mejorar esta compatibilidad.
• Se afirma que “100% de todo el código Bash que deberías escribir a partir de ahora” será generado por LLMs.
• Los LLMs pueden “bajar el techo” de calidad y al mismo tiempo “elevar el piso” mínimo de lo producido.
• Fragmentos de código provenientes de repositorios públicos en GitHub pueden aparecer en salidas generadas, generando preocupación sobre el licenciamiento.
• Los desarrolladores, en general, muestran poco respeto por la propiedad intelectual según ejemplos sobre bienes comunes culturales.
• La “hype cycle” de AI/VC afecta a practicantes inteligentes pero el funcionamiento subyacente no cambia.
• Existe la posibilidad de que los LLMs desplacen a numerosos desarrolladores de software.
• Los LLMs son capaces de generar facsímiles “suficientes” del trabajo creativo humano en el área de las artes visuales.
• Finalmente, se afirma que los agentes de codificación serán, en el futuro, mucho más efectivos que en la actualidad.

Examples and applications:
• Un agente puede resolver tareas de inicio en proyectos pospuestos, proporcionando un punto de entrada inmediato para ajustar el código.
• Un agente puede pasar horas refactorizando pruebas unitarias en una máquina virtual y luego generar una solicitud de extracción (PR).
• El modo agente de Zed (https://zed.dev/agentic) muestra una notificación de escritorio al finalizar el trabajo sin requerir supervisión constante.
• Se menciona la dificultad de establecer una cadena de herramientas para el lenguaje Brainfuck como ejemplo humorístico.
• Los LLMs han sido aplicados para escribir la mayoría del código tedioso en proyectos industriales.
• Usuarios jóvenes utilizan agentes asíncronos que realizan múltiples tareas en paralelo.
• Ejemplo cuantitativo: asignación de 13 tareas a un LLM, con resultados distribuidos en PRs descartadas, retroalimentadas y finalmente integradas.
• Un colaborador expresó que “está tomando rocket fuel”, implicando que quienes no adopten la IA quedarán rezagados.
• Se menciona el paquete rsync junto con el artículo de Andrew Tridgell.
• Ejemplo de streaming de “The Expanse” en LibreWolf y discusiones sobre propiedad intelectual.

Methods and processes:
• Funciones de un agente en programación asistida por LLMs:
  – Explorar el código de forma autónoma.
  – Escribir archivos directamente.
  – Ejecutar herramientas y compilar código.
  – Ejecutar pruebas y realizar iteraciones basadas en los resultados.
  – Incorporar código proveniente de la estructura de archivos local u otras fuentes en línea en una “ventana de contexto”.
  – Utilizar herramientas Unix estándar para navegar y extraer información del árbol de archivos.
  – Interactuar con Git.
  – Usar herramientas existentes (linters, formateadores, comprobadores de modelos).
  – Realizar llamadas arbitrarias a herramientas configuradas a través de MCP.
• El código para “hacer cosas” con el código es similar a un Makefile en dependencia de la verdad básica de la programación.
• La estructura y rendimiento de un agente dependen de la organización de procesos de construcción, linting y pruebas.
• La implementación de agentes implica técnicas de instrucciones (prompts), índices y la integración de herramientas.
• Los LLMs realizan búsquedas internas, tipeo, generación de casos de prueba y ciclos de edición-compilación-prueba-depuración sin fatigarse.
• Los usuarios avanzados revisan y validan el código generado en lugar de copiarlo directamente desde interfaces de ChatGPT.

Results and findings:
• Los LLMs pueden generar una fracción significativa del código tedioso en proyectos típicos.
• La utilización de LLMs reduce drásticamente la necesidad de búsquedas en Google.
• El código que generan los LLMs es legible y comprensible si se mantienen las salvaguardas, negando que sea inherentemente “probabilístico.”
• El uso de agentes en la programación asistida permite una automatización que aumenta la productividad, permitiendo a desarrolladores concentrarse en tareas que requieren juicio.
• La mayoría del código en la mayoría de los proyectos se considera tedioso; por ello, la mediocridad es aceptable en ciertos componentes.
• La experiencia acumulada y la estructura de los procesos de construcción son determinantes en la efectividad de los agentes de codificación.
• Los LLMs han mostrado capacidad para adaptar de forma incipiente a idiosincrasias locales, aunque aún están en proceso de mayor personalización.
• Se ha observado que la atención actual hacia la inteligencia artificial es comparable a la de los smartphones en 2008 y, en menor medida, a los inicios de Internet.
• Se predice que, con el tiempo, los agentes de codificación serán mucho más efectivos, elevando el piso mínimo de calidad en el código producido.