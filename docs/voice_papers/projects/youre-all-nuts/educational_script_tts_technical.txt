Hoy vamos a adentrarnos en el contenido del artículo titulado “My AI Skeptic Friends Are All Nuts.”<break time="1.0s" /> Comenzamos presentando el título y la imagen visual que lo acompaña.<break time="1.0s" /> Se nos muestra una imagen de un paisaje psicodélico, cuya URL es “/blog/youre-all-nuts/assets/whoah.png” y se le acredita a Annie Ruygt, con un enlace de referencia a https://annieruygtillustration.com/.<break time="1.5s" />

Empecemos a explorar los hechos y datos fundamentales.<break time="1.0s" /> Se nos indica que los ejecutivos tecnológicos están impulsando la adopción de modelos de lenguaje a gran escala (LLMs).<break time="1.0s" /> Cabe resaltar una nota temporal que menciona: “o, Dios no lo quiera, hace 2 años con Copilot.”<break time="1.0s" /> Además, se ofrecen datos biográficos del autor, quien ha publicado software desde mediados de los años 90.<break time="1.0s" /> Inicialmente, comenzó trabajando con código en C empaquetado y sellado, transitando luego por una fase de C++ influenciada por Alexandrescu, y posteriormente ha trabajado con Ruby y Python.<break time="1.0s" /> También ha realizado trabajo a nivel de kernel, y ha desarrollado en C (en el entorno del servidor), Go y Rust.<break time="1.0s" /> Se hace una comparación temporal interesante: hace 6 meses, usar un LLM para código sin agentes no se asemeja a lo que hoy practican los codificadores serios.<break time="1.5s" />

En este mismo contexto, se presenta un ejemplo cuantitativo en la programación asistida por LLMs.<break time="1.0s" /> Por ejemplo, se describe el caso de un usuario que asigna 13 tareas a un LLM, donde 3 Pull Requests (PRs) son descartadas y re-promptadas, 5 reciben retroalimentación similar a la de un desarrollador junior, y, finalmente, 5 son integradas (merged).<break time="1.0s" /> También se hace una comparación de costos, contrastando el costo de un interno a $20/mes con el costo de Cursor.ai, y se menciona otro caso en el que se alimentaron 40 transcripciones de log a un agente LLM que en cuestión de segundos detectó problemas de corrupción de metadatos LVM.<break time="1.5s" />

Pasando a los conceptos y definiciones, se aclara que los modelos de lenguaje a gran escala (LLMs) son algoritmos diseñados para generar código, realizar búsquedas internas y lo hacen sin fatigarse.<break time="1.0s" /> Relacionado con esto, se introduce el concepto de “agentes en programación asistida por LLMs.”<break time="1.0s" /> Se trata de software que explora el código de forma autónoma, escribe archivos directamente, ejecuta herramientas, compila código, ejecuta pruebas y realiza iteraciones basadas en los resultados.<break time="1.0s" /> Estos agentes pueden incorporar código arbitrario proveniente de la estructura de archivos local o de otras fuentes en línea en su “ventana de contexto.”<break time="1.0s" /> Además, utilizan herramientas Unix estándar para navegar por el árbol de archivos y extraer información, interactúan con Git, y usan herramientas existentes tales como linters, formateadores y comprobadores de modelos.<break time="1.0s" /> Se menciona además que estos agentes realizan llamadas a herramientas configuradas a través de MCP.<break time="1.0s" /> El código “de sistemas” de los agentes se asemeja a un Makefile, basándose en funciones y dependencias de conceptos básicos de programación.<break time="1.0s" /> Se introduce también el término “chain of thought log,” que se refiere a la traza de pensamiento generada por un agente y que puede mostrar errores o “alucinaciones.”<break time="1.0s" /> Entre los términos críticos en este debate se encuentran “stochastic parrots” y “vibe coding.”<break time="1.0s" /> Asimismo, se menciona el concepto de “yak-shaving,” que se refiere a dedicarse en exceso a refinar funciones accesorias en detrimento del trabajo principal, y se hace referencia a “sashimono joinery,” una técnica de ebanistería japonesa utilizada como analogía.<break time="1.0s" /> Se introduce además la noción de “toolchain,” ejemplificada con la dificultad para Brainfuck, y se destacan términos de algunos inversionistas libertarios, tales como “lamplighters,” “creative destruction” y “new kinds of work.”<break time="1.5s" />

Ahora abordemos las declaraciones y afirmaciones.<break time="1.0s" /> Se trata de una provocación sincera en torno a la programación asistida por IA.<break time="1.0s" /> Algunos programadores y expertos de primera línea creen que la IA es solo una moda pasajera, comparable a la “manía” de los NFT.<break time="1.0s" /> Se resalta que personas talentosas están realizando tareas que hoy en día los LLMs realizan de forma superior, motivados en ocasiones por deseos no constructivos.<break time="1.0s" /> Se declara también que, aun cuando el progreso en los LLMs pueda detenerse en cualquier momento, esto representará la segunda contribución más importante en la carrera del autor.<break time="1.0s" /> Es importante notar que los LLMs pueden escribir gran parte del código tedioso, lo que reduce la necesidad de realizar búsquedas en Google.<break time="1.0s" /> A diferencia de los humanos, estos modelos realizan búsquedas internamente, no se cansan y no sufren de inercia.<break time="1.0s" /> Cada desarrollador sigue siendo responsable del código integrado en la rama “main”, debiendo revisar manualmente el código generado.<break time="1.0s" /> Además, se niega la afirmación de que el código generado por un LLM sea inherentemente “probabilístico,” argumentando que, con las salvaguardas adecuadas, dicho código es legible y comprensible.<break time="1.0s" /> En este sentido, se recalca que leer y entender el código de otros es parte fundamental del trabajo del desarrollador.<break time="1.5s" />

Se menciona que, si bien la traza de pensamiento (“chain of thought log”) puede mostrar errores o “alucinaciones”, se sugiere evitar visualizarla.<break time="1.0s" /> También se explica que los agentes “lint” analizan el código, compilándolo, ejecutando pruebas y, en caso de error, si el LLM inventa una firma de función, el error es detectado, retroalimentado al LLM y este procede a reintentar la tarea.<break time="1.0s" /> Se argumenta, además, que es posible escribir un agente de codificación efectivo en un fin de semana, y se subraya que el rendimiento del agente depende más de la estructura de los procesos de construcción, linting y pruebas que del nivel de sofisticación de las herramientas especializadas.<break time="1.0s" /> Se advierte que los usuarios avanzados evitan copiar directamente el código resultante de interfaces, como ChatGPT, sin una debida revisión, haciendo hincapié en que los desarrolladores serios mantienen la responsabilidad de la curación, el juicio, la orientación y la dirección.<break time="1.0s" /> Se comenta la crítica de que “LLMs no pueden programar”, lo cual puede ser una alusión a que “LLMs no pueden escribir Rust.”<break time="1.0s" /> De igual manera, se argumenta que la elección de lenguajes de programación se basa, en parte, en qué tan bien funcionan los LLMs con ellos, sugiriendo que los desarrolladores de Rust deben trabajar para mejorar esta compatibilidad.<break time="1.0s" /> De forma contundente, se declara que “100% de todo el código Bash que deberías escribir a partir de ahora” será generado por LLMs.<break time="1.0s" /> Se señala que los LLMs son capaces de “bajar el techo” de calidad y, simultáneamente, “elevar el piso” mínimo de lo producido.<break time="1.0s" /> También se menciona un tema relevante sobre fragmentos de código provenientes de repositorios públicos en GitHub que pueden aparecer en salidas generadas, lo cual genera preocupación sobre el licenciamiento.<break time="1.0s" /> En general, se afirma que los desarrolladores muestran poco respeto por la propiedad intelectual, apoyándose en ejemplos de bienes comunes culturales.<break time="1.0s" /> Se destaca que la “hype cycle” de AI/VC afecta a practicantes inteligentes, aunque el funcionamiento subyacente no cambia, y se contempla la posibilidad de que los LLMs desplacen a numerosos desarrolladores de software.<break time="1.0s" /> Además, se reconoce que los LLMs tienen la capacidad de generar facsímiles “suficientes” del trabajo creativo humano en diversas áreas, tales como ilustraciones y composiciones para portadas de revistas, exhibiciones en museos, motion graphics y activos para videojuegos.<break time="1.0s" /> Finalmente, se predice que los agentes de codificación serán, en el futuro, mucho más efectivos que en la actualidad, y en un breve comentario se afirma que algunas personas mencionadas en el artículo son más inteligentes que el autor, sugiriendo que, una vez superada su “afectación”, estos agentes de codificación alcanzarán niveles de efectividad aún mayores.<break time="1.5s" />

Avanzando hacia los ejemplos y casos prácticos, se nos ofrece una visión de lo que puede lograr un agente.<break time="1.0s" /> Este puede encargarse de resolver tareas de inicio en proyectos pospuestos, proporcionando un punto de entrada inmediato para ajustar el código, o bien pasar horas en una máquina virtual refactorizando pruebas unitarias para luego generar una solicitud de extracción (PR).<break time="1.0s" /> Se menciona el modo agente de Zed, disponible en https://zed.dev/agentic, que muestra una notificación de escritorio al finalizar el trabajo sin requerir supervisión constante.<break time="1.0s" /> De forma humorística, se alude a la dificultad de establecer una buena “toolchain” para el lenguaje Brainfuck.<break time="1.0s" /> Se hace referencia también al ejemplo del paquete rsync y al artículo de Andrew Tridgell.<break time="1.0s" /> Regresando al ejemplo previo, se reitera el caso de la asignación de 13 tareas a un LLM, donde se detalla que 3 PRs fueron descartadas y re-promptadas, 5 recibieron retroalimentación al nivel de un desarrollador junior y 5 fueron finalmente integradas.<break time="1.0s" /> Además, se comparte el comentario de un colaborador que dice “está tomando rocket fuel,” implicando que aquellos que no adopten la IA quedarán inevitablemente rezagados.<break time="1.0s" /> Existe también un ejemplo relacionado con streaming, en el que se menciona la dificultad para hacer streaming de “The Expanse” en LibreWolf, haciendo alusión a discusiones sobre propiedad intelectual.<break time="1.5s" />

Pasemos ahora a los métodos y procesos involucrados en la implementación de agentes en programación asistida por LLMs.<break time="1.0s" /> Las funciones principales de un agente incluyen explorar el código de forma autónoma, escribir archivos directamente, ejecutar herramientas, compilar código, ejecutar pruebas y realizar iteraciones basadas en los resultados, así como incorporar código proveniente de la estructura de archivos local u otras fuentes en línea en la “ventana de contexto.”<break time="1.0s" /> Para lograr esto, los agentes utilizan herramientas Unix estándar para navegar por el árbol de archivos y extraer información, interactúan con Git y aprovechan herramientas existentes (como linters, formateadores y comprobadores de modelos) y realizan llamadas a herramientas configuradas a través de MCP.<break time="1.0s" /> De forma similar a cómo funciona un Makefile, el código que ejecutan estos agentes depende de conceptos básicos de programación relativos a funciones y dependencias.<break time="1.0s" /> Se subraya que la efectividad del agente depende en gran medida de la organización de los procesos de construcción, linting y pruebas.<break time="1.0s" /> La implementación de estos agentes se fundamenta en técnicas de instrucciones (prompts), índices y la integración de herramientas.<break time="1.0s" /> Es interesante notar que los LLMs llevan a cabo búsquedas internas, tipeo, generación de casos de prueba y ciclos de edición-compilación-prueba-depuración sin sufrir fatiga ni inercia.<break time="1.0s" /> Sin embargo, se recalca que los usuarios avanzados revisan y validan el código generado en lugar de copiarlo directamente sin revisión.<break time="1.5s" />

Finalmente, llegamos a los resultados y conclusiones reportadas.<break time="1.0s" /> Se afirma que los LLMs son capaces de generar una fracción significativa del código tedioso en proyectos típicos, lo que reduce la necesidad de realizar búsquedas en Google.<break time="1.0s" /> El código generado puede considerarse legible y comprensible, siempre y cuando se mantengan las debidas salvaguardas, negándose la noción de que dicho código sea inherentemente “probabilístico.”<break time="1.0s" /> La aplicación de agentes en la programación asistida incrementa la productividad al permitir que los desarrolladores se centren en tareas que requieren juicio y valores personales.<break time="1.0s" /> Aunque se reconoce que la mayoría del código en proyectos típicos se considera tedioso y, en ocasiones, mediocre, se destaca que la estructura y calidad de los procesos de construcción, linting y pruebas son determinantes en la efectividad de los agentes.<break time="1.0s" /> Se observa también que los LLMs han comenzado a adaptarse de forma incipiente a idiosincrasias locales, aunque sin alcanzar un alto grado de personalización.<break time="1.0s" /> La atención actual hacia la inteligencia artificial se compara con la atención recibida por los smartphones en 2008 y, en menor medida, con la de los inicios de Internet.<break time="1.0s" /> Por último, se predice que, a lo largo del tiempo, los agentes de codificación serán mucho más efectivos, elevando el piso mínimo de calidad del código producido.<break time="1.5s" />

En resumen, hemos recorrido desde la presentación del artículo “My AI Skeptic Friends Are All Nuts,” pasando por los hechos, definiciones, ejemplos, métodos y finalmente las conclusiones, abarcando cada detalle relevante sobre la adopción y funcionamiento de modelos de lenguaje a gran escala, la implementación de agentes en programación y la transformación en la productividad de los desarrolladores que se orientan hacia la inteligencia artificial.<break time="1.0s" /> Cada segmento nos ofrece una visión completa y precisa de cómo la tecnología y la innovación están transformando el panorama del desarrollo de software.