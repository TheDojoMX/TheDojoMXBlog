<!doctype html><html lang=es dir=ltr class=scroll-smooth data-default-appearance=dark data-auto-appearance=true><head><meta charset=utf-8><meta http-equiv=content-language content="es"><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><meta name=theme-color><title>¿Qué es un GPU? &#183; The Dojo MX Blog</title><meta name=title content="¿Qué es un GPU? &#183; The Dojo MX Blog"><meta name=description content="Hablemos de qué es un GPU desde la perspectiva de desarrollo: arquitectura, casos de uso y cuándo aprovecharlo para resolver problemas computacionales complejos."><meta name=keywords content="gpu,hardware,paralelismo,performance,"><link rel=canonical href=https://blog.thedojo.mx/2025/12/29/qu%C3%A9-es-un-gpu/><meta property="og:url" content="https://blog.thedojo.mx/2025/12/29/qu%C3%A9-es-un-gpu/"><meta property="og:site_name" content="The Dojo MX Blog"><meta property="og:title" content="¿Qué es un GPU?"><meta property="og:description" content="Hablemos de qué es un GPU desde la perspectiva de desarrollo: arquitectura, casos de uso y cuándo aprovecharlo para resolver problemas computacionales complejos."><meta property="og:locale" content="es"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-12-29T00:00:00+00:00"><meta property="article:modified_time" content="2025-12-29T00:00:00+00:00"><meta property="article:tag" content="Gpu"><meta property="article:tag" content="Hardware"><meta property="article:tag" content="Paralelismo"><meta property="article:tag" content="Performance"><meta name=twitter:card content="summary"><meta name=twitter:title content="¿Qué es un GPU?"><meta name=twitter:description content="Hablemos de qué es un GPU desde la perspectiva de desarrollo: arquitectura, casos de uso y cuándo aprovecharlo para resolver problemas computacionales complejos."><link type=text/css rel=stylesheet href=/css/main.bundle.min.f3f0a0f5f0a98349075e89ac6efd50d4005df562f33f20a0130bd2ad7167d99c0c20140704a8bb9618407ec5a01059c4c6ae400dd65f404a692fa4ba95f82eaa.css integrity="sha512-8/Cg9fCpg0kHXomsbv1Q1ABd9WLzPyCgEwvSrXFn2ZwMIBQHBKi7lhhAfsWgEFnExq5ADdZfQEppL6S6lfguqg=="><script type=text/javascript src=/js/appearance.min.6f41174b3a05b680820fe08cadbfa5fb7a7ca347b76a0955cdc68b9d8aca1ce24f0547e138cea33bcc7904d551a90afcb1cc7f2d9fe8557075d501419046c08c.js integrity="sha512-b0EXSzoFtoCCD+CMrb+l+3p8o0e3aglVzcaLnYrKHOJPBUfhOM6jO8x5BNVRqQr8scx/LZ/oVXB11QFBkEbAjA=="></script><script src=/lib/zoom/zoom.min.umd.a527109b68c082a70f3697716dd72a9d5aa8b545cf800cecbbc7399f2ca6f6e0ce3e431f2062b48bbfa47c9ea42822714060bef309be073f49b9c0e30d318d7b.js integrity="sha512-pScQm2jAgqcPNpdxbdcqnVqotUXPgAzsu8c5nyym9uDOPkMfIGK0i7+kfJ6kKCJxQGC+8wm+Bz9JucDjDTGNew=="></script><script defer type=text/javascript id=script-bundle src=/js/main.bundle.min.9cc802d09f28c6af56ceee7bc6e320a39251fdae98243f2a9942f221ac57a9f49c51609699a91794a7b2580ee1deaa8e4d794a68ffa94aa317c66e893ce51e02.js integrity="sha512-nMgC0J8oxq9Wzu57xuMgo5JR/a6YJD8qmULyIaxXqfScUWCWmakXlKeyWA7h3qqOTXlKaP+pSqMXxm6JPOUeAg==" data-copy=Copiar data-copied=Copiado></script><script src=/lib/jquery/jquery.slim.min.b0dca576e87d7eaa5850ae4e61759c065786cdb6489d68fcc82240539eebd5da522bdb4fda085ffd245808c8fe2acb2516408eb774ef26b5f6015fc6737c0ea8.js integrity="sha512-sNylduh9fqpYUK5OYXWcBleGzbZInWj8yCJAU57r1dpSK9tP2ghf/SRYCMj+KsslFkCOt3TvJrX2AV/Gc3wOqA=="></script><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><script type=application/ld+json>[{"@context":"https://schema.org","@type":"Article","articleSection":"Posts","name":"¿Qué es un GPU?","headline":"¿Qué es un GPU?","description":"Hablemos de qué es un GPU desde la perspectiva de desarrollo: arquitectura, casos de uso y cuándo aprovecharlo para resolver problemas computacionales complejos.","abstract":"\u003cp\u003eSi has estado atento a las tendencias de desarrollo de software, te habrás dado\ncuenta que la computación especializada cada vez está más extendida, sobre todo\npor la proliferación de modelos de machine learning que requieren un montón\nde cómputo. Uno de los elementos de hardware que brilla en esta industria es\nel GPU (Graphics Processing Unit). Hablemos de qué es un GPU desde nuestra\nperspectiva como desarrolladores de software.\u003c\/p\u003e","inLanguage":"es","url":"https:\/\/blog.thedojo.mx\/2025\/12\/29\/qu%C3%A9-es-un-gpu\/","author":{"@type":"Person","name":""},"copyrightYear":"2025","dateCreated":"2025-12-29T00:00:00\u002b00:00","datePublished":"2025-12-29T00:00:00\u002b00:00","dateModified":"2025-12-29T00:00:00\u002b00:00","keywords":["gpu","hardware","paralelismo","performance"],"mainEntityOfPage":"true","wordCount":"2299"}]</script><script async src="https://www.googletagmanager.com/gtag/js?id=UA-127437335-2"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","UA-127437335-2")</script></head><body class="flex flex-col h-screen m-auto leading-7 max-w-7xl px-6 sm:px-14 md:px-24 lg:px-32 text-lg bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600"><div id=the-top class="absolute flex self-center"><a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="font-bold text-primary-600 pe-2 dark:text-primary-400">&darr;</span>
Ir al contenido</a></div><div class=min-h-[148px]></div><div class="fixed inset-x-0 z-100"><div id=menu-blur class="absolute opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl shadow-2xl"></div><div class="relative m-auto leading-7 max-w-7xl px-6 sm:px-14 md:px-24 lg:px-32"><div class="main-menu flex items-center justify-between py-6 md:justify-start gap-x-3 pt-[2px] pr-2 md:pr-4 pb-[3px] pl-0"><div class="flex flex-1 items-center justify-between"><nav class="flex space-x-3"><a href=/ class="text-base font-medium">The Dojo MX Blog</a></nav><nav class="hidden md:flex items-center gap-x-5 md:ml-12 h-12"><a href=/posts/ class="flex items-center hover:text-primary-600 dark:hover:text-primary-400" aria-label=Posts title=Posts><p class="text-base font-medium">Posts</p></a><a href=/tags/ class="flex items-center hover:text-primary-600 dark:hover:text-primary-400" aria-label=Tags title=Tags><p class="text-base font-medium">Tags</p></a><a href=/about/ class="flex items-center hover:text-primary-600 dark:hover:text-primary-400" aria-label="Acerca de" title="Acerca de este Blog"><p class="text-base font-medium">Acerca de</p></a><button id=search-button aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title="Buscar (/)">
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></button><div class="flex items-center"><button id=appearance-switcher aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400"><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentColor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentColor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></nav><div class="flex md:hidden items-center gap-x-5 md:ml-12 h-12"><span></span>
<button id=search-button-mobile aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title="Buscar (/)">
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span></button>
<button id=appearance-switcher-mobile aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400 me-1"><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentColor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentColor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></div><div class="-my-2 md:hidden"><div id=menu-button class=block><div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentColor" d="M0 96C0 78.33 14.33 64 32 64H416c17.7.0 32 14.33 32 32 0 17.7-14.3 32-32 32H32C14.33 128 0 113.7.0 96zM0 256c0-17.7 14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32H32c-17.67.0-32-14.3-32-32zM416 448H32c-17.67.0-32-14.3-32-32s14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32z"/></svg></span></div><div id=menu-wrapper class="fixed inset-0 z-30 invisible w-screen h-screen m-0 overflow-auto transition-opacity opacity-0 cursor-default bg-neutral-100/50 backdrop-blur-sm dark:bg-neutral-900/50 pt-[5px]"><ul class="flex space-y-2 mt-3 flex-col items-end w-full px-6 py-6 mx-auto overflow-visible list-none text-end max-w-7xl"><li id=menu-close-button><span class="cursor-pointer inline-block align-text-bottom hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentColor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></span></li><li class=mt-1><a href=/posts/ class="flex items-center hover:text-primary-600 dark:hover:text-primary-400" aria-label=Posts title=Posts><p class="text-bg font-bg">Posts</p></a></li><li class=mt-1><a href=/tags/ class="flex items-center hover:text-primary-600 dark:hover:text-primary-400" aria-label=Tags title=Tags><p class="text-bg font-bg">Tags</p></a></li><li class=mt-1><a href=/about/ class="flex items-center hover:text-primary-600 dark:hover:text-primary-400" aria-label="Acerca de" title="Acerca de este Blog"><p class="text-bg font-bg">Acerca de</p></a></li></ul></div></div></div></div><script>(function(){var e=$(".main-menu"),t=window.location.pathname;e.find('a[href="'+t+'"]').each(function(e,t){$(t).children("p").addClass("active")})})()</script></div></div><script type=text/javascript src=/js/background-blur.min.00a57c73ea12f2cab2980c3c3d649e89f6d82f190f74bbe2b67f2f5e39ab7d032ece47086400ca05396758aace13299da49aca43ea643d2625e62c506267a169.js integrity="sha512-AKV8c+oS8sqymAw8PWSeifbYLxkPdLvitn8vXjmrfQMuzkcIZADKBTlnWKrOEymdpJrKQ+pkPSYl5ixQYmehaQ==" data-blur-id=menu-blur></script><div class="relative flex flex-col grow"><main id=main-content class=grow><article><header id=single_header class="mt-5 max-w-prose"><ol class="text-sm text-neutral-500 dark:text-neutral-400 print:hidden"><li class=hidden><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/>The Dojo MX Blog</a><span class="px-1 text-primary-500">/</span></li><li class=inline><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/posts/>Posts</a><span class="px-1 text-primary-500">/</span></li><li class=hidden><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/2025/12/29/qu%C3%A9-es-un-gpu/>¿Qué es un GPU?</a><span class="px-1 text-primary-500">/</span></li></ol><h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">¿Qué es un GPU?</h1><div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden"><div class="flex flex-row flex-wrap items-center"><time datetime=2025-12-29T00:00:00+00:00>29 diciembre 2025</time><span class="px-2 text-primary-500">&#183;</span><span>2299 palabras</span><span class="px-2 text-primary-500">&#183;</span><span title="Tiempo de lectura">11 mins</span></div><div class="flex flex-row flex-wrap items-center"><a class="relative mt-[0.5rem] me-2" href=/tags/gpu/><span class="flex cursor-pointer"><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Gpu
</span></span></a><a class="relative mt-[0.5rem] me-2" href=/tags/hardware/><span class="flex cursor-pointer"><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Hardware
</span></span></a><a class="relative mt-[0.5rem] me-2" href=/tags/paralelismo/><span class="flex cursor-pointer"><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Paralelismo
</span></span></a><a class="relative mt-[0.5rem] me-2" href=/tags/performance/><span class="flex cursor-pointer"><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Performance</span></span></a></div></div><div class="flex author"><div class=place-self-center><div class="text-2xl sm:text-lg"></div></div></div><div class=mb-5></div></header><section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row"><div class="order-first lg:ml-auto px-0 lg:order-last lg:ps-8 lg:max-w-2xs"><div class="toc ps-5 print:hidden lg:sticky lg:top-[140px]"><details open id=TOCView class="toc-right mt-0 overflow-y-auto overscroll-contain scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600 rounded-lg -ms-5 ps-5 pe-2 hidden lg:block"><summary class="block py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 -ms-5 ps-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Tabla de contenido</summary><div class="min-w-[220px] py-2 border-dotted border-s-1 -ms-5 ps-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><a href=#gpus-para-desarrolladores>GPUs para Desarrolladores</a></li><li><a href=#cpu-vs-gpu-filosofías-de-diseño-diferentes>CPU vs GPU: Filosofías de Diseño Diferentes</a><ul><li><a href=#cpu-el-artesano-experto>CPU: El Artesano experto</a></li><li><a href=#gpu-la-línea-de-ensamblaje>GPU: La Línea de Ensamblaje</a></li></ul></li><li><a href=#arquitectura-de-un-gpu>Arquitectura de un GPU</a><ul><li><a href=#unidades-de-procesamiento>Unidades de Procesamiento</a></li><li><a href=#jerarquía-de-memoria>Jerarquía de Memoria</a></li><li><a href=#modelo-de-ejecución-de-un-gpu>Modelo de Ejecución de un GPU</a></li><li><a href=#ancho-de-banda-vs-latencia>Ancho de Banda vs Latencia</a></li></ul></li><li><a href=#paralelismo-de-datos>Paralelismo de Datos</a><ul><li><a href=#ejemplo-práctico>Ejemplo Práctico</a></li><li><a href=#complejidad-de-programación---desafíos>Complejidad de Programación - Desafíos</a></li><li><a href=#cuándo-no-usar-gpu>Cuándo NO usar GPU</a></li><li><a href=#consumo-energético>Consumo Energético</a></li></ul></li><li><a href=#librerías-que-abstraen-el-gpu>Librerías que Abstraen el GPU</a></li><li><a href=#futuro-y-tendencias>Futuro y Tendencias</a><ul><li><a href=#gpu-programming-más-accesible>GPU Programming Más Accesible</a></li><li><a href=#hardware-especializado>Hardware Especializado</a></li><li><a href=#gpus-en-la-nube>GPUs en la Nube</a></li></ul></li><li><a href=#conclusión>Conclusión</a></li><li><a href=#referencias-y-recursos-para-profundizar>Referencias y Recursos para Profundizar</a><ul><li><a href=#libros-fundamentales>Libros Fundamentales</a></li><li><a href=#documentación-oficial>Documentación Oficial</a></li><li><a href=#cursos>Cursos</a></li><li><a href=#recursos-técnicos-y-tutoriales>Recursos Técnicos y Tutoriales</a></li><li><a href=#recursos-de-arquitectura-física>Recursos de Arquitectura física</a></li><li><a href=#herramientas-y-sdks>Herramientas y SDKs</a></li><li><a href=#artículos-y-papers-académicos>Artículos y Papers Académicos</a></li></ul></li></ul></nav></div></details><details class="toc-inside mt-0 overflow-hidden rounded-lg -ms-5 ps-5 lg:hidden"><summary class="py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 -ms-5 ps-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Tabla de contenido</summary><div class="py-2 border-dotted border-neutral-300 border-s-1 -ms-5 ps-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><a href=#gpus-para-desarrolladores>GPUs para Desarrolladores</a></li><li><a href=#cpu-vs-gpu-filosofías-de-diseño-diferentes>CPU vs GPU: Filosofías de Diseño Diferentes</a><ul><li><a href=#cpu-el-artesano-experto>CPU: El Artesano experto</a></li><li><a href=#gpu-la-línea-de-ensamblaje>GPU: La Línea de Ensamblaje</a></li></ul></li><li><a href=#arquitectura-de-un-gpu>Arquitectura de un GPU</a><ul><li><a href=#unidades-de-procesamiento>Unidades de Procesamiento</a></li><li><a href=#jerarquía-de-memoria>Jerarquía de Memoria</a></li><li><a href=#modelo-de-ejecución-de-un-gpu>Modelo de Ejecución de un GPU</a></li><li><a href=#ancho-de-banda-vs-latencia>Ancho de Banda vs Latencia</a></li></ul></li><li><a href=#paralelismo-de-datos>Paralelismo de Datos</a><ul><li><a href=#ejemplo-práctico>Ejemplo Práctico</a></li><li><a href=#complejidad-de-programación---desafíos>Complejidad de Programación - Desafíos</a></li><li><a href=#cuándo-no-usar-gpu>Cuándo NO usar GPU</a></li><li><a href=#consumo-energético>Consumo Energético</a></li></ul></li><li><a href=#librerías-que-abstraen-el-gpu>Librerías que Abstraen el GPU</a></li><li><a href=#futuro-y-tendencias>Futuro y Tendencias</a><ul><li><a href=#gpu-programming-más-accesible>GPU Programming Más Accesible</a></li><li><a href=#hardware-especializado>Hardware Especializado</a></li><li><a href=#gpus-en-la-nube>GPUs en la Nube</a></li></ul></li><li><a href=#conclusión>Conclusión</a></li><li><a href=#referencias-y-recursos-para-profundizar>Referencias y Recursos para Profundizar</a><ul><li><a href=#libros-fundamentales>Libros Fundamentales</a></li><li><a href=#documentación-oficial>Documentación Oficial</a></li><li><a href=#cursos>Cursos</a></li><li><a href=#recursos-técnicos-y-tutoriales>Recursos Técnicos y Tutoriales</a></li><li><a href=#recursos-de-arquitectura-física>Recursos de Arquitectura física</a></li><li><a href=#herramientas-y-sdks>Herramientas y SDKs</a></li><li><a href=#artículos-y-papers-académicos>Artículos y Papers Académicos</a></li></ul></li></ul></nav></div></details><script>(function(){"use strict";const s=.33,o="#TableOfContents",i=".anchor",a='a[href^="#"]',r="li ul",c="active";let t=!1;function l(e,n){const o=window.scrollY+window.innerHeight*n,i=[...document.querySelectorAll('#TableOfContents a[href^="#"]')],s=new Set(i.map(e=>e.getAttribute("href").substring(1)));if(t)for(let t=0;t<e.length;t++){const n=e[t];if(!s.has(n.id))continue;const o=n.getBoundingClientRect().top+window.scrollY;if(Math.abs(window.scrollY-o)<100)return n.id}for(let t=e.length-1;t>=0;t--){const n=e[t].getBoundingClientRect().top+window.scrollY;if(n<=o&&s.has(e[t].id))return e[t].id}return e.find(e=>s.has(e.id))?.id||""}function e({toc:e,anchors:t,links:n,scrollOffset:s,collapseInactive:o}){const i=l(t,s);if(!i)return;if(n.forEach(e=>{const t=e.getAttribute("href")===`#${i}`;if(e.classList.toggle(c,t),o){const n=e.closest("li")?.querySelector("ul");n&&(n.style.display=t?"":"none")}}),o){const n=e.querySelector(`a[href="#${CSS.escape(i)}"]`);let t=n;for(;t&&t!==e;)t.tagName==="UL"&&(t.style.display=""),t.tagName==="LI"&&t.querySelector("ul")?.style.setProperty("display",""),t=t.parentElement}}function n(){const n=document.querySelector(o);if(!n)return;const l=!1,u=[...document.querySelectorAll(i)],d=[...n.querySelectorAll(a)];l&&n.querySelectorAll(r).forEach(e=>e.style.display="none"),d.forEach(e=>{e.addEventListener("click",()=>{t=!0})});const c={toc:n,anchors:u,links:d,scrollOffset:s,collapseInactive:l};window.addEventListener("scroll",()=>e(c),{passive:!0}),window.addEventListener("hashchange",()=>e(c),{passive:!0}),e(c)}document.readyState==="loading"?document.addEventListener("DOMContentLoaded",n):n()})()</script></div></div><div class="min-w-0 min-h-0 max-w-fit"><div class="article-content max-w-prose mb-20"><p>Si has estado atento a las tendencias de desarrollo de software, te habrás dado
cuenta que la computación especializada cada vez está más extendida, sobre todo
por la proliferación de modelos de machine learning que requieren un montón
de cómputo. Uno de los elementos de hardware que brilla en esta industria es
el GPU (Graphics Processing Unit). Hablemos de qué es un GPU desde nuestra
perspectiva como desarrolladores de software.</p><h2 class="relative group">GPUs para Desarrolladores<div id=gpus-para-desarrolladores class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#gpus-para-desarrolladores aria-label=Ancla>#</a></span></h2><p>Lo que comenzó como hardware especializado para renderizar gráficos en videojuegos
se ha convertido en el motor computacional detrás de los modelos de inteligencia
artificial más avanzados, simulaciones científicas complejas y procesamiento
masivo de datos.</p><p>Como desarrolladores modernos, entender qué es un GPU y cuándo aprovecharlo
es muy importante. Si trabajas (o quieres trabajar) con machine learning,
procesamiento de video, análisis de datos masivos o cualquier problema que
requiera procesar grandes cantidades de información, los GPUs pueden acelerar
tu código de 10x a 100x comparado con implementaciones tradicionales.
Esa mejora llega cuando el trabajo es masivamente paralelo (perfectamente paralelizable)
y el costo de mover datos del host al GPU queda amortizado; en cargas pequeñas
o con mucho branching, un CPU con AVX y varios hilos puede igualar o superar al GPU.</p><p>Este artículo te explicará qué es un GPU desde la perspectiva de la arquitectura
de computadoras. En otro artículo veremos cómo identificar problemas que puedan
beneficiarse de una implementación en GPUs en lugar de CPUs tradicionales.</p><h2 class="relative group">CPU vs GPU: Filosofías de Diseño Diferentes<div id=cpu-vs-gpu-filosofías-de-diseño-diferentes class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#cpu-vs-gpu-filosof%c3%adas-de-dise%c3%b1o-diferentes aria-label=Ancla>#</a></span></h2><p>Para entender un GPU, primero debemos contrastar su diseño con el de un CPU
(Central Processing Unit). Pongamos un ejemplo sencillo.</p><h3 class="relative group">CPU: El Artesano experto<div id=cpu-el-artesano-experto class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#cpu-el-artesano-experto aria-label=Ancla>#</a></span></h3><p>Un CPU tiene <strong>pocos núcleos poderosos</strong> (típicamente 4-64 núcleos en CPUs
modernas). Está optimizado <strong>para tareas <em>secuenciales</em> complejas</strong> con
muchas dependencias, o con mucho control de flujo (condicionales, branches).
Ejecuta instrucciones individuales muy rápido, algunas de ellas, dependiendo
de la arquitectura, muy complejas. Por ejemplo, una sola instrucción puede
hacer una operación criptográfica como AES (cifrado) o SHA (hashing).</p><p>Los CPUs tienen un <em>control de flujo sofisticado</em>: pueden predecir
(estadísticamente) por qué camino se irá el código y prepararse para ello.
También tienen cachés &ldquo;enormes&rdquo; (L1, L2, L3) para minimizar la latencia de acceso
a memoria. Otra característica es que pueden reordenar las instrucciones
de bajo nivel para aprovechar mejor los recursos, reduciendo la latencia en la
ejecución.</p><p>Si quieres tener máximo control y flexibilidad, como en el caso de lógica de
negocio, bases de datos, servidores web, algoritmos complejos, etc., tu programa
debe correr en CPU. Esto es lo que el 99.999% de los desarrolladores hacemos,
a tal punto que ni siquiera nos preguntamos dónde debe vivir nuestro software.</p><p>Ahora hablemos del tema que nos concierne: los GPUs.</p><h3 class="relative group">GPU: La Línea de Ensamblaje<div id=gpu-la-línea-de-ensamblaje class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#gpu-la-l%c3%adnea-de-ensamblaje aria-label=Ancla>#</a></span></h3><p>Un GPU tiene <strong>muchísimos núcleos simples</strong> (miles a decenas de miles en GPUs modernas).
Están pensados para <strong>optimizar paralelismo masivo</strong> con operaciones <em>independientes</em>.
Un GPU procesa <strong>grandes cantidades de datos simultáneamente, pero aplicándoles operaciones
relativamente sencillas</strong>.</p><p>Su control de flujo es simple, es decir, no puede predecir branches complejos ni
reordenar instrucciones. Digamos que su principal fortaleza es hacer operaciones
matemáticas básicas (suma, multiplicación, etc.) en muchos datos al mismo tiempo.</p><p>La comparación es clara: un GPU es como una línea de ensamblaje que tiene miles de
unidades que pueden hacer trabajo simple al mismo tiempo, mientras que un CPU es
como un conjunto de artesanos expertos haciendo trabajo complejo y <em>secuencial
principalmente</em>.</p><p>Ahora hablemos de la arquitectura de un GPU para ver cómo hace el paralelismo masivo posible.</p><h2 class="relative group">Arquitectura de un GPU<div id=arquitectura-de-un-gpu class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#arquitectura-de-un-gpu aria-label=Ancla>#</a></span></h2><p>Los GPUs modernos organizan sus recursos computacionales en varias capas. Veamos cuáles y cómo puedes usarlas para tus programas.</p><h3 class="relative group">Unidades de Procesamiento<div id=unidades-de-procesamiento class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#unidades-de-procesamiento aria-label=Ancla>#</a></span></h3><p>El componente principal es el conjunto de núcleos individuales que hacen el trabajo
real, estos pequeños procesadores tienen diferentes nombres dependiendo del
fabricante:</p><ul><li><strong>NVIDIA</strong>: CUDA Cores</li><li><strong>AMD</strong>: Stream Processors</li><li><strong>Intel</strong>: Execution Units (EUs)</li></ul><p>Y así&mldr; pero la idea es la misma: muchos núcleos o procesadores encargados
de hacer operaciones matemáticas básicas.</p><p>Estos núcleos están agrupados en unidades mayores que llamamos <strong>Streaming Multiprocessors (SMs)</strong>
y tienen una memoria rápida compartida entre ellos. A nivel global, tenemos otro nivel de memoria accesible a todos los SMs.</p><p>Desde 2017 (con la arquitectura Volta) y sobre todo pensando en cargas de operaciones matriciales complejas
(como las que se usan en machine learning) se han añadido unidades especializadas: los <strong>Tensor Cores</strong>.
La industria se está adaptando a los nuevos usos del
software.</p><h3 class="relative group">Jerarquía de Memoria<div id=jerarquía-de-memoria class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#jerarqu%c3%ada-de-memoria aria-label=Ancla>#</a></span></h3><p>Al igual que los <em>CPUs</em>, los GPUs tienen un conjunto de diferentes tipos (y velocidades) de memoria.
La jerarquía de memoria típica en un GPU es:</p><ol><li><strong>Registros</strong>: Memoria ultra-rápida privada de cada thread para operaciones inmediatas</li><li><strong>Memoria compartida</strong>: A nivel de bloque de los SMs, muy rápida, accesible por threads del mismo bloque</li><li><strong>Memoria global</strong>: Memoria grande pero con mayor latencia, accesible por todos los threads</li><li><strong>Memoria de textura/constantes</strong>: Optimizada para patrones específicos de acceso (solo lectura)</li><li><strong>Memoria de host</strong>: La RAM del sistema, accesible a través del bus PCIe (la más lenta)</li></ol><p>El patrón de acceso es importante: los accesos coalescidos (threads contiguos leyendo direcciones contiguas)
aprovechan el ancho de banda; accesos dispersos o sin alineación
se penalizan con más transacciones y mayor latencia efectiva.</p><h3 class="relative group">Modelo de Ejecución de un GPU<div id=modelo-de-ejecución-de-un-gpu class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#modelo-de-ejecuci%c3%b3n-de-un-gpu aria-label=Ancla>#</a></span></h3><p>Veamos cómo corre un programa en un GPU: primero el programa se divide
en <strong>kernels</strong>. Un kernel es una función que se ejecuta aprovechando
la estructura de procesamiento del GPU: lanza cientos o miles de threads en paralelo.
Cada thread ejecuta la misma función pero con datos diferentes. Un <strong>thread</strong> (hilo)
es la unidad básica de ejecución en un GPU.</p><p>La jerarquía de ejecución es:</p><ul><li><strong>Warp</strong>: Grupo de <strong>32 threads (en NVIDIA)</strong> que ejecutan la misma instrucción simultáneamente en lockstep.
Es la unidad mínima de scheduling. En AMD se llaman wavefronts y suelen ser de 32 o 64 threads.</li><li><strong>Bloque de threads</strong>: Grupo de threads (múltiples warps) que pueden cooperar y compartir memoria. Un bloque puede tener hasta 1024 threads.</li><li><strong>Grid</strong>: Colección de bloques que ejecutan el mismo kernel. Puede tener miles de bloques.</li></ul><h3 class="relative group">Ancho de Banda vs Latencia<div id=ancho-de-banda-vs-latencia class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#ancho-de-banda-vs-latencia aria-label=Ancla>#</a></span></h3><p>Los GPUs priorizan <strong>throughput</strong> (cantidad de trabajo procesado, basado en datos)
sobre <strong>latencia</strong> (tiempo para una operación individual). Esto significa
que aunque una operación individual puede tardar más en GPU que en CPU, el
GPU puede procesar miles de operaciones simultáneamente, resultando en mayor throughput total.</p><h2 class="relative group">Paralelismo de Datos<div id=paralelismo-de-datos class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#paralelismo-de-datos aria-label=Ancla>#</a></span></h2><p>El modelo de programación de GPUs se basa en <strong>SIMD/SIMT</strong> (Single Instruction, Multiple Data / Single Instruction, Multiple Threads):</p><ul><li><strong>SIMD</strong> (usado también en CPUs): Una instrucción opera sobre múltiples
datos en registros vectoriales</li><li><strong>SIMT</strong> (específico de GPUs): Similar, pero cada thread tiene su propio
contador de programa. Todos los threads en un warp ejecutan la misma instrucción
al mismo tiempo sobre diferentes datos</li></ul><h3 class="relative group">Ejemplo Práctico<div id=ejemplo-práctico class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#ejemplo-pr%c3%a1ctico aria-label=Ancla>#</a></span></h3><p><strong>Problema A</strong>: Multiplicar 1 millón de números por una constante</p><ul><li><strong>Paralelismo perfecto</strong>: Cada operación es independiente</li><li><strong>GPU gana dramáticamente</strong>: 100x más rápido o más dependiendo del hardware</li></ul><p><strong>Problema B</strong>: Construir un árbol de decisión con lógica compleja</p><ul><li><strong>Inherentemente secuencial</strong>: Cada decisión depende de la anterior</li><li><strong>CPU gana</strong>: Mejor control de flujo y menor overhead</li></ul><p><strong>Benchmark rápido (PyTorch)</strong>: mide multiplicar un vector grande en CPU vs GPU (ideal para Colab con GPU).</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> torch<span style=color:#f92672>,</span> time
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>device <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;cuda&#34;</span> <span style=color:#66d9ef>if</span> torch<span style=color:#f92672>.</span>cuda<span style=color:#f92672>.</span>is_available() <span style=color:#66d9ef>else</span> <span style=color:#e6db74>&#34;cpu&#34;</span>
</span></span><span style=display:flex><span>a <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>rand(<span style=color:#ae81ff>10_000_000</span>, device<span style=color:#f92672>=</span>device)
</span></span><span style=display:flex><span>b <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>rand(<span style=color:#ae81ff>10_000_000</span>, device<span style=color:#f92672>=</span>device)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>run</span>(dev):
</span></span><span style=display:flex><span>    x, y <span style=color:#f92672>=</span> a<span style=color:#f92672>.</span>to(dev), b<span style=color:#f92672>.</span>to(dev)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> dev <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;cuda&#34;</span>:
</span></span><span style=display:flex><span>        torch<span style=color:#f92672>.</span>cuda<span style=color:#f92672>.</span>synchronize()
</span></span><span style=display:flex><span>    t0 <span style=color:#f92672>=</span> time<span style=color:#f92672>.</span>time()
</span></span><span style=display:flex><span>    z <span style=color:#f92672>=</span> x <span style=color:#f92672>*</span> y <span style=color:#f92672>+</span> <span style=color:#ae81ff>1.0</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> dev <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;cuda&#34;</span>:
</span></span><span style=display:flex><span>        torch<span style=color:#f92672>.</span>cuda<span style=color:#f92672>.</span>synchronize()
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> time<span style=color:#f92672>.</span>time() <span style=color:#f92672>-</span> t0
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;CPU:&#34;</span>, run(<span style=color:#e6db74>&#34;cpu&#34;</span>))
</span></span><span style=display:flex><span><span style=color:#66d9ef>if</span> torch<span style=color:#f92672>.</span>cuda<span style=color:#f92672>.</span>is_available():
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#34;GPU:&#34;</span>, run(<span style=color:#e6db74>&#34;cuda&#34;</span>))
</span></span></code></pre></div><p>La primera llamada en GPU incluye overhead de inicialización; las siguientes suelen ser mucho más rápidas.</p><h3 class="relative group">Complejidad de Programación - Desafíos<div id=complejidad-de-programación---desafíos class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#complejidad-de-programaci%c3%b3n---desaf%c3%ados aria-label=Ancla>#</a></span></h3><p>Programar para GPUs es completamente diferente que programar para CPUs. Aquí
algunos retos:</p><ul><li><strong>Debugging</strong>: Más difícil que código CPU, porque tenemos herramientas más limitadas</li><li><strong>Profiling</strong>: Herramientas especializadas necesarias (NVIDIA Nsight, AMD ROCm Profiler)</li><li><strong>Curva de aprendizaje</strong>: Entender modelo de memoria y ejecución</li><li><strong>Portabilidad</strong>: CUDA es específico de NVIDIA (alternativas: OpenCL, SYCL, HIP)</li></ul><h3 class="relative group">Cuándo NO usar GPU<div id=cuándo-no-usar-gpu class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#cu%c3%a1ndo-no-usar-gpu aria-label=Ancla>#</a></span></h3><p>No todos los problemas se benefician de un GPU. Aquí algunos casos donde un CPU puede ser mejor:</p><ul><li>Lotes pequeños o poca aritmética por dato: el overhead de lanzar kernels y mover datos por PCIe elimina cualquier ganancia.</li><li>Algoritmos con mucha divergencia de branches: los warps/wavefronts se serializan y pierdes throughput. A esto le llamamos <em>warp divergence</em>.</li><li>Datos que no caben en VRAM o flujos con mucho ida y vuelta host &lt;-> GPU: el bus se vuelve el cuello de botella.</li><li>Latencias ultrabajas por petición (p.ej., microservicios síncronos): el cold-start y la cola del GPU pueden ser peores que un CPU saturado.</li></ul><h3 class="relative group">Consumo Energético<div id=consumo-energético class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#consumo-energ%c3%a9tico aria-label=Ancla>#</a></span></h3><p>Los GPUs consumen más energía total que los CPUs, aunque en cargas masivas suelen entregar mejor rendimiento por watt.</p><p>Para dar contexto:</p><ul><li><strong>CPU de escritorio típico</strong>: 65-125W</li><li><strong>GPU de alto rendimiento (RTX 4090)</strong>: 450W</li><li><strong>GPU de datacenter (H100)</strong>: 700W</li></ul><p>Además del consumo, considera:</p><ul><li>Hardware costoso (una H100 cuesta aprox $30,000 USD, una RTX 4090 aprox $1,600 USD)</li><li>Refrigeración y infraestructura adicional necesaria</li></ul><p>GPUs integrados (iGPU) comparten memoria con el CPU: menos potencia pero sin viaje por PCIe y útiles para prototipos o edge; los discretos (dGPU) tienen VRAM dedicada y mucho más throughput, a cambio de consumo y costo mayores.</p><h2 class="relative group">Librerías que Abstraen el GPU<div id=librerías-que-abstraen-el-gpu class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#librer%c3%adas-que-abstraen-el-gpu aria-label=Ancla>#</a></span></h2><p>No siempre necesitas programar en CUDA directamente. Muchas librerías aprovechan
GPUs de forma transparente:</p><ul><li><strong>Deep Learning</strong>: PyTorch, TensorFlow, JAX</li><li><strong>Data Science</strong>: cuDF, RAPIDS (equivalentes a Pandas pero en GPU)</li><li><strong>Computación científica</strong>: CuPy (NumPy en GPU), cuBLAS</li><li><strong>Procesamiento de imágenes</strong>: OpenCV con CUDA</li><li><strong>Alternativas AMD/Intel/portables</strong>: ROCm (hip, MIOpen, rocBLAS), oneAPI/SYCL (DPC++), OpenCL para no depender solo de CUDA.</li></ul><h2 class="relative group">Futuro y Tendencias<div id=futuro-y-tendencias class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#futuro-y-tendencias aria-label=Ancla>#</a></span></h2><h3 class="relative group">GPU Programming Más Accesible<div id=gpu-programming-más-accesible class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#gpu-programming-m%c3%a1s-accesible aria-label=Ancla>#</a></span></h3><p>Tenemos algunas opciones para programar GPUs sin lidiar directamente con CUDA</p><ul><li><strong>Compiladores inteligentes</strong>: Generación automática de código GPU</li><li><strong>Lenguajes de alto nivel</strong>: Triton (Python para kernels), Mojo, SYCL</li><li><strong>Auto-tuning</strong>: Optimización automática de parámetros</li></ul><h3 class="relative group">Hardware Especializado<div id=hardware-especializado class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#hardware-especializado aria-label=Ancla>#</a></span></h3><ul><li><strong>TPUs (Tensor Processing Units)</strong>: Optimizadas para operaciones de ML, desarrolladas por Google</li><li><strong>NPUs (Neural Processing Units)</strong>: IA en edge devices y dispositivos móviles</li><li><strong>FPGAs (Field-Programmable Gate Arrays)</strong>: Hardware reconfigurable para cargas específicas, menor consumo pero más difíciles de programar</li></ul><h3 class="relative group">GPUs en la Nube<div id=gpus-en-la-nube class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#gpus-en-la-nube aria-label=Ancla>#</a></span></h3><p>Si no tienes un GPU físico hay varias formas de acceder a GPUs de alto rendimiento,
de forma remota y sin mucha inversión por adelantado:</p><ul><li><strong>Serverless GPU</strong>: Paga solo por el tiempo de uso (Modal, RunPod, Lambda Labs). Son modelos administrados con cobro por minuto/hora; no siempre hay cold start cero y la disponibilidad varía por región.</li><li><strong>Spot instances</strong>: GPU computing económico (AWS, GCP, Azure)</li><li><strong>Kubernetes con GPUs</strong>: Orquestación de cargas GPU</li><li><strong>Google Colab / Kaggle</strong>: GPUs gratuitas para experimentación</li></ul><h2 class="relative group">Conclusión<div id=conclusión class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#conclusi%c3%b3n aria-label=Ancla>#</a></span></h2><p>Los GPUs representan una herramienta fundamental en el arsenal del desarrollador
moderno para resolver problemas que involucran paralelismo masivo de datos.</p><p>Entender su arquitectura, fortalezas y limitaciones te permite identificar
oportunidades donde una implementación en GPU puede transformar un problema
intratable en uno solucionable.</p><p>La clave está en reconocer el patrón: <strong>¿Estás aplicando la misma operación a muchos datos?</strong> Si la respuesta es sí, probablemente hay una oportunidad de aceleración con GPU.</p><p>Si quieres experimentar sin instalar nada, abre Google Colab y prueba PyTorch o TensorFlow con GPU habilitado. Verás la diferencia de velocidad en minutos.</p><h2 class="relative group">Referencias y Recursos para Profundizar<div id=referencias-y-recursos-para-profundizar class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#referencias-y-recursos-para-profundizar aria-label=Ancla>#</a></span></h2><p>La programación de GPUs es un campo amplio y bastante diferente a la programación
&ldquo;tradicional&rdquo;. Aquí nos centramos en transformaciones matemáticas, álgebra lineal
e incluso cálculo.</p><h3 class="relative group">Libros Fundamentales<div id=libros-fundamentales class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#libros-fundamentales aria-label=Ancla>#</a></span></h3><p><strong>Programming Massively Parallel Processors: A Hands-on Approach</strong> - (David B.
Kirk, Wen-mei W. Hwu, Izzat El Hajj): El LIBRO que tienes que leer para aprender
programación de GPUs. Cubre desde conceptos básicos hasta técnicas avanzadas con
enfoque práctico.</p><p><strong>GPU Gems Series</strong> (Disponibles gratis online)</p><ul><li><em>GPU Gems 1</em> (2004): Técnicas de programación gráfica en tiempo real</li><li><em>GPU Gems 2</em> (2005): 20 capítulos dedicados a GPU programming</li><li><em>GPU Gems 3</em>: Técnicas modernas de GPU programming</li><li><em>Link</em>: <a href=https://developer.nvidia.com/gpugems target=_blank>NVIDIA Developer</a></li></ul><h3 class="relative group">Documentación Oficial<div id=documentación-oficial class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#documentaci%c3%b3n-oficial aria-label=Ancla>#</a></span></h3><p><strong>CUDA C++ Programming Guide</strong></p><ul><li><em>Fuente</em>: NVIDIA Official Documentation</li><li><em>Descripción</em>: Documentación completa y oficial del modelo de programación CUDA</li><li><em>Link</em>: <a href=https://docs.nvidia.com/cuda/cuda-c-programming-guide/ target=_blank>https://docs.nvidia.com/cuda/cuda-c-programming-guide/</a></li></ul><p><strong>CUDA C++ Best Practices Guide</strong></p><ul><li><em>Descripción</em>: Técnicas de optimización y patrones idiomáticos para programación CUDA</li><li><em>Link</em>: <a href=https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/ target=_blank>https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/</a></li></ul><h3 class="relative group">Cursos<div id=cursos class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#cursos aria-label=Ancla>#</a></span></h3><p><strong>CS 179: GPU Programming</strong> - Caltech</p><ul><li>De este curso puedes encontrar todas las presentaciones en línea</li><li>Curso académico con 6 tareas y proyecto de 4 semanas</li><li><em>Link</em>: <a href=https://courses.cms.caltech.edu/cs179 target=_blank>https://courses.cms.caltech.edu/cs179/</a></li></ul><p><strong>GPU Programming Specialization</strong> - Johns Hopkins (Coursera)</p><ul><li><em>Descripción</em>: Especialización completa en high performance computing con GPUs</li><li><em>Link</em>: <a href=https://www.coursera.org/specializations/gpu-programming target=_blank>Coursera</a></li></ul><p><strong>NVIDIA CUDA Education & Training</strong></p><ul><li><em>Descripción</em>: Cursos oficiales de NVIDIA, self-paced e instructor-led</li><li><em>Incluye</em>: GPU-accelerated workstations en la nube, certificaciones</li><li><em>Link</em>: <a href=https://developer.nvidia.com/cuda-education-training target=_blank>https://developer.nvidia.com/cuda-education-training</a></li></ul><h3 class="relative group">Recursos Técnicos y Tutoriales<div id=recursos-técnicos-y-tutoriales class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#recursos-t%c3%a9cnicos-y-tutoriales aria-label=Ancla>#</a></span></h3><p><strong>GPU Programming: When, Why and How? (ENCCS)</strong></p><ul><li><em>Descripción</em>: Guía comprensiva sobre cuándo y cómo usar GPUs</li><li><em>Temas</em>: Conceptos clave, frameworks disponibles, fundamentos prácticos</li><li><em>Link</em>: <a href=https://enccs.github.io/gpu-programming/ target=_blank>https://enccs.github.io/gpu-programming/</a></li></ul><p><strong>Cornell Virtual Workshop: Understanding GPU Architecture</strong></p><ul><li><em>Descripción</em>: Material educativo sobre arquitectura de GPUs</li><li><em>Link</em>: <a href=https://cvw.cac.cornell.edu/gpu-architecture target=_blank>https://cvw.cac.cornell.edu/gpu-architecture</a></li></ul><p><strong>A Case for Learning GPU Programming with a Compute-First Mindset</strong></p><ul><li><em>Autor</em>: Maister&rsquo;s Graphics Adventures (Octubre 2025)</li><li><em>Descripción</em>: Meta-tutorial moderno sobre aprender programación GPU</li><li><em>Link</em>: <a href=https://themaister.net/blog/2025/10/05/a-case-for-learning-gpu-programming-with-a-compute-first-mindset/ target=_blank>https://themaister.net/blog/2025/10/05/a-case-for-learning-gpu-programming-with-a-compute-first-mindset/</a></li></ul><h3 class="relative group">Recursos de Arquitectura física<div id=recursos-de-arquitectura-física class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#recursos-de-arquitectura-f%c3%adsica aria-label=Ancla>#</a></span></h3><p><strong>Demystifying GPU Compute Architectures (The Chip Letter)</strong></p><ul><li><em>Descripción</em>: Análisis profundo de arquitecturas de cómputo GPU modernas</li><li><em>Link</em>: <a href=https://thechipletter.substack.com/p/demystifying-gpu-compute-architectures target=_blank>https://thechipletter.substack.com/p/demystifying-gpu-compute-architectures</a></li></ul><p><strong>Understanding GPU Architecture (Scale Computing)</strong></p><ul><li><em>Descripción</em>: Explicación de estructura, capas y componentes de GPUs</li><li><em>Link</em>: <a href=https://www.scalecomputing.com/resources/understanding-gpu-architecture target=_blank>https://www.scalecomputing.com/resources/understanding-gpu-architecture</a></li></ul><p><strong>NASA HECC: Basics on NVIDIA GPU Hardware Architecture</strong></p><ul><li><em>Descripción</em>: Fundamentos de arquitectura GPU desde perspectiva de cómputo científico</li><li><em>Link</em>: <a href=https://www.nas.nasa.gov/hecc/support/kb/basics-on-nvidia-gpu-hardware-architecture_704.html target=_blank>https://www.nas.nasa.gov/hecc/support/kb/basics-on-nvidia-gpu-hardware-architecture_704.html</a></li></ul><h3 class="relative group">Herramientas y SDKs<div id=herramientas-y-sdks class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#herramientas-y-sdks aria-label=Ancla>#</a></span></h3><p><strong>CUDA Toolkit</strong></p><ul><li><em>Descripción</em>: Suite completa de desarrollo para GPU computing</li><li><em>Incluye</em>: Librerías, debugger, profiler, compilador, ejemplos de código</li><li><em>Link</em>: <a href=https://developer.nvidia.com/cuda-toolkit target=_blank>https://developer.nvidia.com/cuda-toolkit</a></li></ul><p><strong>CUDA Zone - Library of Resources</strong></p><ul><li><em>Descripción</em>: Hub central de recursos CUDA de NVIDIA</li><li><em>Link</em>: <a href=https://developer.nvidia.com/cuda-zone target=_blank>https://developer.nvidia.com/cuda-zone</a></li></ul><h3 class="relative group">Artículos y Papers Académicos<div id=artículos-y-papers-académicos class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#art%c3%adculos-y-papers-acad%c3%a9micos aria-label=Ancla>#</a></span></h3><p><strong>Inside the GPU: A Comprehensive Guide to Modern Graphics Architecture</strong></p><ul><li><em>Fuente</em>: LearnOpenCV</li><li><em>Link</em>: <a href=https://learnopencv.com/modern-gpu-architecture-explained/ target=_blank>https://learnopencv.com/modern-gpu-architecture-explained/</a></li></ul><p><strong>GPU Architecture and Programming — An Introduction (Medium)</strong></p><ul><li><em>Autor</em>: Najeeb Khan</li><li><em>Link</em>: <a href=https://medium.com/@najeebkan/gpu-architecture-and-programming-an-introduction-561bfcb51f54 target=_blank>https://medium.com/@najeebkan/gpu-architecture-and-programming-an-introduction-561bfcb51f54</a></li></ul></div></div><script type=text/javascript src=/js/page.min.54b6f4371722649edbe871e431d8670d670878c22be8f36e229fe53cc9b786fe25a834def5e6de621f7a3e37b72bc8cd73839aa5ed907ed6cbd45cd3e1b0fa20.js integrity="sha512-VLb0NxciZJ7b6HHkMdhnDWcIeMIr6PNuIp/lPMm3hv4lqDTe9ebeYh96Pje3K8jNc4Oape2QftbL1FzT4bD6IA==" data-oid=views_posts/que-es-un-gpu.md data-oid-likes=likes_posts/que-es-un-gpu.md></script></section><footer class="pt-8 max-w-prose print:hidden"><div class=pt-8><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class="flex justify-between pt-3"><span class="flex flex-col"><a class="flex text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400" href=/2025/08/19/zig-un-lenguaje-que-quiere-reemplazar-al-poderoso-c/><span class=leading-6><span class="inline-block rtl:rotate-180">&larr;</span>&ensp;Zig: un lenguaje que quiere reemplazar al poderoso C
</span></a><span class="ms-6 mt-1 text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2025-08-19T00:00:00+00:00>19 agosto 2025</time>
</span></span><span class="flex flex-col items-end"><a class="flex text-right text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400" href=/2026/01/29/bases-de-datos-para-series-de-tiempo/><span class=leading-6>Bases de datos para series de tiempo&ensp;<span class="inline-block rtl:rotate-180">&rarr;</span>
</span></a><span class="me-6 mt-1 text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2026-01-29T00:00:00+00:00>29 enero 2026</time></span></span></div></div></footer></article><div id=scroll-to-top class="fixed bottom-24 end-6 z-50 transform translate-y-4 opacity-0 duration-200"><a href=#the-top class="pointer-events-auto flex h-12 w-12 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label="Ir arriba" title="Ir arriba">&uarr;</a></div></main><footer id=site-footer class="py-10 print:hidden"><div class="flex items-center justify-between"><p class="text-sm text-neutral-500 dark:text-neutral-400">&copy;
2026</p><p class="text-xs text-neutral-500 dark:text-neutral-400">Desarrollada con <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://gohugo.io/ target=_blank rel="noopener noreferrer">Hugo</a> & <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://blowfish.page/ target=_blank rel="noopener noreferrer">Blowfish</a></p></div><script>mediumZoom(document.querySelectorAll("img:not(.nozoom)"),{margin:24,background:"rgba(0,0,0,0.5)",scrollOffset:0})</script><script type=text/javascript src=/js/process.min.ee03488f19c93c2efb199e2e3014ea5f3cb2ce7d45154adb3399a158cac27ca52831db249ede5bb602700ef87eb02434139de0858af1818ab0fb4182472204a4.js integrity="sha512-7gNIjxnJPC77GZ4uMBTqXzyyzn1FFUrbM5mhWMrCfKUoMdsknt5btgJwDvh+sCQ0E53ghYrxgYqw+0GCRyIEpA=="></script></footer><div id=search-wrapper class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh] z-500" data-url=https://blog.thedojo.mx/><div id=search-modal class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"><header class="relative z-10 flex items-center justify-between flex-none px-2"><form class="flex items-center flex-auto min-w-0"><div class="flex items-center justify-center w-8 h-8 text-neutral-400"><span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></div><input type=search id=search-query class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent" placeholder=Buscar tabindex=0></form><button id=close-search-button class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400" title="Cerrar (Esc)">
<span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentColor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></button></header><section class="flex-auto px-2 overflow-auto"><ul id=search-results></ul></section></div></div></div></body></html>