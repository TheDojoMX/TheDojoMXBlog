<!doctype html><html lang=es dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Usando LangChain 🦜 para crear software basado en LLM's | The Dojo MX Blog</title>
<link rel=icon href=/favicon.svg sizes=any type=image/svg+xml><meta property="og:title" content="Usando LangChain 🦜 para crear software basado en LLM's"><meta property="og:description" content="Vamos a ver cómo funciona LangChain, una herramienta que le puede dar oídos, ojos y manos a tu modelo de lenguaje preferido."><meta property="og:type" content="article"><meta property="og:url" content="https://blog.thedojo.mx/2023/04/15/usando-langchain-para-crear-software-basado-en-llms/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-04-15T00:00:00+00:00"><meta property="article:modified_time" content="2023-04-15T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Usando LangChain 🦜 para crear software basado en LLM's"><meta name=twitter:description content="Vamos a ver cómo funciona LangChain, una herramienta que le puede dar oídos, ojos y manos a tu modelo de lenguaje preferido."><link rel=stylesheet href=/css/extended.min.771dff75f9f3290205d2bfcbeda2ed15a5984c0414d431dfec3423ae5e37bb90.css integrity="sha256-dx3/dfnzKQIF0r/L7aLtFaWYTAQU1DHf7DQjrl43u5A=" crossorigin=anonymous><link rel=stylesheet href=/css/root.min.0e732b812b9751962e01a7c4798a1211cd5f8ac8abec7f99793fe306989e459f.css integrity="sha256-DnMrgSuXUZYuAafEeYoSEc1fisir7H+ZeT/jBpieRZ8=" crossorigin=anonymous><link rel=stylesheet href=/css/bundle.min.59eb1a059f8cd558e64375ede3e68d3e9120ddb0c6bdbab555c247689cef59e1.css integrity="sha256-WesaBZ+M1VjmQ3Xt4+aNPpEg3bDGvbq1VcJHaJzvWeE=" crossorigin=anonymous><script src=/js/bundle.cc8ae9952dbfb731affafabdf26e5c60a6910047ff59ccdeaf1daebaa26c8830.js integrity="sha256-zIrplS2/tzGv+vq98m5cYKaRAEf/Wczerx2uuqJsiDA=" crossorigin=anonymous></script><script defer src=/js/search/flexsearch.compact.64594b125f7b78bdf4fa8316955922bbebb1cd6baef3f16654bfca20309f18f8.js integrity="sha256-ZFlLEl97eL30+oMWlVkiu+uxzWuu8/FmVL/KIDCfGPg="></script><script defer src=/js/search/search.1d980f84df11f3eb7c8c5f17f541d49a0611608df179dd74fa7f06225eb56ace.js integrity="sha256-HZgPhN8R8+t8jF8X9UHUmgYRYI3xed10+n8GIl61as4="></script><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Spectral:ital,wght@0,200;0,300;0,400;0,500;0,600;0,700;0,800;1,200;1,300;1,400;1,500;1,600;1,700;1,800&display=swap" rel=stylesheet><link href="https://fonts.googleapis.com/css2?family=Bricolage+Grotesque:opsz,wght@12..96,200..800&family=Spectral:ital,wght@0,200;0,300;0,400;0,500;0,600;0,700;0,800;1,200;1,300;1,400;1,500;1,600;1,700;1,800&display=swap" rel=stylesheet></head><body class=notransition><div id=container><header id=main-header><div role=navigation aria-label=Main><div class=nav-left><a href=https://blog.thedojo.mx/ style=color:inherit>The Dojo MX Blog</a></div><div class=nav-right><div style=position:absolute;width:0;height:0><div id=nav-dropdown-menu class=hidden href=#><div class=nav-item><a aria-current=true class=ancestor href=/posts/>Posts</a></div><div class=nav-item><a>Acerca de</a></div></div></div><a id=nav-dropdown-button href=#><svg width="20" height="20" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M4 6H20M4 12H20M4 18H20" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg></a><div id=nav-menu><div class=nav-item><a aria-current=true class=ancestor href=/posts/>Posts</a></div><div class=nav-item><a>Acerca de</a></div></div><a id=theme-switcher href=#><svg class="light-icon" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M12 3V4m0 16v1M4 12H3M6.31412 6.31412 5.5 5.5m12.1859.81412L18.5 5.5M6.31412 17.69 5.5 18.5001M17.6859 17.69 18.5 18.5001M21 12H20m-4 0c0 2.2091-1.7909 4-4 4-2.20914.0-4-1.7909-4-4 0-2.20914 1.79086-4 4-4 2.2091.0 4 1.79086 4 4z" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg><svg class="dark-icon" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M3.32031 11.6835c0 4.9706 4.02944 9 8.99999 9 3.7872.0 7.028-2.3392 8.3565-5.6515C19.6402 15.4486 18.5059 15.6834 17.3203 15.6834c-4.9706.0-8.99999-4.0294-8.99999-8.99998C8.32031 5.50338 8.55165 4.36259 8.96453 3.32996 5.65605 4.66028 3.32031 7.89912 3.32031 11.6835z" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg></a></div></div></header><div class="flex grow"><div id=main-pane><main id=main-content><div class=single-header><ol class=breadcrumbs itemscope itemtype=https://schema.org/BreadcrumbList><li itemprop=itemListElement itemscope itemtype=https://schema.org/ListItem><a itemprop=item href=https://blog.thedojo.mx/><span itemprop=name>Home</span>
</a><meta itemprop=position content='1'></li><span>&nbsp»&nbsp</span><li itemprop=itemListElement itemscope itemtype=https://schema.org/ListItem><a itemprop=item href=https://blog.thedojo.mx/posts/><span itemprop=name>Posts</span>
</a><meta itemprop=position content='2'></li><span>&nbsp»&nbsp</span></ol><h1>Usando LangChain 🦜 para crear software basado en LLM's</h1><time class=dim datetime=2023-04-15T00:00:00+00:00>April 15, 2023</time><div class=term-container><div class=tag><a href=https://blog.thedojo.mx/tags/langchain/>#langchain</a></div><div class=tag><a href=https://blog.thedojo.mx/tags/llm/>#llm</a></div><div class=tag><a href=https://blog.thedojo.mx/tags/tutorial/>#tutorial</a></div></ol></div><section class=page-section><p>Los grandes modelos de lenguaje o LLM&rsquo;s (Large Language Models) han sido noticia en este 2023. Es por eso que han surgido muchos proyectos y herramientas que permiten crear software basado en estas herramientas.</p><p>En este artículo vamos a poner un pequeño tutorial de una herramienta creada para hacer aplicaciones basadas en LLM&rsquo;s: <a href=https://python.langchain.com/en/latest/index.html>LangChain</a>.</p><h2 id=qué-es-langchain>¿Qué es LangChain?</h2><p>Las aplicaciones basadas en procesamiento de lenguaje natural, sea como una herramienta de comunicación o como su producto principal, normalmente requieren fuentes de información para potenciar sus capacidades.</p><p>También es una muy buena idea que estas aplicaciones puedan actuar por sí mismas usando las instrucciones creadas por un LLM. Para hacer esto podemos usar <strong>agentes</strong>.</p><p><strong>LangChain</strong> provee componentes que te permiten lograr estas dos tareas, para que tú los uses como quieras, pero también te provee
de cadenas de componentes (<em><a href=/>composición</a> de software, ¿te suena?</em>) con casos de uso comunes, digamos que prefabricados, para hacer software basado en LLM&rsquo;s de manera más rápida.</p><p>Hablemos de qué componentes te provee LangChain para empezar a construir tus programas basados en LLM&rsquo;s.</p><h2 id=componentes-principales>Componentes principales</h2><p>LangChain provee varios tipos de componentes, muchos de los cuales son abstracciones de los conceptos más usados en la interacción con LLM&rsquo;s, veamos algunos de ellos:</p><ul><li><p><strong>Texto</strong>. La abstracción más básica es la que representa un texto cualquiera que le mandamos a un LLM. Este texto puede provenir de diferentes fuentes, como archivos, por ejemplo.</p></li><li><p><strong>Divisores de texto</strong>. Generalmente, un modelo de lenguaje no puede consumir mucho texto al mismo tiempo, por lo que para poder procesar textos grandes hay que mandárselos por partes. Este componente se encarga de ayudarte a dividir el texto en partes que el LLM pueda procesar.</p></li><li><p><strong>Índices</strong>. Es una abstracción que presenta el texto de mejor manera para que un LLM pueda acceder a la información mejor. Los índices se tienen que guardar de alguna manera y LangChain provee una interfaz para guardarlos en una base de datos especializada.</p></li><li><p><strong>Modelo</strong>. Esto es la interfaz con un modelo de lenguaje. Te lo puedes imaginar como el equivalente a un conector a base de datos, abstraen los detalles de la conexión y te dan una interfaz común.</p></li><li><p><strong>Agente</strong>. Un agente puede recibir instrucciones en forma de alguna abstracción de texto, para ejecutar acciones en <em>sistemas externos</em> o consultando para consultar al LLM.</p></li><li><p><strong>Cadena</strong>. Las cadenas son conjuntos de componentes que sirven para resolver problemas comunes o crear aplicaciones completas.</p></li></ul><p>Ya que entendemos las cosas que LangChain nos da, veamos cómo usarlas.</p><h2 id=creando-una-aplicación-de-ejemplo>Creando una aplicación de ejemplo</h2><p>Vamos a crear una aplicación que nos permita consultar todos los posts de este blog y contestar preguntas. Por suerte, existe una cadena que ya nos permite hacer esto.</p><h3 id=instalación>Instalación</h3><p>Primero veamos los requisitos: además de LangChain, necesitas los siguientes paquetes:</p><ul><li>openai</li><li>chromadb</li><li>tiktoken</li></ul><p>Por lo que tu requirements.txt debería verse así:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>langchain
</span></span><span style=display:flex><span>openai
</span></span><span style=display:flex><span>chromadb
</span></span><span style=display:flex><span>tiktoken
</span></span></code></pre></div><p>Aquí, recomiendo usar un entorno virtual con <a href=https://www.anaconda.com/products/distribution>Anaconda</a>, sobre todo si tienes planes de seguir trabajando con cosas relacionadas con
procesamiento de datos.</p><p>Para hacer la creación e instalación puedes correr los siguientes comandos si tienes <code>conda</code>:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>
</span></span><span style=display:flex><span>conda create -n entorno_langchain pip
</span></span><span style=display:flex><span>conda activate entorno_langchain
</span></span><span style=display:flex><span>pip install requeriments.txt
</span></span></code></pre></div><p>Aquí <code>entorno_langchain</code> es el nombre de nuestro entorno virtual y puede ser cualquiera que tú quieras.
También, para empezar, necesito una fuente de datos para empezar a probar, por lo que voy a copiar algunos posts de este blog, que están en formato markdown y pueden ser consumidas sin ningún programa adicional. Voy a crear una carpeta llamada docs y dentro copiaré los archivos markdown de este blog, que están en _posts. Tú puedes poner ahí los diferentes archivos que quieras consultar, tal vez directamente en docs.</p><p>Mi estructura de archivos se ve así (mi carpeta de trabajo es <code>thedojo_agent</code>):</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>
</span></span><span style=display:flex><span>thedojo_agent
</span></span><span style=display:flex><span>├── docs
</span></span><span style=display:flex><span>│   ├── _posts
</span></span><span style=display:flex><span>│   │   ├── 2018-10-28-bienvenidos.md
</span></span><span style=display:flex><span>... muchos archivos más
</span></span><span style=display:flex><span>├── requeriments.txt
</span></span></code></pre></div><p>Teniendo esto listo podemos seguir el ejemplo básico del tutorial de LangChain.</p><h2 id=creando-un-script-mínimo-que-funciona>Creando un script mínimo que funciona</h2><p>Dentro de un archivo que se llame <code>main.py</code> vamos a escribir el siguiente código:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> langchain.document_loaders <span style=color:#f92672>import</span> TextLoader
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> langchain.indexes <span style=color:#f92672>import</span> VectorstoreIndexCreator
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>loader <span style=color:#f92672>=</span> TextLoader(<span style=color:#e6db74>&#34;./docs/_posts/2023-04-07-cuando-separar-el-codigo.md&#34;</span>)
</span></span><span style=display:flex><span>index <span style=color:#f92672>=</span> VectorstoreIndexCreator()<span style=color:#f92672>.</span>from_loaders([loader])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>query <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;¿Cuándo separar el código?&#34;</span>
</span></span><span style=display:flex><span>print(index<span style=color:#f92672>.</span>query(query))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>query <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;¿Qué es un módulo?&#34;</span>
</span></span><span style=display:flex><span>print(index<span style=color:#f92672>.</span>query_with_sources(query))
</span></span></code></pre></div><p>Primero importamos el componente <code>TextLoader</code> que nos permitirá cargar texto de un archivo y el componente <code>VectorstoreIndexCreator</code> que nos permitirá crear un índice y almacenarlo como un vector.</p><p>Ya nos estamos empezando a meter en cosas que no son tan conocidas. Vamos a explicarlas. Un índice es parecido a lo que se hace en las bases de datos, se analiza la información del texto para guardarle de manera organizada, para que cuando necesitemos encontrar algo, sea fácil de encontrar. Por ejemplo, podría estar organizado por palabras clave y con las referencias a donde se puede encontrar en los textos.</p><p>Que se guarde como un vector tiene que ver con la forma en que trabajan los modelos de lenguaje. Lo que en realidad ve un modelo es una lista de tokens, que son números que representan el texto. Cuando un modelo te da una respuesta, te da una lista de tokens junto con la probabilidad de que cada token vaya en ese orden. Esto son los &ldquo;embeddings&rdquo;, y a final de cuenta son colecciones de números, como listas, lo que se conoce como vectores en este mundo del procesamiento de datos.</p><p>Así que primero generamos un índice, que consiste en un conjunto de vectores y después lo guardamos.</p><p>Eso es justo lo que hacen las dos líneas que siguen al import.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>loader <span style=color:#f92672>=</span> TextLoader(<span style=color:#e6db74>&#34;./docs/_posts/2023-04-07-cuando-separar-el-codigo.md&#34;</span>)
</span></span><span style=display:flex><span>index <span style=color:#f92672>=</span> VectorstoreIndexCreator()<span style=color:#f92672>.</span>from_loaders([loader])
</span></span></code></pre></div><p>Después de esto, ahora consultamos el texto de dos formas:</p><ol><li>Primero que nos de la respuesta solita.</li><li>Que nos de la respuestas junto con la fuente de donde la sacó.</li></ol><p>Este ejemplo básico ya empieza a hacer por nosotros lo que queríamos en un principio: consultar un texto y obtener una respuesta.</p><p>Vamos a ir un poco más hondo en el código.</p><h3 id=qué-hace-vectorstoreindexcreator>¿Qué hace VectorstoreIndexCreator?</h3><p>La parte que más magia esconde es el objeto <code>VectorstoreIndexCreator</code>. Este objeto es una composición de otros que cumplen estos roles:</p><ol><li>Un &ldquo;cortador&rdquo; de texto, que ayuda a procesar el texto de la fuente.</li><li>Un modelo de lenguaje para generar los embeddings.</li><li>Un almacén de datos, en nuestro caso, un <code>Vectorstore</code>, o una base de datos que almacene vectores.</li></ol><p>El objeto ya hace por nosotros todo el trabajo, el flujo de información, desde la fuente, que en el ejemplo es un texto cargado desde un conjunto de archivos, hasta el almacén de datos, que en el ejemplo es ChromaDB, que es una base de datos que almacena vectores.</p><p>ChromaDB puede correr en memoria o como servidor, pero aquí corre como base de datos en memoria, usando por debajo DuckDB, una base de datos completamente en memoria, así que cuando salgas del programa, se borra todo.</p><p>Vamos a dejar para un artículo futuro la creación de un índice, explicando sus parámetros.</p><p>Si quieres ver un ejmplo funcionando, Alex y yo hicimos un ejemplo y platicamos más de esto en este directo:</p><hr><p>¡Esperamos tus comentarios!</p></section></main><footer id=main-footer><div class=footer><a href=#>Scroll to Top</a><div class=footer-copyright><div class=dim>© 2025 Héctor Patricio</div><div>Made with ❤️ and powered by <a href=https://github.com/math-queiroz/rusty-typewriter target=_blank>Rusty Typewriter</a> theme for <a href=https://gohugo.io/ target=_blank>Hugo</a></div></div></div></footer></div><aside id=side-pane class=side-sticky><div class=side-details><span>1171 words</span>
<span>7 - 9 minutes read</span></div><h3>Table Of Contents</h3><nav id=TableOfContents><ul><li><a href=#qué-es-langchain>¿Qué es LangChain?</a></li><li><a href=#componentes-principales>Componentes principales</a></li><li><a href=#creando-una-aplicación-de-ejemplo>Creando una aplicación de ejemplo</a><ul><li><a href=#instalación>Instalación</a></li></ul></li><li><a href=#creando-un-script-mínimo-que-funciona>Creando un script mínimo que funciona</a><ul><li><a href=#qué-hace-vectorstoreindexcreator>¿Qué hace VectorstoreIndexCreator?</a></li></ul></li></ul></nav></aside></div></div></body></html>