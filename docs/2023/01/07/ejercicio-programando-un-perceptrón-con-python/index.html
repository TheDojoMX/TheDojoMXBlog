<!doctype html><html lang=es dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Ejercicio: programando un perceptrón con Python | The Dojo MX Blog</title>
<link rel=icon href=/favicon.svg sizes=any type=image/svg+xml><meta property="og:title" content="Ejercicio: programando un perceptrón con Python"><meta property="og:description" content="Programemos un perceptrón en Python para entender a fondo como funciona y poder construir sobre eso para temas más complejos."><meta property="og:type" content="article"><meta property="og:url" content="https://blog.thedojo.mx/2023/01/07/ejercicio-programando-un-perceptr%C3%B3n-con-python/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-01-07T00:00:00+00:00"><meta property="article:modified_time" content="2023-01-07T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Ejercicio: programando un perceptrón con Python"><meta name=twitter:description content="Programemos un perceptrón en Python para entender a fondo como funciona y poder construir sobre eso para temas más complejos."><link rel=stylesheet href=/css/extended.min.771dff75f9f3290205d2bfcbeda2ed15a5984c0414d431dfec3423ae5e37bb90.css integrity="sha256-dx3/dfnzKQIF0r/L7aLtFaWYTAQU1DHf7DQjrl43u5A=" crossorigin=anonymous><link rel=stylesheet href=/css/root.min.0e732b812b9751962e01a7c4798a1211cd5f8ac8abec7f99793fe306989e459f.css integrity="sha256-DnMrgSuXUZYuAafEeYoSEc1fisir7H+ZeT/jBpieRZ8=" crossorigin=anonymous><link rel=stylesheet href=/css/bundle.min.59eb1a059f8cd558e64375ede3e68d3e9120ddb0c6bdbab555c247689cef59e1.css integrity="sha256-WesaBZ+M1VjmQ3Xt4+aNPpEg3bDGvbq1VcJHaJzvWeE=" crossorigin=anonymous><script src=/js/bundle.cc8ae9952dbfb731affafabdf26e5c60a6910047ff59ccdeaf1daebaa26c8830.js integrity="sha256-zIrplS2/tzGv+vq98m5cYKaRAEf/Wczerx2uuqJsiDA=" crossorigin=anonymous></script><script defer src=/js/search/flexsearch.compact.64594b125f7b78bdf4fa8316955922bbebb1cd6baef3f16654bfca20309f18f8.js integrity="sha256-ZFlLEl97eL30+oMWlVkiu+uxzWuu8/FmVL/KIDCfGPg="></script><script defer src=/js/search/search.1d980f84df11f3eb7c8c5f17f541d49a0611608df179dd74fa7f06225eb56ace.js integrity="sha256-HZgPhN8R8+t8jF8X9UHUmgYRYI3xed10+n8GIl61as4="></script><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Spectral:ital,wght@0,200;0,300;0,400;0,500;0,600;0,700;0,800;1,200;1,300;1,400;1,500;1,600;1,700;1,800&display=swap" rel=stylesheet><link href="https://fonts.googleapis.com/css2?family=Bricolage+Grotesque:opsz,wght@12..96,200..800&family=Spectral:ital,wght@0,200;0,300;0,400;0,500;0,600;0,700;0,800;1,200;1,300;1,400;1,500;1,600;1,700;1,800&display=swap" rel=stylesheet></head><body class=notransition><div id=container><header id=main-header><div role=navigation aria-label=Main><div class=nav-left><a href=https://blog.thedojo.mx/ style=color:inherit>The Dojo MX Blog</a></div><div class=nav-right><div style=position:absolute;width:0;height:0><div id=nav-dropdown-menu class=hidden href=#><div class=nav-item><a aria-current=true class=ancestor href=/posts/>Posts</a></div><div class=nav-item><a>Acerca de</a></div></div></div><a id=nav-dropdown-button href=#><svg width="20" height="20" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M4 6H20M4 12H20M4 18H20" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg></a><div id=nav-menu><div class=nav-item><a aria-current=true class=ancestor href=/posts/>Posts</a></div><div class=nav-item><a>Acerca de</a></div></div><a id=theme-switcher href=#><svg class="light-icon" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M12 3V4m0 16v1M4 12H3M6.31412 6.31412 5.5 5.5m12.1859.81412L18.5 5.5M6.31412 17.69 5.5 18.5001M17.6859 17.69 18.5 18.5001M21 12H20m-4 0c0 2.2091-1.7909 4-4 4-2.20914.0-4-1.7909-4-4 0-2.20914 1.79086-4 4-4 2.2091.0 4 1.79086 4 4z" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg><svg class="dark-icon" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M3.32031 11.6835c0 4.9706 4.02944 9 8.99999 9 3.7872.0 7.028-2.3392 8.3565-5.6515C19.6402 15.4486 18.5059 15.6834 17.3203 15.6834c-4.9706.0-8.99999-4.0294-8.99999-8.99998C8.32031 5.50338 8.55165 4.36259 8.96453 3.32996 5.65605 4.66028 3.32031 7.89912 3.32031 11.6835z" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg></a></div></div></header><div class="flex grow"><div id=main-pane><main id=main-content><div class=single-header><ol class=breadcrumbs itemscope itemtype=https://schema.org/BreadcrumbList><li itemprop=itemListElement itemscope itemtype=https://schema.org/ListItem><a itemprop=item href=https://blog.thedojo.mx/><span itemprop=name>Home</span>
</a><meta itemprop=position content='1'></li><span>&nbsp»&nbsp</span><li itemprop=itemListElement itemscope itemtype=https://schema.org/ListItem><a itemprop=item href=https://blog.thedojo.mx/posts/><span itemprop=name>Posts</span>
</a><meta itemprop=position content='2'></li><span>&nbsp»&nbsp</span></ol><h1>Ejercicio: programando un perceptrón con Python</h1><time class=dim datetime=2023-01-07T00:00:00+00:00>January 7, 2023</time><div class=term-container><div class=tag><a href=https://blog.thedojo.mx/tags/machine-learning/>#machine-learning</a></div><div class=tag><a href=https://blog.thedojo.mx/tags/ia/>#ia</a></div><div class=tag><a href=https://blog.thedojo.mx/tags/inteligencia-artificial/>#inteligencia-artificial</a></div></ol></div><section class=page-section><p>En este post platicaremos acerca de cómo funciona un perceptrón con un ejemplo de código y las técnicas que utiliza para aproximar una función a partir de datos.</p><p>Si no tienes claro lo que es un perceptrón, puedes leer nuestro <a href=/2021/03/25/intro-a-machine-learning-entendiendo-perceptron.html>artículo anterior</a>{:target="_blank"}. Ahí también explicamos las bases de funcionamiento. En este artículo lo vamos a ilustrar de la manera más sencilla posible.</p><h2 id=el-conjunto-de-datos>El conjunto de datos</h2><p>Recuerda que para poder crear un algoritmo de machine learning necesitamos un conjunto de datos, ya que el punto es que este algoritmo <em>aprenda</em> de estos datos.</p><p>Los datos que un perceptrón puede clasificar deben poder ser separados en mínimo dos clases por alguna característica, ya que si representáramos al perceptrón como una función, es un línea recta en un plano de dos variables (o su equivalente dependiendo del espacio y sus dimensiones, lo que en para más de tres dimensiones llamamos un <em>hiperespacio</em> matemáticamente).</p><p>No es necesario que los datos <em>sólo</em> puedan estar divididos en dos clases, por ejemplo, imagínate un conjunto de datos que representa los dígitos escritos a mano, del 0 al 9 (este es conocido como el <a href=https://www.tensorflow.org/datasets/catalog/mnist>MNIST dataset</a>). Cada dígito es una clase, pero un perceptrón nos puede servir para clasificar un solo número, por ejemplo, el 5. El perceptrón serviría para clasificar si un dígito es un 5 o no, lo importante es que el conjunto de datos que representa el 5 sea más o menos separable de los demás dígitos.</p><p>Con esto te puedes empezar a dar cuenta de que el perceptrón es el bloque de construcción más básico de las redes neuronales. Por ejemplo, ¿cómo haríamos para clasificar todos los números del conjunto del que hablamos arriba? Necesitamos un perceptrón por cada número, y tomamos el que más confianza nos devuelva.</p><p>Ahora sí veamos qué dataset usaremos nosotros. Ejemplos usando el MNIST o el <a href=https://archive.ics.uci.edu/ml/datasets/iris>Iris</a> encontrarás en muchos lados, así que vamos a escoger uno diferente.
Este es una alternativa a Iris y se conoce como el <a href=https://github.com/allisonhorst/palmerpenguins>Penguin dataset</a>.</p><p>El conjunto de datos de los pingüinos tiene 344 registros etiquetados, cada uno con máximo 6 características (a parte de la etiqueta). Tiene 3 etiquetas diferentes: Adelie, Chinstrap y Gentoo. Las columnas del dataset son:</p><ol><li><strong>species</strong>: especie del pingüino, esta es la clase o etiqueta</li><li><strong>island</strong>: isla donde fue visto el pingüino, tiene 3 valores diferentes: Dream, Torgersen, or Biscoe</li><li><strong>bill_lenth_mm</strong>: longitud de la pico del pingüino</li><li><strong>bill_depth_mm</strong>: profundidad de la pico del pingüino</li><li><strong>flipper_length_mm</strong>: longitud de la aleta del pingüino</li><li><strong>body_mass_g</strong>: masa del cuerpo del pingüino</li><li><strong>sex</strong>: sexo del pingüino</li></ol><p>Tenemos que explorar los datos brevemente para ver qué variables podemos usar para separar. Como este no es el objetivo de este artículo vamos a ver una imagen en la que comparan por pares las variables y seleccionemos las que nos ayuden a separar mejor las clases. Vamos a hacerlo sólamente con dos variables para que el código nos quede más sencillo y se comprenda la idea principal.</p><p>La siguiente imagen es una gráfica de dos variables: la anchura del pico (<strong>bill_depth_mm</strong>) y el largo de su aleta (<strong>flipper_length_mm</strong>). Observa qué bien separa a la clase Gentoo de las otras dos.</p><p><img src=https://res.cloudinary.com/hectorip/image/upload/v1673111878/a1f1d1b7-d87c-478d-b67a-c344c802f4d6_spefvh.png alt="Gráfica de dos variables">{: .align-center}</p><p><strong>Nota</strong>: para el entrenamiento de una red neuronal se hace una exploración mucho más profunda de los datos, pero para este ejemplo no es necesario.</p><h2 id=repaso-del-funcionamiento-básico>Repaso del funcionamiento básico</h2><p>El perceptrón es un algoritmo de aprendizaje <strong>supervisado</strong>, por lo que necesita datos etiquetados, es decir, <em>las características junto con su clase</em>. El trabajo del perceptrón es encontrar los parámetros para una función matemática que defina la frontera de separación entre las clases.</p><p>Esta función matemática es una línea recta en un plano de dos dimensiones, o un plano en un espacio de tres dimensiones, o un <strong>hiperplano</strong> en un espacio de más de tres dimensiones. Puedes pensar en todos estos términos matemáticos como el equivalente a una linea recta en cualquier espacio.</p><h2 id=el-algoritmo>El algoritmo</h2><p>El perceptron es busca ajustar una función lineal que separa las clases. En este caso separaremos &ldquo;Gentoo&rdquo; de &ldquo;no es un Gentoo&rdquo;. El algoritmos nos dirá &ldquo;1&rdquo; si es un Gentoo y &ldquo;0&rdquo; si no lo es. Una función lieneal tiene la forma:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>y <span style=color:#f92672>=</span> w1 <span style=color:#f92672>*</span> x1 <span style=color:#f92672>+</span> w2 <span style=color:#f92672>*</span> x2 <span style=color:#f92672>+</span> b
</span></span></code></pre></div><p>Con un término <code>wn * xn</code> para cada variable de entrada, y un término <code>b</code> para el sesgo. El perceptrón ajusta los valores de <code>w1</code>, <code>w2</code>, y <code>b</code> para que la función lineal se ajuste a los datos.</p><p>Podemos empezar combinando las dos variables que elegimos de la siguiente manera:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>y <span style=color:#f92672>=</span> w1 <span style=color:#f92672>*</span> penguins[<span style=color:#e6db74>&#39;bill_depth_mm&#39;</span>] <span style=color:#f92672>+</span> w2 <span style=color:#f92672>*</span> penguins[<span style=color:#e6db74>&#39;flipper_length_mm&#39;</span>] <span style=color:#f92672>+</span> b
</span></span></code></pre></div><p><strong>Nota</strong>: En este ejemplo no usaremos <code>numpy</code> o <code>pandas</code>, para hacer la programación lo más tradicional posible. Más adelante nos empezaremos a meter en <code>numpy</code>, <code>pandas</code> y esas cosas que parecen magia negra.</p><p>Esto nos dará un número que tenemos que convertir en un 1 o un 0. Usemos una función sencilla. Todos lo números negativos los convertimos en un 0 y todos los positivos y el 0 en un 1. Esto se puede programar sencillo. Vamos a llamar a esta función <code>paso</code>:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>paso</span>(x):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> x <span style=color:#f92672>&lt;</span> <span style=color:#ae81ff>0</span>:
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> <span style=color:#ae81ff>1</span>
</span></span></code></pre></div><p>Ahora podemos usar esta función para convertir la salida de la función lineal en un 1 o un 0:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>clasificar</span>(x, w1, w2, b):
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;Recibe una fila de datos y devuelve 1 si es Gentoo y 0 si no lo es&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> paso(w1 <span style=color:#f92672>*</span> x[<span style=color:#e6db74>&#34;bill_depth_mm&#34;</span>] <span style=color:#f92672>+</span> w2 <span style=color:#f92672>*</span> x[<span style=color:#e6db74>&#34;flipper_length_mm&#34;</span>] <span style=color:#f92672>+</span> b)
</span></span></code></pre></div><p>Nuestra función de clasificación ya está lista. Pero el trabajo del perceptrón es encontrar los valores de <strong>los parámetros</strong>: <code>w1</code>, <code>w2</code>, y <code>b</code>. Creemos el algoritmo que define estos valores, que llamaremos <code>entrenar</code>. Esta función aprende a base de prueba y error. Para aprender hace lo siguiente:</p><ol><li>Clasifica cada dato de entrenamiento</li><li>Verifica si la etiqueta es correcta (para esto necesitamos las etiquetas de los datos de entrenamiento)</li><li>Ajusta sus parámetros: cambiar los valores de <code>w1</code>, <code>w2</code>, y <code>b</code> para que la función lineal se ajuste a los datos.</li><li>Repite el proceso</li></ol><p>Este proceso puede terminar por dos razones:</p><ol><li>Se alcanza un número máximo de iteraciones</li><li>Se alcanza un resultado satisfactorio (ej. el número de elementos mal clasificados es menor a un umbral)</li></ol><p>Para hacerlo sencillo vamos a hacer que el algoritmo se ejecute un número fijo de veces:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>entrenar</span>(datos, iteraciones):
</span></span><span style=display:flex><span>    <span style=color:#75715e># inicializamos los parámetros, esto puede ser aleatorio o cero, como lo hacemos aquí</span>
</span></span><span style=display:flex><span>    w1 <span style=color:#f92672>=</span> w2 <span style=color:#f92672>=</span> b <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>while</span> iteraciones <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>0</span>:
</span></span><span style=display:flex><span>        iteraciones <span style=color:#f92672>-=</span> <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> x <span style=color:#f92672>in</span> datos:
</span></span><span style=display:flex><span>            etiqueta_real <span style=color:#f92672>=</span> int(x[<span style=color:#e6db74>&#34;species&#34;</span>] <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;Gentoo&#34;</span>)
</span></span><span style=display:flex><span>            clase <span style=color:#f92672>=</span> clasificar(x, w1, w2, b)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>if</span> etiqueta_real <span style=color:#f92672>==</span> <span style=color:#ae81ff>1</span> <span style=color:#f92672>and</span> clase <span style=color:#f92672>==</span> <span style=color:#ae81ff>0</span>:
</span></span><span style=display:flex><span>                <span style=color:#75715e># Aquí tenemos un Gentoo mal clasificado, tenemos que</span>
</span></span><span style=display:flex><span>                <span style=color:#75715e># aumentar w1 y w2 para que la función lineal se acerque</span>
</span></span><span style=display:flex><span>                <span style=color:#75715e># a la etiqueta real</span>
</span></span><span style=display:flex><span>                w1 <span style=color:#f92672>+=</span> x[<span style=color:#e6db74>&#34;bill_depth_mm&#34;</span>]
</span></span><span style=display:flex><span>                w2 <span style=color:#f92672>+=</span> x[<span style=color:#e6db74>&#34;flipper_length_mm&#34;</span>]
</span></span><span style=display:flex><span>                b <span style=color:#f92672>+=</span> <span style=color:#ae81ff>1</span>  <span style=color:#75715e># Valor escogido arbitrariamente</span>
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>elif</span> etiqueta_real <span style=color:#f92672>==</span> <span style=color:#ae81ff>0</span> <span style=color:#f92672>and</span> clase <span style=color:#f92672>==</span> <span style=color:#ae81ff>1</span>:
</span></span><span style=display:flex><span>                <span style=color:#75715e># Aquí tenemos un NO Gentoo mal clasificado, tenemos que</span>
</span></span><span style=display:flex><span>                <span style=color:#75715e># disminuir w1 y w2 para que la función lineal se acerque</span>
</span></span><span style=display:flex><span>                <span style=color:#75715e># a la etiqueta real</span>
</span></span><span style=display:flex><span>                w1 <span style=color:#f92672>-=</span> x[<span style=color:#e6db74>&#34;bill_depth_mm&#34;</span>]
</span></span><span style=display:flex><span>                w2 <span style=color:#f92672>-=</span> x[<span style=color:#e6db74>&#34;flipper_length_mm&#34;</span>]
</span></span><span style=display:flex><span>                b <span style=color:#f92672>-=</span> <span style=color:#ae81ff>1</span>  <span style=color:#75715e># valor escogido arbitrariamente</span>
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>&#34;Iteración&#34;</span>, iteraciones, <span style=color:#e6db74>&#34;w1:&#34;</span>, w1, <span style=color:#e6db74>&#34;w2:&#34;</span>, w2, <span style=color:#e6db74>&#34;b:&#34;</span>, b)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> w1, w2, b
</span></span></code></pre></div><p>Podríamos decir que esto es básicamente todo el algoritmo del perceptrón. Ahora podemos entrenar nuestro perceptrón con los datos de entrenamiento. Antes le hacemos unas cuantas modificaciones para que sea más fácil de usar:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># cargar el archivo CSV con los datos de entrenamiento como diccionario, el archivo está en la carpeta data, un nivel arriba</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>with</span> open(<span style=color:#e6db74>&#34;../data/penguins.csv&#34;</span>) <span style=color:#66d9ef>as</span> csvfile:
</span></span><span style=display:flex><span>    data <span style=color:#f92672>=</span> list(csv<span style=color:#f92672>.</span>DictReader(csvfile))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Limpiando los los datos, eliminando los que no tienen bill_depth_mm o flipper_length_mm</span>
</span></span><span style=display:flex><span>data <span style=color:#f92672>=</span> [
</span></span><span style=display:flex><span>    row
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> row <span style=color:#f92672>in</span> data
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> row[<span style=color:#e6db74>&#34;bill_depth_mm&#34;</span>] <span style=color:#f92672>!=</span> <span style=color:#e6db74>&#34;NA&#34;</span> <span style=color:#f92672>and</span> row[<span style=color:#e6db74>&#34;flipper_length_mm&#34;</span>] <span style=color:#f92672>!=</span> <span style=color:#e6db74>&#34;NA&#34;</span>
</span></span><span style=display:flex><span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> row <span style=color:#f92672>in</span> data:
</span></span><span style=display:flex><span>    row[<span style=color:#e6db74>&#34;bill_depth_mm&#34;</span>] <span style=color:#f92672>=</span> float(row[<span style=color:#e6db74>&#34;bill_depth_mm&#34;</span>])
</span></span><span style=display:flex><span>    row[<span style=color:#e6db74>&#34;flipper_length_mm&#34;</span>] <span style=color:#f92672>=</span> float(row[<span style=color:#e6db74>&#34;flipper_length_mm&#34;</span>])
</span></span></code></pre></div><p>Estos datos ya está listos para para ser usados. Ahora podemos entrenar el perceptrón:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Escogemos las iteraciones arbitrariamente</span>
</span></span><span style=display:flex><span>w1, w2, b <span style=color:#f92672>=</span> entrenar(data, <span style=color:#ae81ff>100</span>)
</span></span></code></pre></div><p>Lo podemos probar con los mismos datos de entrenamiento:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>probar</span>(data, w1, w2, b):
</span></span><span style=display:flex><span>    correctos <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>    incorrectos <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> x <span style=color:#f92672>in</span> data:
</span></span><span style=display:flex><span>        clase <span style=color:#f92672>=</span> clasificar(x, w1, w2, b)
</span></span><span style=display:flex><span>        etiqueta_real <span style=color:#f92672>=</span> int(x[<span style=color:#e6db74>&#34;species&#34;</span>] <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;Gentoo&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> clase <span style=color:#f92672>==</span> etiqueta_real:
</span></span><span style=display:flex><span>            correctos <span style=color:#f92672>+=</span> <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>            incorrectos <span style=color:#f92672>+=</span> <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>      print(<span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\n\n</span><span style=color:#e6db74>Resultados:&#34;</span>)
</span></span><span style=display:flex><span>      print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Correctos: </span><span style=color:#e6db74>{</span>correctos<span style=color:#e6db74>}</span><span style=color:#e6db74> - </span><span style=color:#e6db74>{</span>(correctos <span style=color:#f92672>/</span> len(data)) <span style=color:#f92672>*</span> <span style=color:#ae81ff>100</span><span style=color:#e6db74>}</span><span style=color:#e6db74>%&#34;</span>)
</span></span><span style=display:flex><span>      print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Incorrectos: </span><span style=color:#e6db74>{</span>incorrectos<span style=color:#e6db74>}</span><span style=color:#e6db74> - </span><span style=color:#e6db74>{</span>(incorrectos <span style=color:#f92672>/</span> len(data)) <span style=color:#f92672>*</span> <span style=color:#ae81ff>100</span><span style=color:#e6db74>}</span><span style=color:#e6db74>%&#34;</span>)
</span></span><span style=display:flex><span>probar(data, w1, w2, b)
</span></span></code></pre></div><p>Y el resultado es:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>Resultados:
</span></span><span style=display:flex><span>Correctos: <span style=color:#ae81ff>219</span> - 64.03508771929825%
</span></span><span style=display:flex><span>Incorrectos: <span style=color:#ae81ff>123</span> - 35.96491228070175%
</span></span></code></pre></div><p>Parece que nuestro perceptrón no logró ni siquiera aprender bien con los datos de entrenamiento. ¿Qué pasa si aumentamos las iteraciones, digamos a 1000?</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>w1, w2, b <span style=color:#f92672>=</span> entrenar(data, <span style=color:#ae81ff>1000</span>)
</span></span><span style=display:flex><span>probar(data, w1, w2, b)
</span></span></code></pre></div><p>El resultado es:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>Resultados:
</span></span><span style=display:flex><span>Correctos: <span style=color:#ae81ff>342</span> - 100%
</span></span><span style=display:flex><span>Incorrectos: <span style=color:#ae81ff>0</span> - 0.0%
</span></span></code></pre></div><p>Parece que con las suficientes iteraciones el perceptrón logra aprender a clasificar perfectamente los datos de entrenamiento. <strong>Tip</strong>: siempre debes dudar de un algoritmo de inteligencia artificial que clasifique perfectamente, eso puede indicar que se sobreajustó a los datos de entrenamiento y cuando encuentre datos no vistos, fallará.</p><p>Para evitarlo, necesitamos probarlo con datos que no ha visto antes. Para esto vamos a dividir los datos en dos grupos, uno para entrenamiento y otro para pruebas:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Dividir los datos en dos grupos, uno para entrenamiento y otro para pruebas</span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> random
</span></span><span style=display:flex><span>random<span style=color:#f92672>.</span>shuffle(data)
</span></span><span style=display:flex><span>entrenamiento <span style=color:#f92672>=</span> data[:int(len(data) <span style=color:#f92672>*</span> <span style=color:#ae81ff>0.8</span>)]
</span></span><span style=display:flex><span>pruebas <span style=color:#f92672>=</span> data[int(len(data) <span style=color:#f92672>*</span> <span style=color:#ae81ff>0.8</span>):]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>w1, w2, b <span style=color:#f92672>=</span> entrenar(entrenamiento, <span style=color:#ae81ff>1000</span>)
</span></span><span style=display:flex><span>probar(pruebas, w1, w2, b)
</span></span></code></pre></div><p>El resultado es:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>Resultados:
</span></span><span style=display:flex><span>Correctos: <span style=color:#ae81ff>69</span> - 100.0%
</span></span><span style=display:flex><span>Incorrectos: <span style=color:#ae81ff>0</span> - 0.0%
</span></span></code></pre></div><p>Y como vemos, sigue funcionando bien con este dataset sencillo. Esta es le estructura básica de un perceptrón, pero en realidad le faltan muchas partes para que funcione de manera general sin gastar demasiado tiempo de cómputo. Por ejemplo, en este código simplemente sumamos o restamos el valor de las variables a w1 y w2. Estos saltos pueden ser muy bruscos y hacernos saltar fácilmente el valor que necesitamos. Para evitar esto, se usa otro parámetro para la función de entrenamiento llamado &ldquo;ritmo de aprendizaje&rdquo; (learning rate - lr).</p><p>Vamos a incluirlo en nuestro código:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>entrenar</span>(datos, iteraciones, lr<span style=color:#f92672>=</span><span style=color:#ae81ff>0.01</span>):
</span></span><span style=display:flex><span>    <span style=color:#75715e># inicializamos los parámetros, esto puede ser aleatorio o cero, como lo hacemos aquí</span>
</span></span><span style=display:flex><span>    w1 <span style=color:#f92672>=</span> w2 <span style=color:#f92672>=</span> b <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>while</span> iteraciones <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>0</span>:
</span></span><span style=display:flex><span>        iteraciones <span style=color:#f92672>-=</span> <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> x <span style=color:#f92672>in</span> datos:
</span></span><span style=display:flex><span>            etiqueta_real <span style=color:#f92672>=</span> int(x[<span style=color:#e6db74>&#34;species&#34;</span>] <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;Gentoo&#34;</span>)
</span></span><span style=display:flex><span>            clase <span style=color:#f92672>=</span> clasificar(x, w1, w2, b)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>            <span style=color:#75715e>## Esta es la revisión de &#34;la verdad&#34;, más adelante la explicamos en la sección &#34;función de pérdida&#34;</span>
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>if</span> etiqueta_real <span style=color:#f92672>==</span> <span style=color:#ae81ff>1</span> <span style=color:#f92672>and</span> clase <span style=color:#f92672>==</span> <span style=color:#ae81ff>0</span>:
</span></span><span style=display:flex><span>                <span style=color:#75715e># Aquí tenemos un Gentoo mal clasificado, tenemos que</span>
</span></span><span style=display:flex><span>                <span style=color:#75715e># aumentar w1 y w2 para que la función lineal se acerque</span>
</span></span><span style=display:flex><span>                <span style=color:#75715e># a la etiqueta real</span>
</span></span><span style=display:flex><span>                w1 <span style=color:#f92672>+=</span> x[<span style=color:#e6db74>&#34;bill_depth_mm&#34;</span>] <span style=color:#f92672>*</span> lr
</span></span><span style=display:flex><span>                w2 <span style=color:#f92672>+=</span> x[<span style=color:#e6db74>&#34;flipper_length_mm&#34;</span>] <span style=color:#f92672>*</span> lr
</span></span><span style=display:flex><span>                b <span style=color:#f92672>+=</span> <span style=color:#ae81ff>1</span> <span style=color:#f92672>*</span> lr  <span style=color:#75715e># Valor escogido arbitrariamente</span>
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>elif</span> etiqueta_real <span style=color:#f92672>==</span> <span style=color:#ae81ff>0</span> <span style=color:#f92672>and</span> clase <span style=color:#f92672>==</span> <span style=color:#ae81ff>1</span>:
</span></span><span style=display:flex><span>                <span style=color:#75715e># Aquí tenemos un NO Gentoo mal clasificado, tenemos que</span>
</span></span><span style=display:flex><span>                <span style=color:#75715e># disminuir w1 y w2 para que la función lineal se acerque</span>
</span></span><span style=display:flex><span>                <span style=color:#75715e># a la etiqueta real</span>
</span></span><span style=display:flex><span>                w1 <span style=color:#f92672>-=</span> x[<span style=color:#e6db74>&#34;bill_depth_mm&#34;</span>] <span style=color:#f92672>*</span> lr
</span></span><span style=display:flex><span>                w2 <span style=color:#f92672>-=</span> x[<span style=color:#e6db74>&#34;flipper_length_mm&#34;</span>] <span style=color:#f92672>*</span> lr
</span></span><span style=display:flex><span>                b <span style=color:#f92672>-=</span> <span style=color:#ae81ff>1</span> <span style=color:#f92672>*</span> lr  <span style=color:#75715e># valor escogido arbitrariamente</span>
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>&#34;Iteración&#34;</span>, iteraciones, <span style=color:#e6db74>&#34;w1:&#34;</span>, w1, <span style=color:#e6db74>&#34;w2:&#34;</span>, w2, <span style=color:#e6db74>&#34;b:&#34;</span>, b)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> w1, w2, b
</span></span></code></pre></div><p>Y ahora vamos a probarlo de nuevo con 100 iteraciones y el lr default:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>w1, w2, b <span style=color:#f92672>=</span> entrenar(entrenamiento, <span style=color:#ae81ff>100</span>)
</span></span><span style=display:flex><span>probar(pruebas, w1, w2, b)
</span></span></code></pre></div><p>En esta versión podemos ver que con muchas menos iteraciones el perceptrón logra clasificar correctamente los datos de prueba. El resultado es:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>Resultados:
</span></span><span style=display:flex><span>Correctos: <span style=color:#ae81ff>69</span> - 100.0%
</span></span><span style=display:flex><span>Incorrectos: <span style=color:#ae81ff>0</span> - 0.0%
</span></span></code></pre></div><h2 id=función-de-pérdida>Función de pérdida</h2><p>El último detalle de nuestro perceptrón es la forma en la que revisa si se está acercando a &ldquo;la verdad&rdquo;. En este perceptrón simplemente verificamos si la etiqueta está equivocada y elegimos si &ldquo;acercar&rdquo; o &ldquo;alejar&rdquo; la línea del punto en cuestión.</p><p>Esta es una forma no tradicional de hacerlo, pero con lo que te debes quedar es que debe existir una función que te diga qué tan equivocado estás y que te ayude a acercarte a la verdad. Esta función se llama &ldquo;función de pérdida&rdquo; (loss function). En las siguientes versiones del perceptrón vamos a incluir una función de pérdida más sofisticada, &ldquo;de verdad&rdquo;.</p><h2 id=repaso>Repaso</h2><p>En este artículo vimos todas las partes que un perceptrón, la unidad de construcción más básica de una red neuronal. Un perceptrón tiene:</p><ol><li><p>Una función de predicción. Es la que llamamos <code>clasificar</code> y nos dice si un punto de datos pertenece a una clase o no.</p></li><li><p>Una función de entrenamiento. Es la que llamamos <code>entrenar</code> y nos ayuda a ajustar los parámetros que le vamos a pasar a la función de predicción para que nos de un resultado correcto.</p></li><li><p>Una función de pérdida. Es la parte en la función <code>entrenar</code> que nos dice si estamos cerca o lejos de &ldquo;la verdad&rdquo;. Esta función es la que vamos a mejorar en las siguientes versiones del perceptrón.</p></li><li><p>Una función de activación. Esta es la que llamamos <code>paso</code> y nos ayuda a transformar la salida de la función matemática pura que representa una línea en la salida final de nuestro perceptrón. En nuestro caso necesitábamos 0 o 1.</p></li></ol><h2 id=conclusión>Conclusión</h2><p>Este perceptrón funciona, pero no es muy flexible, no se puede usar con otros conjuntos de datos y además con un conjunto de datos más complejo y menos separable probablemente no podría encontrar los parámetros correctos, sin embargo, sigue la arquitectura básica de un perceptrón, que era el punto de este artículo.</p><p>En un siguiente artículo vamos a integrar herramientas matemáticas más poderosas, y vamos a empezar a ver qué tiene qué ver el álgebra lineal con la inteligencia artificial.</p><p>Puedes ver el código completo en este <a href=https://github.com/hectorip/penguins_perceptron>repositorio</a>.</p></section></main><footer id=main-footer><div class=footer><a href=#>Scroll to Top</a><div class=footer-copyright><div class=dim>© 2025 Héctor Patricio</div><div>Made with ❤️ and powered by <a href=https://github.com/math-queiroz/rusty-typewriter target=_blank>Rusty Typewriter</a> theme for <a href=https://gohugo.io/ target=_blank>Hugo</a></div></div></div></footer></div><aside id=side-pane class=side-sticky><div class=side-details><span>2269 words</span>
<span>14 - 17 minutes read</span></div><h3>Table Of Contents</h3><nav id=TableOfContents><ul><li><a href=#el-conjunto-de-datos>El conjunto de datos</a></li><li><a href=#repaso-del-funcionamiento-básico>Repaso del funcionamiento básico</a></li><li><a href=#el-algoritmo>El algoritmo</a></li><li><a href=#función-de-pérdida>Función de pérdida</a></li><li><a href=#repaso>Repaso</a></li><li><a href=#conclusión>Conclusión</a></li></ul></nav><h3>Related</h3><ul><li><a href=/2021/03/25/intro-a-machine-learning-entendiendo-el-perceptr%C3%B3n/>Intro a Machine Learning: Entendiendo el perceptrón</a></li><li><a href=/2021/03/06/ruta-de-aprendizaje-deep-learning/>Ruta de aprendizaje: Deep Learning</a></li><li><a href=/2020/07/19/traducci%C3%B3n-autom%C3%A1tica-apis-vs-tu-propio-modelo/>Traducción automática: API's vs tu propio modelo</a></li></ul></aside></div></div></body></html>